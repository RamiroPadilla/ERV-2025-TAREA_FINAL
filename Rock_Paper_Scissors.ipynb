{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Daisy:\n",
    "`skimage.feature.daisy(image, step=4, radius=15, rings=3, histograms=8, orientations=8, normalization='l1', sigmas=None, ring_radii=None, visualize=False)` \\\\\n",
    "Daisy recorre la imagen de a \"step\" pixeles considerando cada paso un punto clave, en el cual considera un anillo el cual rodea de otros anillos. Lo rodea con \"rings\" anillos de radio \"radius\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dYebFH37Maxk"
   },
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xhyffrzHMeaI"
   },
   "source": [
    "A fines de elaboraci√≥n, configuramos qu√© queremos que se recalcule y qu√© queremos usar desde Drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4Yf4eJyrMZrF"
   },
   "outputs": [],
   "source": [
    "recalcular_descriptores_daisy = False\n",
    "guardar_descriptores_daisy = False\n",
    "recalcular_descriptores_sift = False\n",
    "guardar_descriptores_sift = False\n",
    "\n",
    "recalcular_pipeline = False\n",
    "recalcular_test = True\n",
    "recalcular_mejores = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZM1ASQ3EMzXp"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lE54owhHuXFi",
    "outputId": "69a78c8e-4e42-4dec-f1b7-3f703e4b3314"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.feature import SIFT\n",
    "from skimage.feature import daisy\n",
    "from skimage.transform import resize\n",
    "\n",
    "\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import time\n",
    "import glob\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import math\n",
    "import random\n",
    "\n",
    "import pickle\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuraci√≥n para gr√°ficos\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "print(\"‚úÖ Librer√≠as importadas correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IdZTwNe1-XUy"
   },
   "source": [
    "### ***UTIL***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AG_uJzY4-Wfi"
   },
   "outputs": [],
   "source": [
    "def indicesDeCategoriaEnLista(etiquetas, categoria):\n",
    "  \"\"\"Devuelve los indices donde la etiqueta sea igual que la categoria\"\"\"\n",
    "  return [j for j, etiq in enumerate(etiquetas) if etiq == categoria]\n",
    "\n",
    "def indexadoIndirecto(idx, lista_indices, lista_principal):\n",
    "  \"\"\"Devuelve el resultado de indexar indirectamente una lista\"\"\"\n",
    "  return lista_principal[lista_indices[idx]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ONFwxkt5FiL5"
   },
   "source": [
    "### ***1. Carga y Exploraci√≥n del Dataset***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v5uyKcQO4rVb"
   },
   "source": [
    "**Uso del Drive**\n",
    "\n",
    "Al tratarse de un dataset con tantos elementos, recomendamos utilizar el dataset directamente desde drive en vez de cargarlo cada vez que quieran trabajar con el. Intenten que todos los participantes del grupo lo tengan en el misma direccion para hacer mas fluido su trabajo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f0dHIdnRJm03"
   },
   "source": [
    "Data set: [Rock Paper Scissors](https://www.kaggle.com/datasets/drgfreeman/rockpaperscissors?select=scissors)\n",
    "\n",
    "Para los archivos .pkl: ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2DYwAXoTT10-",
    "outputId": "fbe3fd2e-7122-4fac-ef10-83d0700d9af1"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ouhzSGcC7r-T"
   },
   "outputs": [],
   "source": [
    "def pathDeArchivoPorCategoria(data_path, categoria):\n",
    "  \"\"\"\n",
    "  Devuelve la direccion de todos las imagenes en la carpeta de la categoria\n",
    "\n",
    "  Returns:\n",
    "    archivos: una lista con cada una de las direcciones de archivos.\n",
    "  \"\"\"\n",
    "\n",
    "  categoria_path = os.path.join(data_path, categoria)\n",
    "\n",
    "  archivos = glob.glob(os.path.join(categoria_path, \"*.jpg\")) + \\\n",
    "             glob.glob(os.path.join(categoria_path, \"*.jpeg\")) + \\\n",
    "             glob.glob(os.path.join(categoria_path, \"*.png\"))\n",
    "\n",
    "  return archivos\n",
    "\n",
    "def cargarImagenPorArchivo(archivo):\n",
    "  \"\"\"\n",
    "  Devuelve la imagen cargada en blanco y negro, habiendo sido reescalada si fuera necesario.\n",
    "\n",
    "  Returns:\n",
    "    img: La imgen cargada por Archivo.\n",
    "  \"\"\"\n",
    "\n",
    "  img = imread(archivo, as_gray=True)\n",
    "\n",
    "  # Redimensionar si es necesario (opcional)\n",
    "  if img.shape[0] > 400 or img.shape[1] > 400:\n",
    "    img = resize(img, (300, 300), anti_aliasing=True)\n",
    "\n",
    "  return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7rzFNceOHqJD"
   },
   "outputs": [],
   "source": [
    "def cargarDataSet(data_path, categorias):\n",
    "  \"\"\"\n",
    "  Carga todas las im√°genes del dataset organizadas por categor√≠a\n",
    "\n",
    "  Returns:\n",
    "    imagenes: lista de im√°genes en escala de grises\n",
    "    etiquetas: lista de etiquetas correspondientes\n",
    "    nombres_archivo: lista con nombres de archivos para referencia\n",
    "  \"\"\"\n",
    "\n",
    "  imagenes = []\n",
    "  etiquetas = []\n",
    "  nombres_archivo = []\n",
    "\n",
    "  print(f\"Cargando dataset desde: {data_path}\")\n",
    "\n",
    "  # Cargamos las imagenes de cada Categoria\n",
    "  for categoria in categorias:\n",
    "\n",
    "    archivos = pathDeArchivoPorCategoria(data_path, categoria)\n",
    "    archivos = archivos\n",
    "\n",
    "    print(f\"  {categoria}: {len(archivos)} im√°genes\")\n",
    "\n",
    "    for archivo in tqdm(archivos, desc=f\"Cargando {categoria}\"):\n",
    "\n",
    "      try:\n",
    "        img = cargarImagenPorArchivo(archivo)\n",
    "        imagenes.append(img)\n",
    "        etiquetas.append(categoria)\n",
    "        nombres_archivo.append(os.path.basename(archivo))\n",
    "\n",
    "      except Exception as e:\n",
    "        print(f\"Error cargando {archivo}: {e}\")\n",
    "\n",
    "  return imagenes, etiquetas, nombres_archivo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pfWKlbQV8I2k"
   },
   "source": [
    "***CARGA***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UmAutaM4w-9Y"
   },
   "source": [
    "### ADAPTAR CATEGORIAS, COLORES y PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "cc30a9566ce94590b84acf2d07a0baa6",
      "0809f9dbdd5147ba98f16b4e0022afd0",
      "dd74bf48283d47bd80778c4a4e8dbd74",
      "c5578032f16c4fca95cde683619c9a62",
      "5037ad16612f40f19b45025d4805c9eb",
      "f27adc22788c43f88e54223fdc47db61",
      "698aca425b314d2d956d67628179eecd",
      "98682a8932854bf9a0ddf46622f73b45",
      "99f78703f07d4f2683d086a08d5a33bd",
      "bfeda72fa59c44778472e57336a10d29",
      "462b02c290604ef89b6201716e809eb0",
      "f9032f5765cc4c8bae34cb0e07a67095",
      "a499b15c438440b49b16d172c6ca31f2",
      "09e4d42edb5840459e7e6e376b565750",
      "16b553d31efc41bd8ac260e81c5d6490",
      "9f1ad479e33245d8bc9f6df147d555c7",
      "62aec17acb194d0bae8f599d6f12718f",
      "6446dd3d6407420294026d43e99dbe5e",
      "acbbc6cd530e4341a9aebf4ef3b113c5",
      "4dbbd0d5fe5940caa8c4dac5cd0987bd",
      "9b58025d52f445cd92ce52c716c66b91",
      "1d8b75330a694f8cbd5ec51fb3c97d80",
      "786a2ef1b4cc4df19205d51ae676fd34",
      "ba3a82d66dd94137a257d165edfff249",
      "4d16c613354043f6909a0c0a53ec706d",
      "342dd910b5584678ac98384338dac02b",
      "a3273dfd6fa24191ba59cc3a809255ce",
      "c48be1bd51d442249ce794dbbd08ba92",
      "411c21d08ccc4bfbb8d2de94bc531676",
      "67545bf46a9a4ab781f052ed9d3d05d8",
      "34451ee58188413690cf0fbbc1d982f4",
      "8997de8f99f74ac68a02b6894e0bfa87",
      "039313e485534d3389812bcedf1c8133",
      "cf6f6f447de44ebd91dbfaae5b712ef3",
      "d171e61bcfd34322beb156795726ad6e",
      "a02b0216aa5848daa82a1669cd95f014",
      "b9a6bf834ac14c64a6a553f2d78dd5e1",
      "2ecfd2638a514ca09c3a0f601e24ac4e",
      "f0ad787ae884452f94b33242ebaef699",
      "fe86d3c755604c7696a6ae9ba7eec2ff",
      "b68c133538e64f519b9b8b466d08986a",
      "a217da57c65b454088291ec1fd9d04c8",
      "2049b65899fa426b80d5e328b8e846e6",
      "bdb4143e99de4f65a5bb36aad9632086",
      "badf2cc70f57400d81645e3ef930046c",
      "805dc709d09d4a28a91b55467be47348",
      "e8c049ccdfd14545b7fadcb74552791e",
      "7ac1e05b5f594ce6ab1768d7b1964b2c",
      "6d23da72ec6d4c1ebe517c2c70cf3b8d",
      "5cf656c013954633ba69632d5f624c4a",
      "e00340dfdf5847acbe514291a4b5c91a",
      "45d0b3912c484f6d825a771a7b6c3548",
      "ffdfac113f164c4fae16092a853372cf",
      "57cdd87927d44dc78634600c2f65ce09",
      "3ec49190b50d4b6dadad6b17010bc6e1",
      "b44af2ebc763462d911b037a2eee977d",
      "3acab2bfb98e43d6916f256e33017272",
      "d61f35eb414040ba8dd2a5252216c5de",
      "f43baf77dc0e4c2bb88ac1666d610efb",
      "55910c74abf04b36a2b58d56a3659456",
      "6abeac5832454f54a30945b21abd3b75",
      "d628621c423941f3955f2ade4bb9cceb",
      "f4a846fe547c4903b4bc539a3b130925",
      "8ffc1cb4b91e4f56b8d741cb7a5ebe5c",
      "5b1495d3f3224e2ab6cd4c521f589fef",
      "db36bdd4436040d4ae156db67c0ca87a",
      "15a661c31740463e8a72e726dcfcc406",
      "7f15f9bdb48a49d8b51b966283b6f09c",
      "6ff34a52f44e41fcac2446e7af88914a",
      "6b4d430e45974949914ee6674847879d",
      "62146fe52eba4895980423f322c1f2ac",
      "399daeb5ff604e47be273d5aee348ff2",
      "29bed6112cbb410ab90630d269f0db3f",
      "a8b48dfe825e4dcd884f7ad1a37525be",
      "df168da2c77d42a48510d30b93e0b3ed",
      "42c5fdbf607844599b12125ab805f97d",
      "6a575aecf64a49ce9f6909873deca256",
      "5671b0ec4ca44568a400a4afa3817e12",
      "3a6727e9fe334e34a7c63c40635cbcf4",
      "6cdbba6c5d8547a2894978029b33bb31",
      "36014aa576bf40219828fd548f660b70",
      "56f0b67e77504b67a05aceb4ac87b89a",
      "efef8c272d8144d980ca1a28e0a13a79",
      "e76fbd0393614d09947e4a423d9a05bf",
      "3c19090f33b64da19d666f620bc30a15",
      "7562bc4b621f40b09f6b0896a4d5d30a",
      "b8cd990c2aa14bdbb55df48538326deb",
      "3d8d9eb0540b4419bffcc046b0d4f463",
      "bb33c1210c4145c5af00db781fcbb44c",
      "a8500397354048e19e73c8d87548b533",
      "7b75f0c04cea4a44b7d7f5a485b0661e",
      "75a42d5d1c3645ffaa8e4f157b9a28a0",
      "d588e37ffaa2432a9402dd8c1b597c86",
      "93a7bf180920424b86d4abe5c5f19c0e",
      "54325abe631d43fd87cdbe1b3690d98d",
      "824d3129bb7a4d3a92e6fc9af94e2f74",
      "16f2078ea0f44a80976775b56b0dd747",
      "bd1c6a5ef9ce4dd2bef3180bdc71834e",
      "bcde9d1a993c47d6be586a9b8c593416",
      "9596c62019364cc9a3427dc6c8b58b83",
      "d745647ca6554c979dd5008a4f332961",
      "52ec1985473347b2b9272c009dda2b93",
      "a54f65569e9c40ddaa9476272862b61e",
      "36a780239cc845b0b34a84f627b1cc5e",
      "1e387227c3c648ba9d53e4c4fdd95dfd",
      "2dbab99f077a429d92a7869b9965cac6",
      "e54a957ff017431a95fa7816af9797cf",
      "8913b13ffa484341a3dbd2068379e269",
      "beb1e94b80734d2cab632d4bac205547",
      "0126a565ba0442dcabb5b41c55775eb0",
      "61e06131252943dc80371e4546e9c020",
      "c0e1f8574f6c494698e9e3434eef3a97",
      "700736e8fd094b54bfa54973fed543e2",
      "e6c388866f5e4eada75b1e71d244abf4",
      "52ed19b750434431bdc23cbe373f1738",
      "ebd8a01d06934e7aaf7cdcef618f5681",
      "ba8936a0e3df4123b854d3a76ca1df68",
      "a8d94eb30ad442e9a7cb067b869a880e",
      "a5c6c66801f640178f02a41ea4bcac29",
      "8dc7a75addc04c94b3f3bece28de66e9",
      "f2e7110a375e4ccb948fff6f7d6080e1",
      "e2f470a3ccb24ef2bf6fed2a7a1edaf9",
      "8949bc354df84e6b98af85ce4477fc97",
      "173cd282e77547ac9c3a28b716267399",
      "c4df709a1c7949b7bf662c52c9252851",
      "8e24c27d38bf4342bc1fb437c060e3d4",
      "7dd73f4d4e9043309f7652c1f7769da0",
      "60825205c1934bf7b047ca2b2a066c87",
      "0d0b62ee202a4d768551d99380dabf1e",
      "5116802ee6c6476c9ce443c66c3a83c2",
      "9fbb38b9514d43e9a958e57363c34535",
      "d297fa8490c14b4cb9e7e0da1a21a091",
      "4a50db08f4a0406dad0124bd0e409e11",
      "59e25030a04741caa14ecef5c109d585",
      "fbed0c81413345ea93dac48819f15b35",
      "e77e193e116f4bf9b09904dbaf6032f9",
      "8c2e228a327843adb95d7bdd28befc78",
      "20317480538a47999fee2d3012a40f71",
      "31e9ff1307a244b2818facd333f2f6ee",
      "16219a0e74484855b27ac73659e6d400",
      "29def3a38fc9423b99020358a865f2f5",
      "a14a7c258fad4f3bbf8a6b7a3cc77fc8",
      "408673b7be174ea0848cd5a6ee838c0a",
      "6cfacacace4b4fd8b6d9d88b360ca47c",
      "c4bcc467f4644b61ba1c2d93c02a2166",
      "837c27de932d4fa8affc4476c98cfa07",
      "a12e37c3d5c644f8a46b59f0b8ace995",
      "05f424a58f144b68a5e3d42d6a37a3a3",
      "c03a4f1b8b68426d8897298b1fae0bc6",
      "75a12e4ee7a040c8895671542bc8dd3e",
      "fc1e652d1da34eacb307fe9be12e3c1f",
      "e6d2a0aed4e4420a9d65ec1b2f97c495",
      "9d5efb1803934babbfcaa6c1ea96ab30",
      "281891e13eeb4933a720efd05b548a89",
      "2f256a20d2ac42099d94a82ff4231bf9",
      "ef6236b0b0d3448292ff2a5acb81fb48",
      "0d678e53dfd145f1911fdee116d4cac2",
      "df6b379a01b4482680e82bd1b5bdffe9",
      "a86b1dd9c00346cbb2741470555b6fd2",
      "9fa503db295249a4bfede71a9ccb7bf3",
      "d9029607954f4817a8b86e7fbc41b453",
      "8834d785b8fd43d3acea48906eecb826",
      "3cdee13cea274ec8bfedb8cfb2ad4cbd",
      "e3cafd518f8540c294a6b860b7fd7ee8",
      "d18334c188d24029be9aaef85a50236d",
      "03b16308bbc440ceb2519beb232f1c08",
      "31444eb58c1942e8b27776e148c6e3ee",
      "07cbb2a1c24c4b4aa2fd133dbe673f70",
      "ce65b1b3066e4c84aa5d7cd5afdeebd3",
      "b04f91ba588c45e98062a18117a59012",
      "aff38ba8914d4141b06917d0c3674c47",
      "4a12da886b8c428e86fea679e8bda75f",
      "99bee4773d5f4215812a2543ebafb3d7",
      "74a7c31f7ae6411795b0eab219ad05dc",
      "fd9a1821eb8e4164a991fdc225f2017a",
      "da591329fb9a452bbe204dfc7e8fd5af",
      "8939cc49bd5f4652a40da36f2eca796a",
      "6f1f354bfd39461f901e3c886ba36f4b",
      "13661bc4255d4c12b9c803eb3e2af249",
      "5aba2492208b4682b1b7c60f08571081",
      "e144dc74053d49cb82d3dded409f51ef",
      "e1ae2e01226748ada81ec175ef55d6da",
      "6c5f4451425e4e9eb81b1a30923bf48e",
      "2119be0643754b23b29a6641f4262f19",
      "5675a695b7f84fc8b3ab706a63d0df65",
      "427c04fc912c4f23b79307b936786f58",
      "9dc84710411a402db49c3121cdba1501",
      "a7551f24e029453d9255baf5f8990f72",
      "c51450c6eb1b4203bf0cc8cf14e5df1c",
      "32bed0a105954f5abf3f77382936be35",
      "08e1a26f64d7404d8cdba5fd5414ffbb",
      "91517b636f4e495e9bce2f69fe22e528",
      "918997f11eb04dcab61f8a0694498967",
      "f4e29d2e89e348e68c8915d4b41c03fe",
      "e11d3fbbfa99451f8a51836d08eb494e",
      "d7a345db54214834b35ff778ffa076d2",
      "f7b91e5dfdea4b50a90055e718b1ebd4",
      "3e45b886210f4a758f1bebb776aeab60",
      "7342582e8a1f4d84bfaaf0e9031c32bc",
      "71942881d6814966869f9216771476a3",
      "9189c28bb23140f3b4ceea910b946379",
      "e0d9273ab7b84f4d90a4abc79e79339f",
      "e760074871554970a9aefcc83c36fc10",
      "514933ed4f8e408fb097af22cb70255c",
      "a56c08d5f7c642309fe4d839e940b36b",
      "aa8033aade67440ab6587d0ebdb01a5d",
      "f7ceaf8a42934d7ca5741a452a61ecf5",
      "f573c17be1eb48c087d887b6ec0578c5",
      "8a9b9962ac38432b833cb87447563958",
      "37d4c6b808154086887ccb48d1a1165d",
      "f55d7fae8c6f4082bb50970325a76abc",
      "8a1405d4cb0a49328d689eb102192711",
      "324366f6a1b743cf96385a810b783e56",
      "981380ad3f7647df8353021a6b3b720c",
      "33bdd9cdd935456484ca02a744315a94",
      "64ffa6a6d8364136b3ce09b95eb22972",
      "9d4e07a5e43f4859b289857685a9616e",
      "043bac131d394d3b923499a1255f5e1b",
      "06ef647f6cd0452b9f03e74d8789b8d4",
      "615c1270211649ceb476e558eda1795d"
     ]
    },
    "id": "qJWXjZfZGDDq",
    "outputId": "56f219b2-3f6e-40b4-c5ed-f9dc91e5e4b8"
   },
   "outputs": [],
   "source": [
    "# Definir categor√≠as de especies\n",
    "CATEGORIAS = ['paper', 'rock', 'scissors']\n",
    "COLORES_CATEGORIAS = ['#9e0142', '#d53e4f', '#f46d43']\n",
    "\n",
    "# Paths del dataset\n",
    "DATA_PATH = \"dataset/\"\n",
    "TRAIN_PATH = os.path.join(DATA_PATH, \"train\")\n",
    "TEST_PATH = os.path.join(DATA_PATH, \"test\")\n",
    "\n",
    "# Cargar datasets de entrenamiento y prueba\n",
    "print(\"=\" * 50)\n",
    "print(\"CARGANDO DATASET DE ENTRENAMIENTO\")\n",
    "print(\"=\" * 50)\n",
    "imagenes_train, etiquetas_train, nombres_train = cargarDataSet(TRAIN_PATH, CATEGORIAS)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"CARGANDO DATASET DE PRUEBA\")\n",
    "print(\"=\" * 50)\n",
    "imagenes_test, etiquetas_test, nombres_test = cargarDataSet(TEST_PATH, CATEGORIAS)\n",
    "\n",
    "print(f\"\\nüìä RESUMEN DEL DATASET:\")\n",
    "print(f\"Training: {len(imagenes_train)} im√°genes\")\n",
    "print(f\"Testing: {len(imagenes_test)} im√°genes\")\n",
    "print(f\"Total: {len(imagenes_train) + len(imagenes_test)} im√°genes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gBo7kCmOxHzy"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wpTBy6pW81G7"
   },
   "source": [
    "***VISUALIZACION***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GNTBhEU9TsZE"
   },
   "outputs": [],
   "source": [
    "# Visualizaci√≥n de ejemplos del dataset\n",
    "def mostrarEjemplosDataSet(imagenes, etiquetas, categorias, n_ejemplos=2):\n",
    "  \"\"\"Muestra ejemplos de cada categor√≠a del dataset\"\"\"\n",
    "\n",
    "  fig, axes = plt.subplots(len(categorias), n_ejemplos, figsize=(15, 12))\n",
    "  fig.suptitle('Ejemplos del Dataset por Categor√≠a', fontsize=16, fontweight='bold')\n",
    "\n",
    "  for i, categoria in enumerate(categorias):\n",
    "    # Encontrar √≠ndices de esta categor√≠a\n",
    "    indices_categoria = indicesDeCategoriaEnLista(etiquetas, categoria)\n",
    "    random.shuffle(indices_categoria)\n",
    "\n",
    "    # Mostramos imagenes de Ejemplos por categoria\n",
    "    for j in range(n_ejemplos):\n",
    "\n",
    "        img = indexadoIndirecto(j, indices_categoria, imagenes)\n",
    "        axes[i, j].imshow(img, cmap='gray', clim=(0,1))\n",
    "        axes[i, j].set_title(f'{categoria}', fontweight='bold')\n",
    "        axes[i, j].axis('off')\n",
    "\n",
    "  plt.tight_layout()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "hMj-jye9Txl1",
    "outputId": "3a7b961e-de52-4f59-8cbc-d9e76fb782db"
   },
   "outputs": [],
   "source": [
    "mostrarEjemplosDataSet(imagenes_test, etiquetas_test, CATEGORIAS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jlQ_1Pt1FlkB"
   },
   "source": [
    "### ***2. Extracci√≥n de Caracter√≠sticas Daisy***\n",
    "Con las imagenes cargadas, empezaremos por extraer cada uno de sus keypoints y descriptores de Daisy correspondientes. Luego utilizaremos estos datos para crear nuestras palabras visuales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R-yRms4lWBEJ"
   },
   "outputs": [],
   "source": [
    "def extraerDaisyDataSet(imagenes, step = 16, image_index=0, **kwargs):\n",
    "    keypoints = []\n",
    "    descriptores = []\n",
    "    stats = {cat: {'total_keypoints': 0, 'promedio_keypoints': 0} for cat in CATEGORIAS}\n",
    "\n",
    "    for i, img in enumerate(imagenes):\n",
    "      if i == image_index:\n",
    "        desc, image_daisy = daisy(img, step=step, visualize=True, **kwargs)\n",
    "        plt.imsave('daisy_visualizacion.png', image_daisy, cmap='gray')\n",
    "      else:\n",
    "        desc = daisy(img, step = step , **kwargs)\n",
    "\n",
    "      desc_flat = desc.reshape(-1, desc.shape[-1]).astype(np.float32)\n",
    "      descriptores.append(desc_flat)\n",
    "\n",
    "      # Guardar los keypoints (coordenadas de la grilla)\n",
    "      x, y = np.meshgrid(np.arange(0, img.shape[1], step), np.arange(0, img.shape[0], step))\n",
    "      puntos = np.vstack([x.ravel(), y.ravel()]).T\n",
    "      keypoints.append(puntos)\n",
    "      # Estad√≠sticas\n",
    "\n",
    "      stats[CATEGORIAS[i % len(CATEGORIAS)]]['total_keypoints'] += len(desc_flat)\n",
    "    # Calcular promedios\n",
    "    for cat in CATEGORIAS:\n",
    "        stats[cat]['promedio_keypoints'] = stats[cat]['total_keypoints'] / max(1, sum([1 for e in imagenes if cat in str(e)]))\n",
    "    return keypoints, descriptores, stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nizj_eiHa6Dy",
    "outputId": "843e3ce7-f49f-4ff1-bb94-ce3d1c011715"
   },
   "outputs": [],
   "source": [
    "if recalcular_descriptores_daisy:\n",
    "\n",
    "  # Extraer Daisy del dataset de entrenamiento\n",
    "  print(\"\\n\" + \"=\" * 50)\n",
    "  print(\"EXTRACCI√ìN DE CARACTER√çSTICAS Daisy - TRAINING\")\n",
    "  print(\"=\" * 50)\n",
    "\n",
    "  keypoints_train_daisy, descriptores_train_daisy, stats_train_daisy = extraerDaisyDataSet(imagenes_train, step=45, image_index = 5, radius=30, rings=2, histograms=6, orientations=8)\n",
    "\n",
    "  if guardar_descriptores_daisy:\n",
    "    # Guardamos as√≠ no lo calculamos todo el tiempo\n",
    "    ruta = 'daisy_train.pkl'\n",
    "    with open(ruta, 'wb') as f:\n",
    "      pickle.dump((keypoints_train_daisy, descriptores_train_daisy, stats_train_daisy), f)\n",
    "\n",
    "  # Mostrar estad√≠sticas\n",
    "  print(\"\\nüìä ESTAD√çSTICAS DE EXTRACCI√ìN Daisy:\")\n",
    "  for categoria in CATEGORIAS:\n",
    "    total = stats_train_daisy[categoria]['total_keypoints']\n",
    "    promedio = stats_train_daisy[categoria]['promedio_keypoints'] # corregir promedio\n",
    "    print(f\"{categoria}: {total} keypoints total, {promedio:.1f} promedio por imagen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2NYLQIqnzNOn"
   },
   "outputs": [],
   "source": [
    "if not recalcular_descriptores_daisy:\n",
    "\n",
    "   # Cargar los resultados\n",
    "\n",
    "  ruta = 'daisy_train.pkl'\n",
    "\n",
    "  with open(ruta, 'rb') as f:\n",
    "    keypoints_train_daisy, descriptores_train_daisy, stats_train_daisy = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraerSIFTImagen(imagen):\n",
    "  \"\"\"\n",
    "  Extrae caracter√≠sticas SIFT de una imagen\n",
    "\n",
    "  Returns:\n",
    "    keypoints: coordenadas de los puntos clave\n",
    "    descriptores: descriptores SIFT (128 dimensiones cada uno)\n",
    "  \"\"\"\n",
    "\n",
    "  sift = SIFT()\n",
    "\n",
    "  sift.detect_and_extract(imagen)\n",
    "\n",
    "  return sift.keypoints, sift.descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraerSIFTDataSet(imagenes, etiquetas):\n",
    "  \"\"\"\n",
    "  Extrae SIFT de todo el dataset\n",
    "\n",
    "  Returns:\n",
    "    keypoints_dataset: lista de keypoints por imagen\n",
    "    descriptores_dataset: lista de descriptores por imagen\n",
    "    estadisticas: diccionario con estad√≠sticas de extracci√≥n\n",
    "  \"\"\"\n",
    "\n",
    "  keypoints_dataset = []\n",
    "  descriptores_dataset = []\n",
    "\n",
    "  # Estad√≠sticas por categor√≠a\n",
    "  stats = {cat: {'total_keypoints': 0, 'num_images': 0} for cat in CATEGORIAS}\n",
    "\n",
    "  print(\"Extrayendo caracter√≠sticas SIFT...\")\n",
    "\n",
    "  # i: indice | img: imagen correspondiente | etiqueta: etiqueta correspondiente\n",
    "  for i, (img, etiqueta) in enumerate(tqdm(zip(imagenes, etiquetas), total=len(imagenes))):\n",
    "\n",
    "    keypoints, descriptores = extraerSIFTImagen(img)\n",
    "\n",
    "    keypoints_dataset.append(keypoints)\n",
    "    descriptores_dataset.append(descriptores)\n",
    "\n",
    "    # Actualizar estad√≠sticas\n",
    "    stats[etiqueta]['total_keypoints'] += len(keypoints)\n",
    "    stats[etiqueta]['num_images'] += 1\n",
    "\n",
    "  # Calcular promedios\n",
    "  for categoria in stats:\n",
    "    if stats[categoria]['num_images'] > 0:\n",
    "      stats[categoria]['promedio_keypoints'] = stats[categoria]['total_keypoints'] / stats[categoria]['num_images']\n",
    "\n",
    "  return keypoints_dataset, descriptores_dataset, stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if recalcular_descriptores_sift:\n",
    "\n",
    "  # Extraer Daisy del dataset de entrenamiento\n",
    "  print(\"\\n\" + \"=\" * 50)\n",
    "  print(\"EXTRACCI√ìN DE CARACTER√çSTICAS Sift - TRAINING\")\n",
    "  print(\"=\" * 50)\n",
    "\n",
    "  keypoints_train_sift, descriptores_train_sift, stats_train_sift = extraerSIFTDataSet(imagenes_train, etiquetas_train)\n",
    "\n",
    "  if guardar_descriptores_daisy:\n",
    "    # Guardamos as√≠ no lo calculamos todo el tiempo\n",
    "    ruta = 'sift_train.pkl'\n",
    "    with open(ruta, 'wb') as f:\n",
    "      pickle.dump((keypoints_train_sift, descriptores_train_sift, stats_train_sift), f)\n",
    "\n",
    "  # Mostrar estad√≠sticas\n",
    "  print(\"\\nüìä ESTAD√çSTICAS DE EXTRACCI√ìN Sift:\")\n",
    "  for categoria in CATEGORIAS:\n",
    "    total = stats_train_sift[categoria]['total_keypoints']\n",
    "    promedio = stats_train_sift[categoria]['promedio_keypoints'] # corregir promedio\n",
    "    print(f\"{categoria}: {total} keypoints total, {promedio:.1f} promedio por imagen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not recalcular_descriptores_sift:\n",
    "\n",
    "   # Cargar los resultados\n",
    "\n",
    "   ruta = 'sift_train.pkl'\n",
    "\n",
    "   with open(ruta, 'rb') as f:\n",
    "     keypoints_train_sift, descriptores_train_sift, stats_train_sift = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tD0qb7K4FCB9"
   },
   "source": [
    "***VISUALIZACION***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364
    },
    "collapsed": true,
    "id": "B4WNAXv0GE98",
    "outputId": "69a52396-9a85-4981-8eb2-a727400032f5"
   },
   "outputs": [],
   "source": [
    "# Visualizar keypoints en ejemplos\n",
    "def mostrar_keypoints_ejemplos(imagenes, keypoints, etiquetas, categorias):\n",
    "  \"\"\"Muestra keypoints detectados en ejemplos de cada categor√≠a\"\"\"\n",
    "\n",
    "  fig, axes = plt.subplots(2, len(categorias), figsize=(20, 10))\n",
    "  fig.suptitle('Keypoints Daisy detectados por categor√≠a', fontsize=16, fontweight='bold')\n",
    "\n",
    "  for i, categoria in enumerate(categorias):\n",
    "    indices_categoria = indicesDeCategoriaEnLista(etiquetas, categoria)\n",
    "    random.shuffle(indices_categoria)\n",
    "\n",
    "    for row in range(2):\n",
    "      img = indexadoIndirecto(row, indices_categoria, imagenes)\n",
    "      kp = indexadoIndirecto(row, indices_categoria, keypoints)\n",
    "\n",
    "      # Imagen original\n",
    "      axes[row, i].imshow(img, cmap='gray')\n",
    "\n",
    "      # Keypoints\n",
    "      axes[row, i].scatter(kp[:, 0], kp[:, 1], s=10, c='red', alpha=0.7)\n",
    "\n",
    "      axes[row, i].set_title(f'{categoria} ({len(kp)} keypoints)')\n",
    "      axes[row, i].axis('off')\n",
    "\n",
    "  plt.tight_layout()\n",
    "  plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"VISUALIZACI√ìN DE KEYPOINTS\")\n",
    "print(\"=\" * 50)\n",
    "mostrar_keypoints_ejemplos(imagenes_train, keypoints_train_daisy, etiquetas_train, CATEGORIAS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E5NzUbK8zsX8"
   },
   "source": [
    "### ***3. Cross Validation***\n",
    "\n",
    "Para poder encontrar los mejores parametros a usar en el categorizador sin caer en la trampa de **sobreajustarse a los datos de test**, utilizaremos la tecnica de **Cross Validation**.\n",
    "\n",
    "Dividiremos nuestro set de entrenamiento en 5 subsets balanceados en categoria y aleatorios. Por cada uno de los subsets, tomaremos el resto de los 4 para **entrenar un categorizador** utilizando los meta-parametros a testear (numero de clusters, batch size, etc) y los testearemos sobre el subset apartado.\n",
    "\n",
    "Por ultimo, utilizaremos la combinacion de meta-parametros que mejor accuracy hayan conseguido en **promedio**.\n",
    "\n",
    "Con esta tecnica aumentamos las chances de generalizar sin tener que aumentar los datos de entrenamiento, ya que estariamos eligiendo los parametros que mayor capacidad de generalizacion obtuvieron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2QrhgLZczsX8"
   },
   "outputs": [],
   "source": [
    "def getPorcionDeSubset(lista, indices_cat, cat_subset_inicio, cat_subset_fin):\n",
    "  \"\"\"\n",
    "    Devuelve una sublista del arreglo original siendo indexada indirectamente\n",
    "    por un arreglo con los indices de una categoria en especifico\n",
    "  \"\"\"\n",
    "\n",
    "  return [indexadoIndirecto(idx, indices_cat, lista) for idx in range(cat_subset_inicio, cat_subset_fin)]\n",
    "\n",
    "def crearSubsets(imagenes, etiquetas, nombres, keypoints, descriptores, n_subsets=5):\n",
    "  \"\"\"Devuelve una lista con los subsets creados al dividir el dataset de entrenamiento original\"\"\"\n",
    "\n",
    "  # Encontramos los indices que le pertenecen a cada categoria (3\n",
    "  # Encontramos cuantos item de cada categoria deberia haber por subset\n",
    "  indices_categorias = {cat: indicesDeCategoriaEnLista(etiquetas,cat) for cat in CATEGORIAS}\n",
    "  categoria_por_subset = {cat: math.ceil(len(indices_categorias[cat]) / n_subsets) for cat in CATEGORIAS}\n",
    "\n",
    "  # Reordenamos los indices de las categorias de forma aleatoria\n",
    "  for cat in CATEGORIAS:\n",
    "    random.shuffle(indices_categorias[cat])\n",
    "\n",
    "  subsets = []\n",
    "\n",
    "  for subset_index in range(n_subsets):\n",
    "    subset = {\n",
    "        'imagenes': [],\n",
    "        'etiquetas': [],\n",
    "        'nombres': [],\n",
    "        'keypoints': [],\n",
    "        'descriptores': [],\n",
    "        'stats': {cat: {'num_images': 0} for cat in CATEGORIAS}\n",
    "      }\n",
    "\n",
    "    for cat in CATEGORIAS:\n",
    "\n",
    "      cat_indices = indices_categorias[cat]\n",
    "      cat_subset_inicio = subset_index * categoria_por_subset[cat]\n",
    "      cat_subset_fin = min(cat_subset_inicio + categoria_por_subset[cat], len(indices_categorias[cat]))\n",
    "\n",
    "      cat_etiquetas = getPorcionDeSubset(etiquetas, cat_indices, cat_subset_inicio, cat_subset_fin)\n",
    "      cat_descriptores = getPorcionDeSubset(descriptores, cat_indices, cat_subset_inicio, cat_subset_fin)\n",
    "      cat_nombres = getPorcionDeSubset(nombres, cat_indices, cat_subset_inicio, cat_subset_fin)\n",
    "      cat_imagenes = getPorcionDeSubset(imagenes, cat_indices, cat_subset_inicio, cat_subset_fin)\n",
    "      cat_keypoints = getPorcionDeSubset(keypoints, cat_indices, cat_subset_inicio, cat_subset_fin)\n",
    "\n",
    "      subset['etiquetas'] += (cat_etiquetas)\n",
    "      subset['nombres'] += (cat_nombres)\n",
    "      subset['descriptores']+=(cat_descriptores)\n",
    "      subset['imagenes']+=(cat_imagenes)\n",
    "      subset['keypoints']+=(cat_keypoints)\n",
    "\n",
    "      subset['stats'][cat]['num_images'] = len(cat_imagenes)\n",
    "\n",
    "    subsets.append(subset)\n",
    "\n",
    "  return subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m4mu2UhazsX9",
    "outputId": "17c14bf5-21ef-4a87-82d6-c23c6a07b30f"
   },
   "outputs": [],
   "source": [
    "subsets_daisy = crearSubsets(imagenes_train, etiquetas_train, nombres_train, keypoints_train_daisy, descriptores_train_daisy)\n",
    "subsets_sift = crearSubsets(imagenes_train, etiquetas_train, nombres_train, keypoints_train_sift, descriptores_train_sift)\n",
    "\n",
    "for i in range(len(subsets_daisy)):\n",
    "    subset = subsets_daisy[i]\n",
    "\n",
    "    print(f\"Subset {i}\")\n",
    "    print(f\"Imagenes Totales: {len(subset['etiquetas'])}\")\n",
    "\n",
    "    for categoria in CATEGORIAS:\n",
    "      print(f\"\\t{categoria}: {subset['stats'][categoria]['num_images']} imagenes\")\n",
    "\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1TvXuV2qzsX9"
   },
   "outputs": [],
   "source": [
    "def imagenesDeEjemploSubSet(subset, n_ejemplos=4):\n",
    "  \"\"\"Muestra ejemplos de cada categor√≠a del subset\"\"\"\n",
    "\n",
    "  fig, axes = plt.subplots(len(CATEGORIAS), n_ejemplos, figsize=(15, 12))\n",
    "  fig.suptitle('Ejemplos del Sub Dataset por Categor√≠a', fontsize=16, fontweight='bold')\n",
    "\n",
    "  for i, categoria in enumerate(CATEGORIAS):\n",
    "    # Encontrar √≠ndices de esta categor√≠a\n",
    "    indices_categoria = indicesDeCategoriaEnLista(subset['etiquetas'], categoria)\n",
    "    random.shuffle(indices_categoria)\n",
    "\n",
    "    # Mostramos imagenes de Ejemplos por categoria\n",
    "    for j in range(n_ejemplos):\n",
    "\n",
    "        img = indexadoIndirecto(j, indices_categoria, subset['imagenes'])\n",
    "        axes[i, j].imshow(img, cmap='gray', clim=(0,1))\n",
    "        axes[i, j].set_title(f'{categoria}', fontweight='bold')\n",
    "        axes[i, j].axis('off')\n",
    "\n",
    "  plt.tight_layout()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 803
    },
    "collapsed": true,
    "id": "tQsmqgekzsX9",
    "outputId": "e806d804-9019-49cf-9c93-2e66999e3ed5"
   },
   "outputs": [],
   "source": [
    "imagenesDeEjemploSubSet(subsets_daisy[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TT-j_d5TzsX9"
   },
   "outputs": [],
   "source": [
    "def unirSubsets(subsets):\n",
    "  \"\"\"Devuelve un subset conformado por la union de los subset en la lista\"\"\"\n",
    "\n",
    "  subset_union = {\n",
    "        'imagenes': [],\n",
    "        'etiquetas': [],\n",
    "        'nombres': [],\n",
    "        'keypoints': [],\n",
    "        'descriptores': [],\n",
    "        'stats': {cat: {'num_images': 0} for cat in CATEGORIAS}\n",
    "      }\n",
    "\n",
    "  for subset in subsets:\n",
    "\n",
    "    subset_union['etiquetas'] += subset['etiquetas']\n",
    "    subset_union['nombres']+= subset['nombres']\n",
    "    subset_union['descriptores']+= subset['descriptores']\n",
    "    subset_union['imagenes']+= subset['imagenes']\n",
    "    subset_union['keypoints']+= subset['keypoints']\n",
    "\n",
    "    for cat in CATEGORIAS:\n",
    "      subset_union['stats'][cat]['num_images'] += len(subset['etiquetas'])\n",
    "\n",
    "  return subset_union\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZdrKNAG0Fr9C"
   },
   "source": [
    "### ***4. Creaci√≥n del Vocabulario Visual***\n",
    "\n",
    "Ya teniendo los descriptores, podemos clasificarlos para comprender que keypoints eran similares a traves de las imagenes y empezar a hablar sobre el contenido de ellas.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "***Construccion de Vocabulario Visual*** ‚û°Ô∏è *Representacion BOW* ‚û°Ô∏è *Procesamiento de la Representacion* ‚û°Ô∏è *Entrenamiento de Categorizador* ‚û°Ô∏è *Validacion*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eO1OjqnVmdPB"
   },
   "outputs": [],
   "source": [
    "# Crear matriz global de descriptores para clustering\n",
    "def crearMatrizDescriptores(descriptores_dataset):\n",
    "    \"\"\"\n",
    "    Combina todos los descriptores en una matriz global para poder realizar clustering\n",
    "    Donde cada fila es un descriptor\n",
    "    \"\"\"\n",
    "    matriz_descriptores = []\n",
    "\n",
    "    for descriptores_imagen in descriptores_dataset:\n",
    "      matriz_descriptores.append(descriptores_imagen)\n",
    "\n",
    "    matriz_descriptores = np.vstack(matriz_descriptores)\n",
    "\n",
    "    return matriz_descriptores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XnZOssGkmA4N"
   },
   "outputs": [],
   "source": [
    "def construirVocabularioAgglomerativeClustering(descriptores, n_clusters=100, metric='euclidean', linkage='ward'):\n",
    "    \"\"\"\n",
    "    Construye vocabulario visual usando Agglomerative Clustering.\n",
    "\n",
    "    Returns:\n",
    "        modelo: objeto con labels y centroides de los clusters\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"Construyendo vocabulario con Agglomerative Clustering (n_clusters={n_clusters})...\")\n",
    "    modelo = AgglomerativeClustering(n_clusters=n_clusters, linkage=linkage)\n",
    "    labels = modelo.fit_predict(descriptores)\n",
    "\n",
    "\n",
    "    centroides = np.zeros((n_clusters, descriptores.shape[1]), dtype=np.float32)\n",
    "    for i in range(n_clusters):\n",
    "        grupo = descriptores[labels == i]\n",
    "        if len(grupo) > 0:\n",
    "            centroides[i] = grupo.mean(axis=0).astype(np.float32)\n",
    "\n",
    "    return {\"modelo\": modelo, \"centroides\": centroides}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construirVocabularioMiniBatchKMeans(descriptores, k=200, batch_size=1024, random_state=42):\n",
    "  \"\"\"\n",
    "  Construye vocabulario visual usando K-means\n",
    "\n",
    "  Args:\n",
    "    descriptores: matriz de descriptores\n",
    "    k: n√∫mero de clusters (palabras visuales)\n",
    "    batch_size: Cantidad de keypoints aleatorios que utilizara para encontrar los clusters (chico para hacer pruebas, luego incrementar)\n",
    "    random_state: semilla para reproducibilidad\n",
    "\n",
    "  Returns:\n",
    "    kmeans: Categorizador K-Means entrenado para categorizar los descriptores a su centroido mas cercano\n",
    "  \"\"\"\n",
    "  print(f\"Construyendo vocabulario con k={k} palabras visuales...\")\n",
    "\n",
    "  kmeans = MiniBatchKMeans(\n",
    "      n_clusters=k,\n",
    "      random_state=random_state,\n",
    "      batch_size=batch_size,\n",
    "      max_iter=300,\n",
    "      n_init=5,\n",
    "      verbose=0\n",
    "      )\n",
    "\n",
    "  kmeans.fit(descriptores)\n",
    "\n",
    "  return kmeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WXS34Uq1FyRE"
   },
   "source": [
    "### ***5. Representaci√≥n Bag of Words***\n",
    "Ya teniendo nuestro corpus o palabras visuales, podremos empezar a re-describir nuestras imagenes segun este. Gracias a esto podemos \"hablar\" de todas nuestras imagenes en el mismo \"lenguaje\", el nuevo descriptor.\n",
    "\n",
    "Para la descripcion de una imagen utilizaremos la frecuencia de cada palabra en el vocabulario.\n",
    "\n",
    "---\n",
    "\n",
    "*Construccion de Vocabulario Visual* ‚û°Ô∏è ***Representacion BOW*** ‚û°Ô∏è *Procesamiento de la Representacion* ‚û°Ô∏è *Entrenamiento de Categorizador* ‚û°Ô∏è *Validacion*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oQZy1cjV6KCA"
   },
   "source": [
    "### FALTA OBTENER n_clusters A PARTIR DEL MODELO ENTRENADO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5mbhfWW7nc5A"
   },
   "outputs": [],
   "source": [
    "def descriptoresABOWAgglomerativeClustering(descriptores_imagen, vocabulario):\n",
    "    \"\"\"\n",
    "    Convierte descriptores de una imagen a representaci√≥n BoW\n",
    "\n",
    "    Args:\n",
    "        descriptores_imagen: np.array de descriptores Daisy de una imagen\n",
    "        vocabulario: modelo Agglomerative Clustering entrenado (modelo del vocabulario visual)\n",
    "\n",
    "    Returns:\n",
    "        histograma: vector de frecuencias de palabras visuales (BoW)\n",
    "    \"\"\"\n",
    "    centroides = vocabulario[\"centroides\"].astype(np.float32)\n",
    "\n",
    "    # Calcular distancias de cada descriptor al centroide m√°s cercano\n",
    "    distancias = cdist(descriptores_imagen, centroides, metric='euclidean').astype(np.float32) # (n_descriptores, n_clusters)\n",
    "\n",
    "    # Asignar cada descriptor al centroide m√°s cercano (palabra visual)\n",
    "    asignaciones = np.argmin(distancias, axis=1)\n",
    "\n",
    "    # Construir histograma de frecuencias de palabras visuales\n",
    "    histograma, _ = np.histogram(asignaciones, bins=np.arange(len(centroides) + 1))\n",
    "\n",
    "    return histograma.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def descriptoresABOWMiniBatchKMeans(descriptores_imagen, vocabulario):\n",
    "    \"\"\"\n",
    "    Convierte descriptores de una imagen a representaci√≥n BoW\n",
    "\n",
    "    Args:\n",
    "        descriptores_imagen: np.array de descriptores SIFT de una imagen\n",
    "        vocabulario: objeto MiniBatchKMeans entrenado (modelo del vocabulario visual)\n",
    "\n",
    "    Returns:\n",
    "        histograma: vector de frecuencias de palabras visuales (BoW)\n",
    "    \"\"\"\n",
    "    n_clusters = vocabulario.n_clusters\n",
    "\n",
    "    # Asignar cada descriptor al centroide m√°s cercano (palabra visual)\n",
    "    asignaciones = vocabulario.predict(descriptores_imagen) #COMPLETAR ...\n",
    "\n",
    "    # Construir histograma de frecuencias de palabras visuales\n",
    "    histograma, _ = np.histogram(asignaciones, bins=np.arange(n_clusters + 1)) #COMPLETAR ...\n",
    "\n",
    "    return histograma.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D7ThfTFInjVW"
   },
   "outputs": [],
   "source": [
    "def crearMatrizBOW(descriptores_dataset, vocabulario, clustering=None):\n",
    "    \"\"\"\n",
    "    Crea matriz BoW para todo el dataset\n",
    "    Donde Cada fila es la frecuencia del vocabulario en una imagen\n",
    "    \"\"\"\n",
    "    matriz_bow = []\n",
    "\n",
    "    print(\"Creando representaciones BoW...\")\n",
    "\n",
    "    for descriptores_imagen in tqdm(descriptores_dataset):\n",
    "      if clustering == \"agglomerative_clustering\":\n",
    "        bow = descriptoresABOWAgglomerativeClustering(descriptores_imagen, vocabulario)\n",
    "      else:\n",
    "        bow = descriptoresABOWMiniBatchKMeans(descriptores_imagen, vocabulario)\n",
    "      matriz_bow.append(bow.astype(np.float32))\n",
    "      del bow\n",
    "\n",
    "    return np.array(matriz_bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2jR00-SJWWVy"
   },
   "source": [
    "### ***6. TF-IDF***\n",
    "Con la Matriz de Representacion de Bag Of Words creada, podemos empezar a transformarla para intentar conseguir un mejor puntaje de forma barata. Una de nuestras opciones es aplicarle **TF-IDF**, presentado en la clase practica, con la intencion de darle mas importancia a las palabras visuales menos frecuentes y bajar el impacto de palabras comunes que no aportan informacion. Si pensamos en una analogia con texto, seria el equivalente de \"bajarle el precio\" a conectores, pronombres, articulos y etc.\n",
    "\n",
    "$$\n",
    "\\text{Tf-idf}_{t,d} = \\text{tf}_{t,d} ‚ãÖ log(\\frac{N}{\\text{df}_t})\n",
    "$$\n",
    "\n",
    "donde\n",
    "- $\\text{Tf-idf}_{t,d}$ sera el nuevo valor de la palabra $t$ para la imagen $d$\n",
    "- $\\text{tf}_{t,d}$ era la frecuencia de la palabra $t$ para la imagen $d$\n",
    "- $N$ es la cantidad de imagenes totales\n",
    "- $\\text{df}_t$ es la cantidad de imagenes en la que la palabra $t$ aparece al menos una vez.\n",
    "\n",
    "---\n",
    "\n",
    "*Construccion de Vocabulario Visual* ‚û°Ô∏è *Representacion BOW* ‚û°Ô∏è ***Procesamiento de la Representacion*** ‚û°Ô∏è *Entrenamiento de Categorizador* ‚û°Ô∏è *Validacion*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8T5EH0POZJnc"
   },
   "outputs": [],
   "source": [
    "def aplicar_tfidf(matriz_bow):\n",
    "  \"\"\"\n",
    "  Aplica transformaci√≥n TF-IDF a matriz de frecuencias\n",
    "\n",
    "  Args:\n",
    "    matriz_bow: matriz de frecuencias (n_images x n_words)\n",
    "\n",
    "  Returns:\n",
    "    matriz_tfidf: matriz con pesos TF-IDF\n",
    "  \"\"\"\n",
    "\n",
    "  matriz_tfidf = matriz_bow.copy()\n",
    "\n",
    "  n, m = matriz_bow.shape\n",
    "\n",
    "  df = np.count_nonzero(matriz_bow>0, axis=0)\n",
    "\n",
    "  df[df==0] = 1\n",
    "\n",
    "  idf = np.log(n / df)\n",
    "\n",
    "  matriz_tfidf = matriz_tfidf * idf\n",
    "\n",
    "\n",
    "  return matriz_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9QfjWjr0F4td"
   },
   "source": [
    "### ***7. Entrenamiento de un Clasificador***\n",
    "\n",
    "Ya habiendo aplicado todo el **post-procesamiento** que quisieramos a nuestra aplicacion, solo nos queda usarla para entrenar un **Categorizador de Escenas** que luego utilizaremos para hacer predicciones con imagenes entrantes nuevas.\n",
    "\n",
    "En este caso usaremos una **SVC** por su flexibilidad y por ya haber sido presentada en la Tarea anterior. Recordemos que una **SVC** encuentra los mejores Hiper Planos para separar los puntos de cada categoria, dejandonos aplicarle una **transformacion a los datos de entradas a un espacio de dimensionalidad mayor** si nos es necesario para encontrar hiperplanos validos.\n",
    "\n",
    "---\n",
    "\n",
    "*Construccion de Vocabulario Visual* ‚û°Ô∏è *Representacion BOW* ‚û°Ô∏è *Procesamiento de la Representacion* ‚û°Ô∏è ***Entrenamiento de Categorizador*** ‚û°Ô∏è *Validacion*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uoN2Uv1vM3XH"
   },
   "outputs": [],
   "source": [
    "def entrenar_svm(descriptores_train, etiquetas_train):\n",
    "    \"\"\"\n",
    "    Entrena un clasificador SVM\n",
    "\n",
    "    Returns:\n",
    "        clf: pipeline con SVC\n",
    "    \"\"\"\n",
    "\n",
    "    # make_pipeline les permite crear un pipeline sobre el propio categorizador SVC\n",
    "    # por si quieren hacer un procesamiento mas general de los datos antes de enviarlos a la SVC\n",
    "    clf = make_pipeline(SVC(kernel='linear', probability=True))\n",
    "    clf.fit(descriptores_train, etiquetas_train)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yE8NFiovkB_c"
   },
   "source": [
    "### ***8. Validacion***\n",
    "\n",
    "Con nuestro Clasificador entrenado, solo queda probarlo con los datos de validacion. Para esto tendremos que representar nuestras imagenes de validacion utilizando el vocabulario y las transformaciones de post-procesamiento con las que se entreno la SVM.\n",
    "\n",
    "Luego podremos analizar con mas detalles que puntos debiles tiene nuestro clasificador, por ejemplo, cuales son las categorias que mas se confunde entre si.\n",
    "\n",
    "---\n",
    "\n",
    "*Construccion de Vocabulario Visual* ‚û°Ô∏è *Representacion BOW* ‚û°Ô∏è *Procesamiento de la Representacion* ‚û°Ô∏è *Entrenamiento de Categorizador* ‚û°Ô∏è ***Validacion***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H99sr8oab90L"
   },
   "outputs": [],
   "source": [
    "def evaluar_clasificador_svm(clasificador, descriptores_bow_test, etiquetas_test, nombre_experimento=\"\"):\n",
    "  \"\"\"\n",
    "  Eval√∫a el clasificador SVM\n",
    "  Args:\n",
    "    clasificador: Clasificador a Evaluar\n",
    "    descriptores_bow_test: Descriptores de BoW a categorizar\n",
    "    etiquetas_test: Ground Truth para cada descriptor\n",
    "    nombre_experimento: Nombre opcional a imprimr\n",
    "\n",
    "  Returns:\n",
    "    predicciones: Etiquetas predichas por el clasificador para cada muestra del conjunto de prueba.\n",
    "    confianzas: Probabilidad m√°s alta asignada por el modelo a la clase predicha para cada muestra (valor entre 0 y 1).\n",
    "    accuracy: Proporci√≥n de etiquetas correctamente clasificadas sobre el total de muestras: (n¬∞ aciertos) / (n¬∞ total).\n",
    "    precision: Para cada categor√≠a, proporci√≥n de verdaderos positivos entre todos los predichos como esa categor√≠a: TP / (TP + FP).\n",
    "    recall: Para cada categor√≠a, proporci√≥n de verdaderos positivos entre los casos reales de esa categor√≠a: TP / (TP + FN).\n",
    "    f1: Para cada categor√≠a, media arm√≥nica entre precisi√≥n y recall: 2 * (precision * recall) / (precision + recall).\n",
    "    support: N√∫mero real de muestras en cada categor√≠a dentro del conjunto de prueba (distribuci√≥n real por clase).\n",
    "    confusion_matrix: Matriz de Confusion\n",
    "  \"\"\"\n",
    "\n",
    "  print(f\"Evaluando clasificador: {nombre_experimento}\")\n",
    "\n",
    "  # Predicci√≥n\n",
    "  predicciones = clasificador.predict(descriptores_bow_test)\n",
    "\n",
    "  # Confianzas: tomamos la probabilidad de la clase predicha\n",
    "  confianzas_prob = clasificador.predict_proba(descriptores_bow_test)\n",
    "  confianzas = confianzas_prob.max(axis=1)\n",
    "\n",
    "  # M√©tricas\n",
    "  accuracy = accuracy_score(etiquetas_test, predicciones)\n",
    "\n",
    "  precision, recall, f1, support = precision_recall_fscore_support(\n",
    "      etiquetas_test, predicciones, average=None, labels=CATEGORIAS\n",
    "  )\n",
    "\n",
    "  # Creamos una Matriz de Confusion para ver en que categorias se confunde nuestro clasificador\n",
    "  cm = confusion_matrix(etiquetas_test, predicciones, labels=CATEGORIAS)\n",
    "\n",
    "  return {\n",
    "    'predicciones': predicciones,\n",
    "    'confianzas': confianzas,\n",
    "    'accuracy': accuracy,\n",
    "    'precision': precision,\n",
    "    'recall': recall,\n",
    "    'f1': f1,\n",
    "    'support': support,\n",
    "    'confusion_matrix': cm\n",
    "  }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H2x39LAOnAjo"
   },
   "source": [
    "### ***8 Bis. Analisis de Resultados***\n",
    "Ya teniendo una muestra de como funciona nuestro categorizador, analizemos en mas detalle su desempe√±o."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c_zeXOggn6bQ"
   },
   "source": [
    "#### **Funciones de Analisis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T4zU1jMSnk78"
   },
   "outputs": [],
   "source": [
    "def crearTablaResultados(resultados, ks=None, metodos=None):\n",
    "    \"\"\"\n",
    "    Crea tabla resumen con todos los resultados\n",
    "    resultados: dict {metodo: m√©tricas}\n",
    "    ks: dict opcional {metodo: valor_k}, si no se pasa, muestra '-'\n",
    "    metodos: lista opcional [(clave, titulo_legible)]\n",
    "    \"\"\"\n",
    "    if ks is None:\n",
    "        ks = {}\n",
    "\n",
    "    if metodos is None:\n",
    "        metodos = [(m, m) for m in resultados.keys()]\n",
    "\n",
    "    print(\"\\nüìä TABLA RESUMEN DE RESULTADOS\")\n",
    "    print(\"=\" * 90)\n",
    "    print(f\"{'Config':<35} {'Accuracy':<10} {'Precisi√≥n':<12} {'Recall':<10} {'F1-Score':<10}\")\n",
    "\n",
    "    for (metodo, titulo) in metodos:\n",
    "        res = resultados[metodo]\n",
    "        k_val = ks.get(metodo, '-')\n",
    "        config = f\"{titulo} (k={k_val})\"\n",
    "\n",
    "        acc = res['accuracy']\n",
    "        prec = np.mean(res['precision'])\n",
    "        rec = np.mean(res['recall'])\n",
    "        f1 = np.mean(res['f1'])\n",
    "\n",
    "        print(f\"{config:<35} {acc:<10.3f} {prec:<12.3f} {rec:<10.3f} {f1:<10.3f}\")\n",
    "\n",
    "    print(\"-\" * 90)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2Mr2ssgFnpGl"
   },
   "outputs": [],
   "source": [
    "def plotConfusionMatrices(resultados, k_valor, metodos):\n",
    "    \"\"\"Plotea matrices de confusi√≥n para un valor de k espec√≠fico\"\"\"\n",
    "\n",
    "    fig, axes = plt.subplots(1, len(metodos), figsize=(15, 6))\n",
    "    if len(metodos) == 1:\n",
    "        axes = [axes]\n",
    "    for i, (metodo, titulo) in enumerate(metodos):\n",
    "\n",
    "        cm = resultados[metodo]['confusion_matrix']\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                   xticklabels=[cat for cat in CATEGORIAS],\n",
    "                   yticklabels=[cat for cat in CATEGORIAS],\n",
    "                   ax=axes[i])\n",
    "\n",
    "        axes[i].set_title(f'{titulo} (k={k_valor})')\n",
    "        axes[i].set_xlabel('Predicci√≥n')\n",
    "        axes[i].set_ylabel('Verdadero')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FUnSGF1snwC_"
   },
   "outputs": [],
   "source": [
    "def analizar_errores(resultados, metodo, testing_set):\n",
    "  \"\"\"Devuelve los errores de clasificaci√≥n\"\"\"\n",
    "\n",
    "  resultado = resultados[metodo]\n",
    "  predicciones = resultado['predicciones']\n",
    "\n",
    "  etiquetas = testing_set['etiquetas']\n",
    "  imagenes = testing_set['imagenes']\n",
    "  nombres = testing_set['nombres']\n",
    "\n",
    "  # Encontrar errores\n",
    "  errores = []\n",
    "  for i, (real, pred) in enumerate(zip(etiquetas, predicciones)):\n",
    "    if real != pred:\n",
    "      errores.append({\n",
    "        'real': real,\n",
    "        'predicho': pred,\n",
    "        'imagen': imagenes[i],\n",
    "        'imagen_nombre': nombres[i],\n",
    "        'confianza': resultado['confianzas'][i]\n",
    "      })\n",
    "\n",
    "  return errores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mzDMR5dory63"
   },
   "outputs": [],
   "source": [
    "def imprimirErrores(errores, k, metodo, total, name=\"\"):\n",
    "  \"\"\"Imprime informacion sobre los errores\"\"\"\n",
    "  if not (k == None):\n",
    "    print(f\"\\nüîç AN√ÅLISIS DE ERRORES ({metodo.upper()}, {name.upper()}, k={k})\")\n",
    "  else:\n",
    "    print(f\"\\nüîç AN√ÅLISIS DE ERRORES ({metodo.upper()}, {name.upper()})\")\n",
    "\n",
    "  print(\"-\" * 50)\n",
    "  print(f\"Total de errores: {len(errores)} de {total} im√°genes\")\n",
    "  print(f\"Accuracy: {(total - len(errores))/total:.3f}\")\n",
    "\n",
    "\n",
    "\n",
    "  # An√°lisis de confusiones m√°s comunes\n",
    "  confusiones = {}\n",
    "  for error in errores:\n",
    "    par = (error['real'], error['predicho'])\n",
    "    if par not in confusiones:\n",
    "      confusiones[par] = []\n",
    "    confusiones[par].append(error)\n",
    "\n",
    "  print(f\"\\nüìä CONFUSIONES M√ÅS COMUNES:\")\n",
    "  for (real, pred), casos in sorted(confusiones.items(), key=lambda x: len(x[1]), reverse=True):\n",
    "    print(f\"  {real} ‚Üí {pred}: {len(casos)} casos\")\n",
    "\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cpLgrjx4n4ap"
   },
   "outputs": [],
   "source": [
    "def mostrarEjemplosErrores(errores, n_ejemplos=4, name=\"\"):\n",
    "    \"\"\"Muestra ejemplos visuales de errores de clasificaci√≥n en 2 columnas\"\"\"\n",
    "\n",
    "    if len(errores) == 0:\n",
    "        print(\"¬°No hay errores para mostrar!\")\n",
    "        return\n",
    "\n",
    "    n_mostrar = min(n_ejemplos, len(errores))\n",
    "    errores_sample = random.sample(errores, k=n_mostrar)\n",
    "\n",
    "    # Definir 2 columnas\n",
    "    cols = 2\n",
    "    rows = math.ceil(n_mostrar / cols)\n",
    "\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(10, 5 * rows))\n",
    "    axes = axes.flatten()  # Convertir a lista para indexar f√°cilmente\n",
    "\n",
    "    fig.suptitle('Ejemplos de Errores de Clasificaci√≥n', fontsize=16, fontweight='bold')\n",
    "\n",
    "    for i, error in enumerate(errores_sample):\n",
    "        axes[i].imshow(error['imagen'], cmap='gray', clim=(0,1))\n",
    "        axes[i].set_title(f'Real: {error[\"real\"].title()}\\nPredicho: {error[\"predicho\"].title()}')\n",
    "        axes[i].axis('off')\n",
    "\n",
    "    # Ocultar ejes sobrantes si hay menos im√°genes que subplots\n",
    "    for j in range(i+1, len(axes)):\n",
    "        axes[j].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Guardar en Drive\n",
    "    output_dir = '/content/drive/MyDrive/TP-Final/'\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    output_path = os.path.join(output_dir, f\"{name.replace(' ', '_')}.png\")\n",
    "    plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tqaK8ed_DXaE"
   },
   "source": [
    "## PIPELINE DUAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SadlXwPRDRs_"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def pipeline(\n",
    "    subsets,\n",
    "    crearMatrizDescriptores,\n",
    "    crearMatrizBOW,\n",
    "    aplicar_tfidf,\n",
    "    entrenar_svm,\n",
    "    evaluar_clasificador_svm,\n",
    "    n_clusters=0,\n",
    "    K=0,\n",
    "    batch_size=0,\n",
    "    clustering_method=None\n",
    "):\n",
    "\n",
    "    if (clustering_method not in [\"agglomerative_clustering\", \"minibatchkmeans\"]):\n",
    "      print(\"Clustering inv√°lido\")\n",
    "      return\n",
    "\n",
    "    usaKMeans = clustering_method == \"minibatchkmeans\"\n",
    "\n",
    "    resultados = []\n",
    "\n",
    "    n_folds = len(subsets)\n",
    "\n",
    "\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    if usaKMeans:\n",
    "       print(f\"Evaluando vocabulario con k={K} y batch_size={batch_size}\")\n",
    "    else:\n",
    "       print(f\"Evaluando vocabulario con {n_clusters} clusters...\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "\n",
    "    metrics_bow = []\n",
    "    metrics_tfidf = []\n",
    "    tiempos = []\n",
    "\n",
    "    for fold in range(n_folds):\n",
    "        print(f\"Fold {fold + 1}/{n_folds}\")\n",
    "\n",
    "        # Separo en subsets para cross validation\n",
    "        val_subset = subsets[fold]\n",
    "        train_subsets = [s for i, s in enumerate(subsets) if i != fold]\n",
    "        train_subset = unirSubsets(train_subsets)\n",
    "\n",
    "        print(\"Creo matriz de descriptores global\")\n",
    "\n",
    "        # 1. Creao matriz de descriptores global\n",
    "        descriptores = crearMatrizDescriptores(train_subset['descriptores'])\n",
    "\n",
    "        # 2. Entreno vocabulario\n",
    "\n",
    "        inicio = time.time()\n",
    "\n",
    "        descriptores_entrenamiento = np.vstack(train_subset['descriptores'])\n",
    "\n",
    "        print(\"Entreno vocabulario\")\n",
    "        if usaKMeans:\n",
    "          vocabulario = construirVocabularioMiniBatchKMeans(descriptores_entrenamiento, k=K, batch_size=batch_size)\n",
    "        else:\n",
    "          vocabulario = construirVocabularioAgglomerativeClustering(descriptores_entrenamiento, n_clusters)\n",
    "\n",
    "        fin = time.time()\n",
    "        tiempo_vocab = fin - inicio\n",
    "        tiempos.append(tiempo_vocab)\n",
    "\n",
    "        # 3. Representaciones BoW\n",
    "\n",
    "        print(\"Creo matriz BOW\")\n",
    "        X_train_bow = crearMatrizBOW(train_subset['descriptores'], vocabulario, clustering=clustering_method)\n",
    "        X_val_bow = crearMatrizBOW(val_subset['descriptores'], vocabulario, clustering=clustering_method)\n",
    "\n",
    "        # # 4. TF-IDF\n",
    "        X_train_tfidf = aplicar_tfidf(X_train_bow)\n",
    "        X_val_tfidf = aplicar_tfidf(X_val_bow)\n",
    "\n",
    "        # 5. Entrenar clasificadores\n",
    "\n",
    "        print(\"Entreno clasificador\")\n",
    "\n",
    "        clf_bow = entrenar_svm(X_train_bow, train_subset['etiquetas'])\n",
    "        clf_tfidf = entrenar_svm(X_train_tfidf, train_subset['etiquetas'])\n",
    "\n",
    "        # 6. Evaluo los clasificadores\n",
    "\n",
    "        print(\"Evaluo\")\n",
    "        resultado_bow = evaluar_clasificador_svm(\n",
    "            clf_bow, X_val_bow, val_subset['etiquetas'], f\"BoW fold {fold+1} (n_cluster={n_clusters})\"\n",
    "        )\n",
    "        resultado_tfidf = evaluar_clasificador_svm(\n",
    "            clf_tfidf, X_val_tfidf, val_subset['etiquetas'], f\"TF-IDF fold {fold+1} (n_cluster={n_clusters})\"\n",
    "        )\n",
    "\n",
    "        metrics_bow.append(resultado_bow)\n",
    "        metrics_tfidf.append(resultado_tfidf)\n",
    "\n",
    "    # Promedio m√©tricas por fold (accuracy, precision, recall, f1)\n",
    "    def promediar_metricas(lista_resultados):\n",
    "        return {\n",
    "            'accuracy': np.mean([r['accuracy'] for r in lista_resultados]),\n",
    "            'precision': np.mean([r['precision'] for r in lista_resultados], axis=0),\n",
    "            'recall': np.mean([r['recall'] for r in lista_resultados], axis=0),\n",
    "            'f1': np.mean([r['f1'] for r in lista_resultados], axis=0),\n",
    "            'support': np.sum([r['support'] for r in lista_resultados], axis=0),  # soporte se suma\n",
    "            'confusion_matrix': np.sum([r['confusion_matrix'] for r in lista_resultados], axis=0)\n",
    "        }\n",
    "\n",
    "    promedio_bow = promediar_metricas(metrics_bow)\n",
    "    promedio_tfidf = promediar_metricas(metrics_tfidf)\n",
    "\n",
    "    if usaKMeans:\n",
    "        res = {\n",
    "        'k' : K,\n",
    "        'batch_size' : batch_size,\n",
    "        'n_cluster' : n_clusters,\n",
    "        'tiempo_promedio_vocab': np.mean(tiempos),\n",
    "        'bow': promedio_bow,\n",
    "        'tfidf': promedio_tfidf\n",
    "        }\n",
    "\n",
    "    else:\n",
    "        res = {\n",
    "        'n_cluster' : n_clusters,\n",
    "        'tiempo_promedio_vocab': np.mean(tiempos),\n",
    "        'bow': promedio_bow,\n",
    "        'tfidf': promedio_tfidf\n",
    "        }\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "08c8c13bd2e846d39b29a479df82b3b9",
      "6f286fbce079411d82903e49f0cce0d8",
      "d616de610d2b4abb8be0ad9a09915590",
      "21bc7372455444db8e13035fb1768d56",
      "4d9c6e505dcb492aa0b0d6baee25b518",
      "69c6cab8f1424d94b6a3a295b1049045",
      "5a0651c1ad5c43dd83e68e6a1dda8744",
      "ea429c0e9fa04867bde6087a8ecf9ec0",
      "2463cebd30104f60b0bf45dfd9570a2f",
      "5dfd7efc277b474cb7c1de858baf0d95",
      "5654dccfc7bb4a75b0c046aa4ad83876",
      "800a780635e747618b76785883174805",
      "ad76db799a524fe7875aa6d698a62cf3",
      "df41f363c8434521b0d24b5ffb5cae7b",
      "5903072f9a0849acbf05f1ed6c242316",
      "5be40f40216b4c96ae8b66477ad3c5a8",
      "d64561f796e143ed8e90b622c12a7fb1",
      "5fcb88f777af48388e4642ee518bf4af",
      "bed19e8b2a0f443981029add0bd1e3f4",
      "534accc056b64169a7825ee3b819122f",
      "61856204190f49a1bdbb7824bbf5336c",
      "9ed5295756414dea8a635156e2b71476",
      "46e7ada498cb406981ef7f5822bf1fd0",
      "a3ae0adee968459da8526543521bc5e6",
      "03ddb358d91d42b7823e948e344feda4",
      "80e3e1e6ca174f199a53cdaa7426a857",
      "9c1a6d40c9a84934b2de1cac82ee6fe6",
      "18ca8e2279ab4aa3b2118c97e81e5814",
      "bede69a6310b4639ac68e49d19462566",
      "72520c05c00742f0a2c22673059611d4",
      "03475cbaad3840c9bc35dd8dba217e46",
      "4fddbd02057a48c0b8d48bbd509824eb",
      "c48500db85a1408e8c47b97c4f1bfe40",
      "2212d97175eb4b318c8a0083d4426165",
      "c7f172734d064b9480e22c2afb8310eb",
      "0508e331f07842c1a236df4fa403df84",
      "a5c69c76859a4d88b0445eca54d242e0",
      "60b68b8f35d14b73becc8755af7def5e",
      "70dae5b6b1d04e94a679e9f8e08ecd0d",
      "faad1ee1b5504de082353d8a556da25c",
      "5affeb32f4e248fcb7e7647e87e79134",
      "dc104ef74bf34fbfacb0c68e97a2a696",
      "20587c05495e433bbe8b291aad82b165",
      "742e1a27e9be41169548afc18a9ebecd",
      "ab0f627b720345d690082ac6ffb03f92",
      "8cbd17a97dd14c3cab28730c6ab337de",
      "ac1ff63c83fc4c5895e3f7954ac0ae54",
      "e3f85c708b9a4a7a845273a2a50303c4",
      "2b263afa1b82492baacf168fa8b4891e",
      "9be0783f9b41431b9cc53b0667543e9d",
      "8ec0c02682404b0c80b42ad721e77671",
      "8a3e84ed842847bb84b9c375683ab70c",
      "d3b0d42a82244caf912076f47faaf48e",
      "0a2a34a3727d490f863ecf4ad51f23ca",
      "3e7cb6dbfe5243788d38db2ba6edc9f3",
      "5f0b43c80e5d4294b7d12b9eefb64037",
      "40de6387dd1f4054a2d958a3160482c8",
      "f1517f120eef4c1ba9bb0fd611e21d9d",
      "4e7b87e0c55b4f5c95cda5fe5c334ea6",
      "ffca0e02362b431da6d91417410c5108",
      "0d72fbd6185a4ccf92fc617ed189531e",
      "e9a136a2d42845c69f1985e04aa619b6",
      "1c2629179749410298e0b7b36cd37259",
      "abc210ae719f46e69ae9cc2e8eb6e6b8",
      "6d0b87cdd7b54b53a041125009e15a8f",
      "d3c586272030472f97649f12f2081a92",
      "ff72aa39ee004b3e84e8b71832986a24",
      "f06b44a6998749feb0cc3efd300a5a0f",
      "5e7ce1a5a5374f6ca81c1aaa5c31d444",
      "6928236e3e7c4caf982d052ddab0cca1",
      "a657cc3900914db2b60a3247914c7802",
      "90fada24068543169e71f281bcded12f",
      "8c7ddf533b2b4d5d98c3b0dad4bb8df9",
      "fb11ecb6d8014a6198fb51877857cf41",
      "6096698d03d74d2a91202738828d19b5",
      "60164109985f4d3f8cb5e0c4006178cd",
      "88bed3336b064a53bdf2a43f8896d49b",
      "65858b52d4d4485ebd93526e966e6818",
      "6474218b57a441f1ae55163a2bccffe3",
      "b9ced31c5ed64942a7ac20c962c15a8b",
      "ee5ef3f2d2a64202962a52b55f0f8422",
      "5ecd6a6b2e77443480f985dab19a50df",
      "a0976c61c93c4259a7d2af7cfa757329",
      "fa3c91ff9352492ab3d02652d520f866",
      "775f6c008fd84d708c58e6e2839966a4",
      "93892728347f4dcf969a1e6c8608c7f4",
      "68997764116346878dc25e2bffa4cfa1",
      "8447ed1fd70f4b9f918411b640e14627",
      "8ee659e3b308410f9153c92eb8592001",
      "389d08dbd00f452f8aa5a60231f92623",
      "69872954ef92408dba16381d2fcdd635",
      "a25be9efb1ae40ddbfb4ef8fdebf1362",
      "f663ab5f3c56437ca501475aea37c858",
      "b1fb21ed55f64fa9a4baca69a6971898",
      "0b610c71010046f79642d482a1d66db3",
      "0e9de5676b644bd6984d0c0f3b94b4ff",
      "712886e8591d4e0c986301749b9777c8",
      "c8a4f36bf778400aa2d8ad84a2c9d02e",
      "caea81046327403995a59ee8103aa8fb",
      "55b536ed453e45538e4777beefb8178e",
      "6730a4b05a8f4f69a75cb82cdf8d156b",
      "a94b20cc5b2f4f57a5611cf9be4eb62a",
      "0ea8bc7508dc4c749d1717618f694e86",
      "f8e7cd8d3dbf47cda50913692af3ba96",
      "26610378cb30435c823b018e39b7239c",
      "f6cc0565d8474901bb1b349ff518b523",
      "16cc377350de41a18c2984898f8a9904",
      "b71e0b8d08d54b89b35cf50b24f7d55b",
      "8e670b68bdbc42708ef448397a66371a",
      "c1a268fc88de4d01b37a46c60d64f977",
      "e1f140619d5d4b80bf68c67c648d3ec1",
      "4ec7c456b8e24235b9316820bd2952b4",
      "de9f66eb43254e8a9a1d96b4d8025bfb",
      "5b61ea8380c04e779975bc911fa44c29",
      "394e3731876c4d26b33772394f5c182a",
      "f07066b97ccf4ef2bfba268a5980810a",
      "91f0a7fa112047119edec8071429cb99",
      "3118424eb2894509be69a4a4e75c1272",
      "d5b23781341e495d94b18a0dc3722f44",
      "e9d0ac5d1f714143899494e0264c650c",
      "e87b21f6a9b747428f9cab3ad945409a",
      "cf5e40fe96cb4c41866d55c92c76d375",
      "f32e3e08e77c4055973072513d632080",
      "5c1573f8aba542d0aa8cd715207c5779",
      "e8a9767f144d41c8a8bc745aa229413a",
      "00371b6ccbce449fa69e4fd156507b71",
      "5d98bbba4a14446f8cc1c93550eb2f19",
      "6051890d0db74ceca5e796f883c9df54",
      "d7ec246cb75b498ca09490cd8ca09da6",
      "cf73069687914426b79f9c9fad6608c1",
      "2dad3909bfb9463da0190d88e428fe17",
      "09c752a577624d3a9d953cb33203b004",
      "407c3f0360854171885ca89d5b7849ef",
      "37fd190c06e6465493bfcf332cd779eb",
      "44b144ef6180402da637b8c3654b9699",
      "8799d631ee11471c91f47da887568c8d",
      "092d52616f9f4bbd8d206e1e1bdb760d",
      "af73acca3df84082927593b00886bade",
      "e4430acf62d7488ba9cc31e1ce561676",
      "f4c1262ede094b339ccdcd766de52c72",
      "36cb62b9dd7548ada6c71442ee6f844c",
      "312a822825b149e3b90df66592972bf9",
      "ac7410d0daa443fbac44af103e429caf",
      "22095d2745484b2f8b1b6f8d49ab21f1",
      "198a0f1030224003bf7e6d75620ec5f2",
      "1c1ca76997fa44eab7bf91e342688ba6",
      "15566c4ef7d1438d8d46070c58340c53",
      "5e3ef14d1f144082a9814fe8a8ee1114",
      "3bc5b0d642574feea148131adb63e2cf",
      "c6f3cdef51ef4592a33049e8b8687970",
      "9c832b6249b249ad8b7d40dd07ffabc0",
      "0dce219ba63d4b0c99e2dfab4c41194c",
      "ccdce9c88a5045a3839d9400fe64e683",
      "dec189c98ecd465aaea9a9dcecd7083b",
      "879e3b903ed84a43ae151169faed29a1",
      "61dd700eafb6407cabe355a5962ed488",
      "9776fb76efbe4a558f0544bc1ecec266",
      "213149af171b4189917df00175dcc62b",
      "00a699db2989474ea068f28c525eb876",
      "0130e9e0d59f44e8a3fd02f549458889",
      "a493143bccb6484482b3e151fb86de3b",
      "1a4f99a0c71b4ecca3ddb9c55b3a4063",
      "68713e99f1e9452f8a8e444867206955",
      "4b19e5e6633845bf806fb2490a105405",
      "591dc3550d3940289a2433f280aa50c7",
      "08af21f465df4e3397be42e494c31c7d",
      "4f96b534dfc04877b881454afde4f984",
      "8965aa85cac6429ebbe185cd852aab5a",
      "651d2915501a4e7eafe099d0bf8b3b09",
      "7a2491eee38343b19d90340da9410e20",
      "7a4e8ca0491c4a7b9897cc57dc162371",
      "84bf5eeee8bc4d81810f50239e23bf37",
      "cf4dd68551894da1ad248d930ad81c0d",
      "6114e5697c0d4b80a48a726729df5f38",
      "00ac742d72684f28bfc796222e2b4d65",
      "fcf45f746b364f4fa0b54888217cacc1",
      "d16baecf7922441089ca5b0e372d12ef",
      "b66771c0bcd24331a1c3813691a41cfc",
      "14710c19496c403cac7cc58ce8e0dbc7",
      "c68dbed531b243bab8d8bdb2820d0f74",
      "1445b5bc4198415bb1276170e592ce9d",
      "1c84a1694dbf4e4da997e2165dfbb19a",
      "2319386f636346c7a9507fb670540663",
      "79bbb84d1d194463b0671b79194d54fc",
      "18c4db23056b47f7a9d2c1b5eb8dbac1",
      "73359ce914a843c7adb0c875bf681520",
      "f1d62ef06cac4a63b6e99ed352098c2d",
      "76a300106b924c8580482c0598fa4826",
      "13a61a2e5c384d019677f9cb7418c38b",
      "14e3c9f89f704b02b10feb35ccd47bc3",
      "0f6b8a723a204063ab57b65fd9db16c1",
      "009de33c238046fbaf57e6cb55f0faae",
      "92f2caeed9064f3f86338c378ceb9b93",
      "79bc2cf0ab5b4f33958f2f9b37d7c4a9",
      "715a22e4856a4656afe37c410ed78d7e",
      "25b9ed7bbb514666bc82d2115235f121",
      "c53e77bfdad0409d9bb7636b7766e6be",
      "d9a702cf447a4790b1b9b41c3bcc2f91",
      "992f290b7ca84d96a1b351f786da070c",
      "6dfc5018a3534b52af636c8958d99327",
      "ef5d6755ea46491cbdcd294f04709abc",
      "a19f91791a5446938aac2c78c1f00039",
      "5b01f8f731b941ceaa333405b4545eff",
      "58068b5a5d0f4dab89ac02ddcfec0fc9",
      "b2d3960d5ca5452c82e720650537dfcd",
      "58e5fec57af048c5bb7990e549569885",
      "a57affeaab8d4eefaba1dfe97fe46683",
      "167c8ea756d9446297f44cc9ca8af217",
      "15a75ac4c71f4bb2817d76713fc2375a",
      "e2b9d08081c344a5859380013ba214ab",
      "42387bbb16ea44f2bd79ecff733de171",
      "4482c060ffe74ba5b58f54b8540b4738",
      "69c67390b17044e0a5eb9635c0a5efbb",
      "1767b36e794947ccb1dd0454db58965a",
      "b9afe19eea0d4710bdac84ef563a6760",
      "a2ae295e6a0a430abc2e40d655e4b59f",
      "4f280dae4b574947bc9cfc8e55ad8450",
      "8bbdf86295d5436d82d032392e28e379",
      "60c631c97a2c49f0ad8dddfb4777128b",
      "ab918091753a48f5a2b9e0760d525d9b",
      "f4f3d7f38a15468787894b600fac19f9",
      "2baa4a82a3c04d1facd07bfecd6aba2b",
      "1a6f4e6f95f44777a3c0e380bcfb060b",
      "e351e5e539b04dde9dbf836d1a72cdb0",
      "4d1ba9d932ea49c49a502fb62947ee13",
      "7fd3be156af7496a96811ca12ef71c93",
      "f3042b76ed4c4ec0b11d5cdaffaab63d",
      "05f2f0cba8424b0dab7ed72cf961d614",
      "e12aeed52310444e807d7f3100d39080",
      "05525c56aadd47beb78dc030ed222fba",
      "a10d175b183b41dbbf42fb95bed80c14",
      "0102d73528d44062989dcfbef3e88291",
      "88c0d6866b3644569cba9214d610479c",
      "4c16679076f4419e98af3c1884312bfc",
      "04e282757bce4e00843a9a1abcc3d1a6",
      "8fcb145104584e21a8b9c57004bf3982",
      "5f318d0141874488b6c96f740a0f581e",
      "f82f3456db094c729992c9b7a762dd2b",
      "9a910ddbceec4f1c9f59310ffafa849b",
      "46908241982d4b20be46a2b10e73e6d5",
      "c56b2c22342b467fb2aa1355a8f55020",
      "d32bc5b2e1ac4ee385f4389a39d5234b",
      "da11f0a4f4344ccb8caae832eeaff9b6",
      "6d797871062449c9ab1fdcc0ec7ca93d",
      "38138b1d9f724f31b5d09e09402382ef",
      "547efe889bde482da8d656fb354647f0",
      "f9a3f033b1c84f86b1f273ba4d98e194",
      "b1b5da5229424b049c7153c87b2e8ebe",
      "1865b3eb27834552b0cf91986f618d08",
      "4a41ea8276914e96badfca2fcabf1614",
      "7b3587db020a457aa413527fb3e4667d",
      "e5b9d4a8538b41439fdf9b05d846ec25",
      "bec16fc6114d44449aaa9a1074bfbccb",
      "10cb88d9680e41478d02cdc2f11057be",
      "084006ca835c4d10978bf91d4a26e381",
      "321c903fc36644c890596c6720d3f8f1",
      "555c005322f7461297957003bfad1fb2",
      "b28ba156f43a44dfaeb3e7d8e80f557c",
      "a22f08848e484a58abc3b0f3bc3ccc48",
      "ffd63210525d42dbb98f23f467fd32f8",
      "92faaa12648541e380dfb887f402f157",
      "43dbe32a714c49bea160b5cf8fe97018",
      "93c17548eb2449c496f3bcfb9e4906ab",
      "5ab47b0761014a5b966c76c08f6fb748",
      "e9285ed1975241be807d9a024267ee0f",
      "ba55cf7e4b8f4f75ba153326c80bc41f",
      "407f7b6d1d7c4db5b2aa643840e84432",
      "4ee981fc341a4cd4aa70e120f837b261",
      "4a97ca4bbeeb487dac236749571b5221",
      "b7876066dec34277baf6aa4d11476d46",
      "3dc72a1bf0cf489c9decd8f1d63711d0",
      "d6db393fa34742038f07ca40ebc683a5",
      "4132649e9c5243d1af51fc07663d6e7d",
      "45557f321dd245afbb4590f6763e35fc",
      "faa133031dba4f708f8fe87583ca5657",
      "ea381311d6a447b2bdc9968c79709cd5",
      "18a3c3e8d5854b709a9cf400835cff44",
      "f3af1b46042b4d9d9031968b6d8a74c8",
      "079e8b3851c44e7f97ffe5e207033668",
      "e16e278bce45481b95e15d6cf052280a",
      "fb444a14c967425599e30645f8e5a072",
      "67e27aa55afc47d2838e13654fa518b1",
      "724982a96f5f4f16a0c810db53d3f5bd",
      "a1fb17f1a7e24fa38c8182c7cd816848",
      "44844d8de4994ac69eda65ce2e606bae",
      "1a944b48c07b457ab06e8df266be5e9a",
      "6804fd8eace6453bbb6357793ff2018b",
      "a489d95275134ac18a18a8e8bb25bd7a",
      "bd9b9abcdb2b4425aa56246be4e28ae5",
      "7f180de5ff8c4823a09d206dba49f34c",
      "36b848eb8f474a9a940f2d9407066101",
      "a8d61ed2bd8a4d22bbe3d12b1d6dbf71",
      "44e2ba50050b4d918f7a5c1c273b27f8",
      "8c3722ca1c0f4fd7abf3be27ba81d00a",
      "0c595e38f4d540c1973a54057a3fd9e7",
      "793010d1effc448994e335f49ba75b94",
      "86154ede542e452a930fc9ca1172823d",
      "b5799f6339174952bba2fb813b532e1f",
      "6bbb80e39e0e4c4fac4e60f72a7b3de9",
      "23821ea680184d4abcb16a6af79ad193",
      "a9c8b93f436a40d8bccfc1c52fa8e134",
      "62dcc778b709485f8a665093cb675d84",
      "647248415ff340d9b271202c2e7a83cf",
      "34cd3ba52c4d4ed1a84a7b8b89523cce",
      "1f8aa3512bb04fe7a36cea7403b5e1b9",
      "cb4cb4cac2684c2cb5483393c45398f9",
      "61901b2327464c0a9ac88e10f25a885a",
      "b22f92da87494d11a56ca0894c1f35db",
      "15916c73c24d438c8276d82b1cf552e7",
      "e000251866e04b2289683dcca27a266d",
      "2cbdd378314840cd8bd2fa6272f4512a",
      "6debd77f7b924484b56e80153754a6d0",
      "656e2ee18af74bbd989faa5e914fcbf9",
      "c856def0876e42f5a5bb1c090ab06a09",
      "bac8d1ba5727497bbe06e985921581e0",
      "5d4eb63f45a947cd91d9b61de0f30bd0",
      "9538763991e444a19c79f1a2c0e8fa2b",
      "a7f6927d79f24b7a9f7d31c8f9a9a24a",
      "87d003dd21714e84ae3618c0b3865764",
      "50386c26a36049a2b985833115140e68",
      "4208183327c44921898cd58c7ab19aaf",
      "e89ba1d25b8b41a28a34a5a76911c492",
      "fb502e341fb046b2a44e80d97f66d81b",
      "26418086eb994861b39994fa9980c813",
      "49cf1b55508e4c32bc9314add558f510",
      "e167f4ad865a4015a29a4514829ae6ba",
      "dc42ed6ede594bc2bc3882d190ec62a4",
      "b17096243882469aa9ae4b588d99841b",
      "06c465fad1334fb78db740561b0a9171",
      "37d3368e5eec4c4fb12fc6155fb698ae",
      "2a9da849f70f4ddfa22ee59a54462163",
      "1e3053853cbb4942bce4ff4ecb5f8b2f",
      "70c6ce176d99416da720aaa4284fba79",
      "976d46938478433297891f10017da9fd",
      "2aef00c462cf47d0bd78b6090480d0c1",
      "f34ea1065be14b56a513a01c2c18e82e",
      "10bcb5a4489845559b772a5a45a63e49",
      "fcc64c6f1e374a9fb42f5c144fb8095c",
      "98d58fd81edd43848c55c820c2cfe475",
      "b169ef5e16834a708c101689fdb34011",
      "7faac2534ac84ad7bcfd7c6da9a462df",
      "9d9ab44998bd43afa33802d31e04b575",
      "668563d54d214070a345c4b84e4b1176",
      "a47a53f4c43342ebb5c8e12b1c3d3319",
      "d65aa9cc8bda455085f28c65aeacda4d",
      "90525dea2ea340f78d2fe244e788fe57",
      "22fd2c2ec28249548f2b98fcacaf4df7",
      "7055b715d1be449c8e9e24740d074071",
      "fdaae4d6637440f1a1ef2171190feca2",
      "c39bbdf548f44a9d94fc53f90dd0821b",
      "ddcf49cc34f04fe294179a5ca6f6dc0b",
      "1efbbec2a55348ffb527335d230cbd01",
      "7665b15f225e4420a9601fff5ce40753",
      "6dc6d2f5d8bf41449733668e0d260ea0",
      "acc555d7607642019529b3f364a5675e",
      "c2c2ed6ee38743d8b3473409fc1dcc2d",
      "5a8afdb50ad442a59e2b565afc2418b8",
      "87be7c8a39d34ec5bbe650e57a5569df",
      "f11f2dbbbb85404eb9fe858c2fdce274",
      "1b4d634e4a564e0eb077645626caabb6",
      "cd3047280156441587a5f3a7ea9ae161",
      "f4e917fbffb941c291623def1b9fca31",
      "e6cf8982f87a470bb014a111677be072",
      "980cd06261a4469b802cda4798ea7183",
      "3d7b119b3f1440b19ede236d771929f0",
      "46d80a066f3b4f0f95ea5ebb6b502544",
      "cc0c180539384b1285491d5ebd2627e0",
      "6154bc7a0d2f492a8f7a359eee5dd6de",
      "f6a4f140f8d240a3bd5c303f8d752291",
      "a9a1ac4652994b56996ddc205b3c2c9e",
      "d72785f9ff8541d2a12a9d85f64f09dc",
      "c19f49e33dcd4130ae8a1ca31bf091ed",
      "0853705919024ca4a6ca30b1d85a3926",
      "3f7dbc4fb94b4d58b77c36471dbd7c1c",
      "380298877e1f436e8f8da0b28abe5b82",
      "eca9b61fd46f4a7b81d673ca46760fad",
      "a1067487c9504346b0f325680b079f0f",
      "1e4ab44e16534fcba7f23c9a751d21c8",
      "45d1c532f62045e2a6c7649c989a5f01",
      "24230f58deeb466e8bacae8a741307fd",
      "00d533abbf7a4088b62b66912aec9a15",
      "465523e7a1f84b4e917707036474870c",
      "9a91f77c7bab4cd18022fd365b2aa4fe",
      "84f21f11f553400bb1f27ae5701d8f54",
      "9f7054a37a344ae193a8428b1cb9a003",
      "41e4c13826c143e58fa633463a613cf3",
      "a6fcf1a8948e4b8db2652c6970645657",
      "415c70ded5874e32aeed6f29b2d76fd7",
      "e49336d736ee428cbd1e588cbca7a985",
      "3bcf812ebd4d48048b2fe3e0b36d244f",
      "966e0e344ef647b0a838e357709b868f",
      "d467d083701c4e89bc04c403ad8be659",
      "0f8b8e272db441bc8759949f5d725d6f",
      "bf012a5daeb64b8780e54c0e6cd1256e",
      "06569162c89e40c7ac0555a5fcfb9057",
      "143450d1195445ff9d72b6d7dc118c3f",
      "e75da2322946476e99ecab0df4d9a6fe",
      "e62c33f0e31d4169ac892964bf7ea1e4",
      "2c2e9c3d06434c1f907e30c61cd7f1e5",
      "b062bd52fa4d42a398bdc69f93b20492",
      "053bd463e5104332a52104cb1377e771",
      "0faabbdb1faa46a0bd2748bf538ba806",
      "fa147f7101224881b10ec2d19a4dd127",
      "7532ec1f5ec446c8a78b9ea5d77f5e23",
      "b05eeb3f0231466da954fd8982085406",
      "8a51ccd860ee49ae819c9ef30031bd21",
      "f2d692d84e4c469ea93609be1e8ff312",
      "ef01d739c2cc4c8ea8eb8060a69f396c",
      "e870ccdd7468437796c3a9a4d2dfcfbd",
      "d6836844a8e841c9925ef9582c6ff306",
      "ca09a7ec48af4a6780145a1b7494036f",
      "ca03fd2904f74d38bfd7f013c4730428",
      "e58b8bd8ddea405986d06211eb7ac299",
      "dc26fbf430174b0e9d6cd830992aa407",
      "d6d1757fcd284deea48b75f498ebe1ca",
      "9c559ec9c4b040c9accbb5d7e4c87f52",
      "eefb028521d746878e90a714563cb1fd",
      "c5ea232a808b4a2c9a1401708f3a9b4e",
      "fafbf2ea29b84137a1e2052f7425ad6a",
      "4579f4bbd6994215b6722c8ac6c48995",
      "3ae361b57a3e4d28a0c79699fbd93983",
      "8c4a0ec2c16347cba90f8b10cf1a4d5f",
      "2dfa722031984636b1cef33974460038",
      "cea111b17a77438993d35907a0a03df8",
      "857a9c40bef6456a8dcd57f102250eeb",
      "7d71ba09d1c14864b2852f8bb0ebbade",
      "29ea9a5c6d1347b3877d6ddf87e156e8",
      "619d7cdb82a24070933b762e2c56b2f8",
      "ad603368862a48b587b0f1debddb1cb2",
      "4db4a689917a4ce28ccbee5ad7e9b02b",
      "de057105a4b442929a1fecafc206c92f",
      "5313dd53d16a409d9b35135b731ee268",
      "c02f51959e8548068124fa7d6251f3d1",
      "48b11034cef345438fde907c439cd395",
      "e34135d407254e1b85b005bfe7e0351f",
      "346fee514c3e4ee09dc63929d48b5bfa",
      "5cb8542003364c0bbdecee0ca743815a",
      "5b8ecfcb51be439781f3477f1b562bcd",
      "6d52e0c6f1d04f19bf1b653450d35f16",
      "e041e71969db4b818cac3eb0ea475de5",
      "525f6142253e462abae3f928f541c207",
      "b5710b8a9dd949a59a0db963329d5ab7",
      "848dc3e9eff1471482c9f8fc045346b8",
      "09e781d1dfd14ba29987104faa327104",
      "7925e90db75049faab52a1bd773cdecd",
      "3525246860c349e1bae59b07324716bb",
      "e5c2724392884d41bc23b698beac7063",
      "14f3eed918f24b8184247b32b5d7e86c",
      "c4130f95d18b4c36a92608b6c35deef1",
      "e97698e867814c7d9d27cd85064e1291",
      "f5190db440d440cb97faeab9735fb0d5",
      "03e2cbc76742404c9175e51ca7af5920",
      "1e61403069f74ad191bb6e717848b570",
      "997b2c152cf94f25bb259df39c256eb1",
      "be0ad9953bf648ebb2308821c8a01de0",
      "d035479345b844df822f7c7c45a4899f",
      "ea57cd7d9cc94b15b90f39af61745160",
      "f5180c840a0a46a387e1e4382ca2995d",
      "691c68cdf15c487281e493c5b872eac0",
      "67f2a0f0e29f444083fa067c58ff189e",
      "3a78542f27ba4a8b8083609f4b1dbf06",
      "14be0b24003348dfb9ceed4f15d41f85",
      "7abc2c2f0937438a84b2e1984a316673",
      "27564add73ac433da4f272a7e0576d3d",
      "e3242263116d498e9cc488d88606e850",
      "227ee3d685a34aa0bddc2bc3e8711947",
      "6061de06d6384ec1a8ae9bd52a0eff50",
      "df96f18835b64b038663ce02957cadcf",
      "64ceb55368244b6883139a5a6ccfda12",
      "4443692d412b4c7485abbe344ae63a5d",
      "b93edc8f9bec49b3b588fda83f8d6b60",
      "07933fbe66e74c7a9407e8cd3ecfd8f6",
      "f60b44639bdb4fc5ba042d0cc135b9ce",
      "87197c95b4c24297a352067085dddaf2",
      "fd75560f321046ae891d15f7ad2ce0b6",
      "3b8810ecfb804b299145e1d782f52e5b",
      "7e3f4566c25a4006a3ea77886ecaba8a",
      "6e3c87bd85a74d3495c026fd4f6e4d1d",
      "75f9ee5ae3ba48f29973ed5674a2296d",
      "5ba501855eb34e7cb00395683b12eaec",
      "d20255e338ff4f5c93d63d0cc21293c4",
      "d95b4990b42044689fa5a7804d70690f",
      "064bbf4d362547658ba64b162611f2ee",
      "0eeef83c14034ba6ac8005bf7249152b",
      "22e5e13fe17844338ea30e19c503433d",
      "9d032a32b76247ec913d3dfbd6ac08b4",
      "c1343a61a2044cf68c7f5f268b9b1042",
      "abb1ac4034c24cedb4723168c94316c8",
      "64effed1415243f6a8417f6c3fb939ce",
      "382ebee342af415ea4988e2991925672",
      "75fba35d4f85443da1e72046473beb69",
      "d90d947fa02b40ddabce28cacb18af92",
      "085f739cec7d465bba3aebea24c32457",
      "2ce1375f28d34062acd4d5b6259af10d",
      "c1170aa6d9cb4e7cadd782887a9e45ae",
      "ab3b8d9e215f4dc1a0c177d6e4d1c8c0",
      "8b875565f9114139ae45b509bcc2b7e9",
      "6660a525e3de4aebabeee0287f05547c",
      "75bb01b3de3a4295baaa671647df61a7",
      "b843c5d8b5d34cbb9337cb6bae4e5878",
      "cb3bacefa9ab43809491215933df754c",
      "7bff3c95ea214eedb0e9c5a1cf881fc3",
      "9dc3246267e44ce2986cc3426a17db13",
      "c51e348ab1b84840abbd8e88e36f5a49",
      "a7c2abc0c86145eb9a542f4f748b952a",
      "47b88f44d884437388d21a9563efee62",
      "8999895d3ccf4963ba8bfbebbe3b0ce3",
      "d3daa609d4804b1e97d1192235507201",
      "14a153f481104e819f78ea7f4a07880e",
      "5b6b785822f140c2a835c3975110e1e7",
      "0a97b05f93484a3aba146d6512a00f93",
      "c823624bb00f412e84becd3087b1897b",
      "59f130e7b2c14c6e973fceedd20cd9c9",
      "500369cc61464c9f873e77761f134fe4",
      "c8641c03e6f4467c86b865db412b648c",
      "8468f9452f954016895a19850cbd40b8",
      "73324d0a9d1d4eb5ac68feeda78854b3",
      "c1341a935402451aba1be7bd743ada30",
      "3b995340a49448afb81c7dd70e9a4b94",
      "080f261320b24b18a4bfe7aed9af38f3",
      "5e2dc9cf77644dbab1d07066997498c0",
      "f2a3e3b891884c529236791f64fce291",
      "de613aa95309457eaeaca6965c3f759e",
      "3db9a16afd874c37b9da0eb85db68682",
      "4f7e7790f2e14812956083252774e616",
      "3e0bbb6d57f94a6fa24d91e5e6df1516",
      "c8a9d199eeba4aae97c4486cd6411dc5",
      "64c59eb480944f11a0423cc90fe4c3bf",
      "e09968619d1045859ee1a39f4a8ffeb1",
      "1b44329b78ea45779d5f570649abc562",
      "bc40dfb487d347d8a90c0b59d1e34ca6",
      "30bedcbfa8f946c1b2621757a4104342",
      "40b4a8d3ee7147f68a656cd414505cbd",
      "2d5ef5b847b0457a8dfdad960928edaa",
      "be6672c095144723a3686cf80588de26",
      "cc4af6c70709482d8b898cb537bfb006",
      "a9e9fa5769ef4557ad54f26f53503505",
      "28d3174ffd7042588eda0aba309cc61b",
      "df4271db770f4ed3a924538127abed7d",
      "84d5a54a68454f5296e68097e39d56c4",
      "4d28255c22614b3da2d2ac2f1363ab73",
      "6f3c2168453c49d3b00ea5362e218696",
      "311aad4ff96148868be6534e27ef54fe",
      "cf63ff07e8f5475db563a78c0ceb1743",
      "68c76aa248c34f009826b03967abe8bc",
      "9f0da93abad9499b9479bd5f5cc8bd6a",
      "9a11a6e6ee6041689974cece702191ca",
      "74e2f962594a4b29aeb7c4e5488087be",
      "c20735c1cb6e41c795fadb82ba224556",
      "fa9e4d062d094bf59fddfec306eb3932"
     ]
    },
    "id": "o7owhXoNDKu6",
    "outputId": "68bf4205-cb0e-49c8-8266-e9fad00d0d3b"
   },
   "outputs": [],
   "source": [
    "n_clusters = [5, 10, 20, 50, 100, 150, 200]\n",
    "k_values = [5, 30, 50, 100, 300]\n",
    "batch_sizes = [200, 500, 800, 1000]\n",
    "\n",
    "if recalcular_pipeline:\n",
    "  res_agglomerative = []\n",
    "\n",
    "  for n_cluster in n_clusters:\n",
    "    res = pipeline(\n",
    "      subsets=subsets_daisy,\n",
    "      crearMatrizDescriptores=crearMatrizDescriptores,\n",
    "      crearMatrizBOW=crearMatrizBOW,\n",
    "      aplicar_tfidf=aplicar_tfidf,\n",
    "      entrenar_svm=entrenar_svm,\n",
    "      evaluar_clasificador_svm=evaluar_clasificador_svm,\n",
    "      n_clusters=n_cluster,\n",
    "      K=None,\n",
    "      batch_size=None,\n",
    "      clustering_method=\"agglomerative_clustering\"\n",
    "      )\n",
    "    res_agglomerative.append(res)\n",
    "\n",
    "  res_kmeans = []\n",
    "\n",
    "  for k in k_values:\n",
    "    for batch_size in batch_sizes:\n",
    "      res = pipeline(\n",
    "        subsets=subsets_sift,\n",
    "        crearMatrizDescriptores=crearMatrizDescriptores,\n",
    "        crearMatrizBOW=crearMatrizBOW,\n",
    "        aplicar_tfidf=aplicar_tfidf,\n",
    "        entrenar_svm=entrenar_svm,\n",
    "        evaluar_clasificador_svm=evaluar_clasificador_svm,\n",
    "        n_clusters=None,\n",
    "        K=k,\n",
    "        batch_size=batch_size,\n",
    "        clustering_method=\"minibatchkmeans\"\n",
    "        )\n",
    "      res_kmeans.append(res)\n",
    "\n",
    "    # Guardamos as√≠ no lo calculamos todo el tiempo\n",
    "    with open(\"res_agglomerative.pkl\", \"wb\") as f:\n",
    "        pickle.dump(res_agglomerative, f)\n",
    "    with open(\"res_kmeans.pkl\", \"wb\") as f:\n",
    "        pickle.dump(res_kmeans, f)\n",
    "\n",
    "else:\n",
    "    with open(\"/content/drive/MyDrive/TP-Final/res_agglomerative.pkl\", \"rb\") as f:\n",
    "        res_agglomerative = pickle.load(f)\n",
    "    with open(\"/content/drive/MyDrive/TP-Final/res_kmeans.pkl\", \"rb\") as f:\n",
    "        res_kmeans = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v6KV2y2EUeAk",
    "outputId": "a218f117-a5fc-452c-a7f7-0f3ea8583ee4"
   },
   "outputs": [],
   "source": [
    "print(f\"{'n_clusters':<6} {'BoW Acc':<10} {'TF-IDF Acc':<12} {'Tiempo Vocabulario (s)':<10} \")\n",
    "print(\"-\" * 50)\n",
    "for r in res_agglomerative: # Corrected to iterate through res_agglomerative for n_cluster\n",
    "    print(f\"{r['n_cluster']:<6}  {r['bow']['accuracy']:<12.2f} {r['tfidf']['accuracy']:<10.3f} {r['tiempo_promedio_vocab']:<10.3f}\")\n",
    "\n",
    "print(\" \")\n",
    "print(f\"{'k':<6} {'batch_size':<10} {'Acc. BoW':<10} {'Acc. TF-IDF':<10} {'Tiempo(s)':<12} \")\n",
    "print(\"-\" * 50)\n",
    "for r in res_kmeans: # Corrected to iterate through res_kmeans for k and batch_size\n",
    "    print(f\"{r['k']:<6} {r['batch_size']:<10} {r['bow']['accuracy']:<10.3f} {r['tfidf']['accuracy']:<10.3f} {r['tiempo_promedio_vocab']:<12.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def convertir_resultados_a_df(resultados, metodo):\n",
    "    filas = []\n",
    "    for r in resultados:\n",
    "        fila = {\n",
    "            'metodo': metodo,\n",
    "            'n_clusters': r.get('n_cluster'),\n",
    "            'k': r.get('k', None),\n",
    "            'batch_size': r.get('batch_size', None),\n",
    "            'tiempo_vocab': r['tiempo_promedio_vocab'],\n",
    "            'accuracy_bow': r['bow']['accuracy'],\n",
    "            'accuracy_tfidf': r['tfidf']['accuracy'],\n",
    "            'f1_macro_bow': r['bow']['f1'].mean(),\n",
    "            'f1_macro_tfidf': r['tfidf']['f1'].mean()\n",
    "        }\n",
    "        filas.append(fila)\n",
    "    return pd.DataFrame(filas)\n",
    "\n",
    "df_kmeans = convertir_resultados_a_df(res_kmeans, \"MiniBatchKMeans\")\n",
    "df_agglom = convertir_resultados_a_df(res_agglomerative, \"Agglomerative\")\n",
    "\n",
    "df_resultados = pd.concat([df_kmeans, df_agglom], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "plt.figure(figsize=(18, 10))\n",
    "\n",
    "# 1. Accuracy BoW\n",
    "plt.subplot(2, 3, 1)\n",
    "sns.lineplot(data=df_resultados, x='n_clusters', y='accuracy_bow', marker='o')\n",
    "plt.title('Accuracy (BoW) vs n_clusters')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('n_clusters')\n",
    "\n",
    "# 2. Accuracy TF-IDF\n",
    "plt.subplot(2, 3, 2)\n",
    "sns.lineplot(data=df_resultados, x='n_clusters', y='accuracy_tfidf', marker='o')\n",
    "plt.title('Accuracy (TF-IDF) vs n_clusters')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('n_clusters')\n",
    "\n",
    "# 3. Tiempo vocabulario\n",
    "plt.subplot(2, 3, 3)\n",
    "sns.lineplot(data=df_resultados, x='n_clusters', y='tiempo_vocab', marker='o')\n",
    "plt.title('Tiempo promedio vocabulario vs n_clusters')\n",
    "plt.ylabel('Tiempo (seg)')\n",
    "plt.xlabel('n_clusters')\n",
    "\n",
    "# 4. F1 macro BoW\n",
    "plt.subplot(2, 3, 4)\n",
    "sns.lineplot(data=df_resultados, x='n_clusters', y='f1_macro_bow', marker='o')\n",
    "plt.title('F1 macro (BoW) vs n_clusters')\n",
    "plt.ylabel('F1 macro')\n",
    "plt.xlabel('n_clusters')\n",
    "\n",
    "# 5. F1 macro TF-IDF\n",
    "plt.subplot(2, 3, 5)\n",
    "sns.lineplot(data=df_resultados, x='n_clusters', y='f1_macro_tfidf', marker='o')\n",
    "plt.title('F1 macro (TF-IDF) vs n_clusters')\n",
    "plt.ylabel('F1 macro')\n",
    "plt.xlabel('n_clusters')\n",
    "\n",
    "# Espacio entre subplots\n",
    "\n",
    "plt.suptitle(\"Visualizaci√≥n de resultados para Daisy + Agglomerative Clustering\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar que a partir de los 50 clusters no hay una tendencia significativa de aumento en las m√©tricas. Adem√°s, el tiempo se mantiene cercano al rango de los 70-80 segundos para todos los valores. Entre Bag of Words y TF-IDF no vemos una ventaja clara, ya que dan resultados muy similares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funci√≥n auxiliar para crear cada heatmap\n",
    "def plot_heatmap(df, value_col, title, ax, cmap=\"YlGnBu\", fmt=\".3f\"):\n",
    "    tabla = df.pivot(index='batch_size', columns='k', values=value_col)\n",
    "    sns.heatmap(tabla, annot=True, fmt=fmt, cmap=cmap, ax=ax)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"k\")\n",
    "    ax.set_ylabel(\"batch_size\")\n",
    "\n",
    "# Crear figura: 3 filas, 2 columnas\n",
    "fig, axes = plt.subplots(3, 2, figsize=(14, 14))\n",
    "\n",
    "# Heatmaps m√©tricas\n",
    "plot_heatmap(df_kmeans, 'accuracy_bow', 'Accuracy (BoW)', axes[0, 0])\n",
    "plot_heatmap(df_kmeans, 'accuracy_tfidf', 'Accuracy (TF-IDF)', axes[0, 1])\n",
    "plot_heatmap(df_kmeans, 'f1_macro_bow', 'F1 macro (BoW)', axes[1, 0], cmap=\"magma\")\n",
    "plot_heatmap(df_kmeans, 'f1_macro_tfidf', 'F1 macro (TF-IDF)', axes[1, 1], cmap=\"magma\")\n",
    "\n",
    "# Heatmap de tiempo\n",
    "plot_heatmap(df_kmeans, 'tiempo_vocab', 'Tiempo construcci√≥n vocabulario (seg)', axes[2, 0], cmap=\"OrRd\", fmt=\".2f\")\n",
    "axes[2, 1].axis('off')  # Dejar el √∫ltimo espacio vac√≠o\n",
    "\n",
    "# T√≠tulo general\n",
    "plt.suptitle(\"Efecto de k y batch_size en SIFT+MiniBatchKMeans\", fontsize=18)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso, vemos que con K=30 ya es suficiente para un accuracy elevado, y que con K=300 es casi inmejorable. Hay una leve tendencia a aumentar los parametros con un K m√°s elevado, sin embargo, no hay diferencias significativas al aumentar el batch_size m√°s all√° de 200. El tiempo, por su parte, es muy inferior al de Daisy+Agglomerative Clustering, y podemos notar que a medida que aumentamos los clusters, tambi√©n lo hace el tiempo, aunque nunca superior a los 2 segundos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîù Top 5 resultados seg√∫n Accuracy (BoW):\")\n",
    "print(df_resultados.sort_values(by='accuracy_bow', ascending=False).head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si priorizamos el accuracy o el f1, que ya vimos que aumentan de forma muy similar, las mejores combinaciones son con MiniBatchKMeans, y a un costo computacional considerablemente mejor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluaci√≥n final de ambos modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar los mejores resultados seg√∫n BoW Accuracy\n",
    "best_agglomerative = max(res_agglomerative, key=lambda r: r['bow']['accuracy'])\n",
    "best_kmeans = max(res_kmeans, key=lambda r: r['bow']['accuracy'])\n",
    "\n",
    "# Extraer valores\n",
    "best_n_cluster = best_agglomerative['n_cluster']\n",
    "best_k = best_kmeans['k']\n",
    "best_batch = best_kmeans['batch_size']\n",
    "\n",
    "print(\"Mejor Agglomerative:\")\n",
    "print(f\"  n_clusters = {best_n_cluster}, Accuracy = {best_agglomerative['bow']['accuracy']:.3f}\")\n",
    "\n",
    "print(\"Mejor MiniBatchKMeans:\")\n",
    "print(f\"  k = {best_k}, batch_size = {best_batch}, Accuracy = {best_kmeans['bow']['accuracy']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if recalcular_test:\n",
    "    # Extraer SIFT del set de test\n",
    "    keypoints_test_sift, descriptores_test_sift, stats_test_sift = extraerSIFTDataSet(imagenes_test, etiquetas_test)\n",
    "    keypoints_test_daisy, descriptores_test_daisy, stats_test_daisy = extraerDaisyDataSet(imagenes_test, step=45, image_index = 5, radius=30, rings=2, histograms=6, orientations=8)\n",
    "    # Guardar los resultados de test\n",
    "    with open('sift_test.pkl', 'wb') as f:\n",
    "        pickle.dump((keypoints_test_sift, descriptores_test_sift, stats_test_sift), f)\n",
    "\n",
    "    with open('daisy_test.pkl', 'wb') as f:\n",
    "        pickle.dump((keypoints_test_daisy, descriptores_test_daisy, stats_test_daisy), f)\n",
    "else:\n",
    "\n",
    "    with open('sift_test.pkl', 'rb') as f:\n",
    "        keypoints_test_sift, descriptores_test_sift, stats_test_sift = pickle.load(f)\n",
    "\n",
    "    with open('daisy_test.pkl', 'rb') as f:\n",
    "        keypoints_test_daisy, descriptores_test_daisy, stats_test_daisy = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluo Daisy + Agglomerative clustering\n",
    "\n",
    "if recalcular_mejores:\n",
    "\n",
    "  descs_entrenamiento = np.vstack(descriptores_train_daisy)\n",
    "\n",
    "  vocab = construirVocabularioAgglomerativeClustering(descs_entrenamiento, n_clusters=best_n_cluster)\n",
    "\n",
    "  X_train_bow = crearMatrizBOW(descriptores_train_daisy, vocab, clustering='agglomerative_clustering')\n",
    "\n",
    "  X_test_bow = crearMatrizBOW(descriptores_test_daisy, vocab, clustering='agglomerative_clustering')\n",
    "\n",
    "  clf_bow = entrenar_svm(X_train_bow, etiquetas_train)\n",
    "\n",
    "  resultado_daisy = evaluar_clasificador_svm(clf_bow, X_test_bow, etiquetas_test, \"Daisy + Agglomerative Clustering\")\n",
    "\n",
    "  if recalcular_mejores:\n",
    "    with open('res_mejor_daisy.pkl', 'wb') as f:\n",
    "        pickle.dump(resultado_daisy, f)\n",
    "\n",
    "else:\n",
    "  with open('res_mejor_daisy.pkl', 'rb') as f:\n",
    "    resultado_daisy = pickle.load(f)\n",
    "\n",
    "\n",
    "print(resultado_daisy[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluo SIFT + MiniBatchKMeans\n",
    "\n",
    "if recalcular_mejores:\n",
    "\n",
    "  descs_entrenamiento = np.vstack(descriptores_train_sift)\n",
    "\n",
    "  vocab2 = construirVocabularioMiniBatchKMeans(descs_entrenamiento, k=best_k, batch_size=best_batch)\n",
    "\n",
    "  X_train_bow = crearMatrizBOW(descriptores_train_sift, vocab2, clustering='minibatchkmeans')\n",
    "\n",
    "  X_test_bow = crearMatrizBOW(descriptores_test_sift, vocab2, clustering='minibatchkmeans')\n",
    "\n",
    "  clf_bow = entrenar_svm(X_train_bow, etiquetas_train)\n",
    "\n",
    "  resultado_sift = evaluar_clasificador_svm(clf_bow, X_test_bow, etiquetas_test, \"SIFT + MiniBatchKMeans\")\n",
    "\n",
    "  if recalcular_mejores:\n",
    "    with open('/content/drive/MyDrive/TP-Final/res_mejor_sift.pkl', 'wb') as f:\n",
    "        pickle.dump(resultado_sift, f)\n",
    "\n",
    "else:\n",
    "  with open('/content/drive/MyDrive/TP-Final/res_mejor_sift.pkl', 'rb') as f:\n",
    "      resultado_sift = pickle.load(f)\n",
    "\n",
    "print(resultado_sift[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados = {\n",
    "    'sift': resultado_sift,\n",
    "    'daisy': resultado_daisy\n",
    "}\n",
    "\n",
    "ks = {\n",
    "    'sift': best_k,\n",
    "    'daisy': None\n",
    "}\n",
    "\n",
    "metodos = [\n",
    "    ('sift', 'BoW SIFT Final'),\n",
    "    ('daisy', 'BoW DAISY Final')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotConfusionMatrices({'bow': resultado_sift}, best_k, [('bow', 'BoW Final')])\n",
    "plotConfusionMatrices({'bow': resultado_daisy}, \"-\", [('bow', 'BoW Final')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_set = {\n",
    "    'imagenes': imagenes_test,\n",
    "    'etiquetas': etiquetas_test,\n",
    "    'nombres': nombres_test\n",
    "}\n",
    "errores_test_daisy = analizar_errores({'bow': resultado_daisy}, 'bow', testing_set)\n",
    "imprimirErrores(errores_test_daisy, k=None, metodo='bow', total=len(etiquetas_test), name=\"DAISY\")\n",
    "\n",
    "errores_test_sift = analizar_errores({'bow': resultado_sift}, 'bow', testing_set)\n",
    "imprimirErrores(errores_test_sift, k=best_k, metodo='bow', total=len(etiquetas_test), name=\"SIFT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrarEjemplosErrores(errores_test_daisy, 2, name=\"DAISY + Agglomerative Clustering\")\n",
    "mostrarEjemplosErrores(errores_test_sift, 4, name=\"SIFT + MiniBatchKMeans\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graficar_sift_vs_daisy(imagen, kp_sift, kp_daisy, step=45, radius=30, rings=2, histograms=6, orientations=8):\n",
    "    \"\"\"\n",
    "    Muestra comparaci√≥n entre SIFT, DAISY simple y DAISY detallado (visualize=True).\n",
    "\n",
    "    Params:\n",
    "        imagen: imagen en escala de grises o RGB\n",
    "        kp_sift: lista de puntos (KeyPoint o coordenadas)\n",
    "        kp_daisy: lista de puntos (KeyPoint o coordenadas)\n",
    "    \"\"\"\n",
    "    # Convertir a escala de grises para DAISY\n",
    "    img_gray = color.rgb2gray(imagen) if imagen.ndim == 3 else imagen\n",
    "\n",
    "    # Normalizar para OpenCV\n",
    "    img_cv = (img_gray * 255).astype('uint8') if img_gray.dtype != 'uint8' else img_gray\n",
    "\n",
    "    # Convertir keypoints DAISY a KeyPoint si es necesario\n",
    "    def convertir(lista, size=10):\n",
    "        return [cv2.KeyPoint(float(x), float(y), size) for (x, y) in lista]\n",
    "\n",
    "    if not isinstance(kp_sift[0], cv2.KeyPoint):\n",
    "        kp_sift = convertir(kp_sift)\n",
    "    if not isinstance(kp_daisy[0], cv2.KeyPoint):\n",
    "        kp_daisy = convertir(kp_daisy)\n",
    "\n",
    "    # Dibujar keypoints\n",
    "    img_sift = cv2.drawKeypoints(img_cv, kp_sift, None, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "    # DAISY detallado (visualize=True)\n",
    "    _, daisy_vis = daisy(img_gray, step=step, radius=radius, rings=rings,\n",
    "                         histograms=histograms, orientations=orientations,\n",
    "                         visualize=True)\n",
    "\n",
    "    # Mostrar\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    axs[0].imshow(cv2.cvtColor(img_sift, cv2.COLOR_BGR2RGB))\n",
    "    axs[0].set_title(f\"SIFT Keypoints ({len(kp_sift)})\", fontsize=16, fontweight='bold')\n",
    "    axs[0].axis('off')\n",
    "\n",
    "\n",
    "    axs[1].imshow(daisy_vis, cmap='gray')\n",
    "    axs[1].set_title(\"DAISY Structure\", fontsize=16, fontweight='bold')\n",
    "    axs[1].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagen = imagenes_test[7]\n",
    "kp_sift = keypoints_test_sift[7]\n",
    "kp_daisy = keypoints_test_daisy[7]\n",
    "\n",
    "graficar_sift_vs_daisy(imagen, kp_sift, kp_daisy)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "c_zeXOggn6bQ"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
