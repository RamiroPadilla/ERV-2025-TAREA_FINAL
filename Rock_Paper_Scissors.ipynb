{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Daisy:\n",
    "`skimage.feature.daisy(image, step=4, radius=15, rings=3, histograms=8, orientations=8, normalization='l1', sigmas=None, ring_radii=None, visualize=False)` \\\\\n",
    "Daisy recorre la imagen de a \"step\" pixeles considerando cada paso un punto clave, en el cual considera un anillo el cual rodea de otros anillos. Lo rodea con \"rings\" anillos de radio \"radius\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dYebFH37Maxk"
   },
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xhyffrzHMeaI"
   },
   "source": [
    "A fines de elaboración, configuramos qué queremos que se recalcule y qué queremos usar desde Drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4Yf4eJyrMZrF"
   },
   "outputs": [],
   "source": [
    "recalcular_descriptores_daisy = False\n",
    "guardar_descriptores_daisy = False\n",
    "recalcular_descriptores_sift = False\n",
    "guardar_descriptores_sift = False\n",
    "\n",
    "recalcular_pipeline = False\n",
    "recalcular_test = True\n",
    "recalcular_mejores = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZM1ASQ3EMzXp"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lE54owhHuXFi",
    "outputId": "69a78c8e-4e42-4dec-f1b7-3f703e4b3314"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.feature import SIFT\n",
    "from skimage.feature import daisy\n",
    "from skimage.transform import resize\n",
    "\n",
    "\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import time\n",
    "import glob\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import math\n",
    "import random\n",
    "\n",
    "import pickle\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuración para gráficos\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "print(\"✅ Librerías importadas correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IdZTwNe1-XUy"
   },
   "source": [
    "### ***UTIL***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AG_uJzY4-Wfi"
   },
   "outputs": [],
   "source": [
    "def indicesDeCategoriaEnLista(etiquetas, categoria):\n",
    "  \"\"\"Devuelve los indices donde la etiqueta sea igual que la categoria\"\"\"\n",
    "  return [j for j, etiq in enumerate(etiquetas) if etiq == categoria]\n",
    "\n",
    "def indexadoIndirecto(idx, lista_indices, lista_principal):\n",
    "  \"\"\"Devuelve el resultado de indexar indirectamente una lista\"\"\"\n",
    "  return lista_principal[lista_indices[idx]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ONFwxkt5FiL5"
   },
   "source": [
    "### ***1. Carga y Exploración del Dataset***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v5uyKcQO4rVb"
   },
   "source": [
    "**Uso del Drive**\n",
    "\n",
    "Al tratarse de un dataset con tantos elementos, recomendamos utilizar el dataset directamente desde drive en vez de cargarlo cada vez que quieran trabajar con el. Intenten que todos los participantes del grupo lo tengan en el misma direccion para hacer mas fluido su trabajo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f0dHIdnRJm03"
   },
   "source": [
    "Data set: [Rock Paper Scissors](https://www.kaggle.com/datasets/drgfreeman/rockpaperscissors?select=scissors)\n",
    "\n",
    "Para los archivos .pkl: ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2DYwAXoTT10-",
    "outputId": "fbe3fd2e-7122-4fac-ef10-83d0700d9af1"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ouhzSGcC7r-T"
   },
   "outputs": [],
   "source": [
    "def pathDeArchivoPorCategoria(data_path, categoria):\n",
    "  \"\"\"\n",
    "  Devuelve la direccion de todos las imagenes en la carpeta de la categoria\n",
    "\n",
    "  Returns:\n",
    "    archivos: una lista con cada una de las direcciones de archivos.\n",
    "  \"\"\"\n",
    "\n",
    "  categoria_path = os.path.join(data_path, categoria)\n",
    "\n",
    "  archivos = glob.glob(os.path.join(categoria_path, \"*.jpg\")) + \\\n",
    "             glob.glob(os.path.join(categoria_path, \"*.jpeg\")) + \\\n",
    "             glob.glob(os.path.join(categoria_path, \"*.png\"))\n",
    "\n",
    "  return archivos\n",
    "\n",
    "def cargarImagenPorArchivo(archivo):\n",
    "  \"\"\"\n",
    "  Devuelve la imagen cargada en blanco y negro, habiendo sido reescalada si fuera necesario.\n",
    "\n",
    "  Returns:\n",
    "    img: La imgen cargada por Archivo.\n",
    "  \"\"\"\n",
    "\n",
    "  img = imread(archivo, as_gray=True)\n",
    "\n",
    "  # Redimensionar si es necesario (opcional)\n",
    "  if img.shape[0] > 400 or img.shape[1] > 400:\n",
    "    img = resize(img, (300, 300), anti_aliasing=True)\n",
    "\n",
    "  return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7rzFNceOHqJD"
   },
   "outputs": [],
   "source": [
    "def cargarDataSet(data_path, categorias):\n",
    "  \"\"\"\n",
    "  Carga todas las imágenes del dataset organizadas por categoría\n",
    "\n",
    "  Returns:\n",
    "    imagenes: lista de imágenes en escala de grises\n",
    "    etiquetas: lista de etiquetas correspondientes\n",
    "    nombres_archivo: lista con nombres de archivos para referencia\n",
    "  \"\"\"\n",
    "\n",
    "  imagenes = []\n",
    "  etiquetas = []\n",
    "  nombres_archivo = []\n",
    "\n",
    "  print(f\"Cargando dataset desde: {data_path}\")\n",
    "\n",
    "  # Cargamos las imagenes de cada Categoria\n",
    "  for categoria in categorias:\n",
    "\n",
    "    archivos = pathDeArchivoPorCategoria(data_path, categoria)\n",
    "    archivos = archivos\n",
    "\n",
    "    print(f\"  {categoria}: {len(archivos)} imágenes\")\n",
    "\n",
    "    for archivo in tqdm(archivos, desc=f\"Cargando {categoria}\"):\n",
    "\n",
    "      try:\n",
    "        img = cargarImagenPorArchivo(archivo)\n",
    "        imagenes.append(img)\n",
    "        etiquetas.append(categoria)\n",
    "        nombres_archivo.append(os.path.basename(archivo))\n",
    "\n",
    "      except Exception as e:\n",
    "        print(f\"Error cargando {archivo}: {e}\")\n",
    "\n",
    "  return imagenes, etiquetas, nombres_archivo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pfWKlbQV8I2k"
   },
   "source": [
    "***CARGA***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UmAutaM4w-9Y"
   },
   "source": [
    "### ADAPTAR CATEGORIAS, COLORES y PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "cc30a9566ce94590b84acf2d07a0baa6",
      "0809f9dbdd5147ba98f16b4e0022afd0",
      "dd74bf48283d47bd80778c4a4e8dbd74",
      "c5578032f16c4fca95cde683619c9a62",
      "5037ad16612f40f19b45025d4805c9eb",
      "f27adc22788c43f88e54223fdc47db61",
      "698aca425b314d2d956d67628179eecd",
      "98682a8932854bf9a0ddf46622f73b45",
      "99f78703f07d4f2683d086a08d5a33bd",
      "bfeda72fa59c44778472e57336a10d29",
      "462b02c290604ef89b6201716e809eb0",
      "f9032f5765cc4c8bae34cb0e07a67095",
      "a499b15c438440b49b16d172c6ca31f2",
      "09e4d42edb5840459e7e6e376b565750",
      "16b553d31efc41bd8ac260e81c5d6490",
      "9f1ad479e33245d8bc9f6df147d555c7",
      "62aec17acb194d0bae8f599d6f12718f",
      "6446dd3d6407420294026d43e99dbe5e",
      "acbbc6cd530e4341a9aebf4ef3b113c5",
      "4dbbd0d5fe5940caa8c4dac5cd0987bd",
      "9b58025d52f445cd92ce52c716c66b91",
      "1d8b75330a694f8cbd5ec51fb3c97d80",
      "786a2ef1b4cc4df19205d51ae676fd34",
      "ba3a82d66dd94137a257d165edfff249",
      "4d16c613354043f6909a0c0a53ec706d",
      "342dd910b5584678ac98384338dac02b",
      "a3273dfd6fa24191ba59cc3a809255ce",
      "c48be1bd51d442249ce794dbbd08ba92",
      "411c21d08ccc4bfbb8d2de94bc531676",
      "67545bf46a9a4ab781f052ed9d3d05d8",
      "34451ee58188413690cf0fbbc1d982f4",
      "8997de8f99f74ac68a02b6894e0bfa87",
      "039313e485534d3389812bcedf1c8133",
      "cf6f6f447de44ebd91dbfaae5b712ef3",
      "d171e61bcfd34322beb156795726ad6e",
      "a02b0216aa5848daa82a1669cd95f014",
      "b9a6bf834ac14c64a6a553f2d78dd5e1",
      "2ecfd2638a514ca09c3a0f601e24ac4e",
      "f0ad787ae884452f94b33242ebaef699",
      "fe86d3c755604c7696a6ae9ba7eec2ff",
      "b68c133538e64f519b9b8b466d08986a",
      "a217da57c65b454088291ec1fd9d04c8",
      "2049b65899fa426b80d5e328b8e846e6",
      "bdb4143e99de4f65a5bb36aad9632086",
      "badf2cc70f57400d81645e3ef930046c",
      "805dc709d09d4a28a91b55467be47348",
      "e8c049ccdfd14545b7fadcb74552791e",
      "7ac1e05b5f594ce6ab1768d7b1964b2c",
      "6d23da72ec6d4c1ebe517c2c70cf3b8d",
      "5cf656c013954633ba69632d5f624c4a",
      "e00340dfdf5847acbe514291a4b5c91a",
      "45d0b3912c484f6d825a771a7b6c3548",
      "ffdfac113f164c4fae16092a853372cf",
      "57cdd87927d44dc78634600c2f65ce09",
      "3ec49190b50d4b6dadad6b17010bc6e1",
      "b44af2ebc763462d911b037a2eee977d",
      "3acab2bfb98e43d6916f256e33017272",
      "d61f35eb414040ba8dd2a5252216c5de",
      "f43baf77dc0e4c2bb88ac1666d610efb",
      "55910c74abf04b36a2b58d56a3659456",
      "6abeac5832454f54a30945b21abd3b75",
      "d628621c423941f3955f2ade4bb9cceb",
      "f4a846fe547c4903b4bc539a3b130925",
      "8ffc1cb4b91e4f56b8d741cb7a5ebe5c",
      "5b1495d3f3224e2ab6cd4c521f589fef",
      "db36bdd4436040d4ae156db67c0ca87a",
      "15a661c31740463e8a72e726dcfcc406",
      "7f15f9bdb48a49d8b51b966283b6f09c",
      "6ff34a52f44e41fcac2446e7af88914a",
      "6b4d430e45974949914ee6674847879d",
      "62146fe52eba4895980423f322c1f2ac",
      "399daeb5ff604e47be273d5aee348ff2",
      "29bed6112cbb410ab90630d269f0db3f",
      "a8b48dfe825e4dcd884f7ad1a37525be",
      "df168da2c77d42a48510d30b93e0b3ed",
      "42c5fdbf607844599b12125ab805f97d",
      "6a575aecf64a49ce9f6909873deca256",
      "5671b0ec4ca44568a400a4afa3817e12",
      "3a6727e9fe334e34a7c63c40635cbcf4",
      "6cdbba6c5d8547a2894978029b33bb31",
      "36014aa576bf40219828fd548f660b70",
      "56f0b67e77504b67a05aceb4ac87b89a",
      "efef8c272d8144d980ca1a28e0a13a79",
      "e76fbd0393614d09947e4a423d9a05bf",
      "3c19090f33b64da19d666f620bc30a15",
      "7562bc4b621f40b09f6b0896a4d5d30a",
      "b8cd990c2aa14bdbb55df48538326deb",
      "3d8d9eb0540b4419bffcc046b0d4f463",
      "bb33c1210c4145c5af00db781fcbb44c",
      "a8500397354048e19e73c8d87548b533",
      "7b75f0c04cea4a44b7d7f5a485b0661e",
      "75a42d5d1c3645ffaa8e4f157b9a28a0",
      "d588e37ffaa2432a9402dd8c1b597c86",
      "93a7bf180920424b86d4abe5c5f19c0e",
      "54325abe631d43fd87cdbe1b3690d98d",
      "824d3129bb7a4d3a92e6fc9af94e2f74",
      "16f2078ea0f44a80976775b56b0dd747",
      "bd1c6a5ef9ce4dd2bef3180bdc71834e",
      "bcde9d1a993c47d6be586a9b8c593416",
      "9596c62019364cc9a3427dc6c8b58b83",
      "d745647ca6554c979dd5008a4f332961",
      "52ec1985473347b2b9272c009dda2b93",
      "a54f65569e9c40ddaa9476272862b61e",
      "36a780239cc845b0b34a84f627b1cc5e",
      "1e387227c3c648ba9d53e4c4fdd95dfd",
      "2dbab99f077a429d92a7869b9965cac6",
      "e54a957ff017431a95fa7816af9797cf",
      "8913b13ffa484341a3dbd2068379e269",
      "beb1e94b80734d2cab632d4bac205547",
      "0126a565ba0442dcabb5b41c55775eb0",
      "61e06131252943dc80371e4546e9c020",
      "c0e1f8574f6c494698e9e3434eef3a97",
      "700736e8fd094b54bfa54973fed543e2",
      "e6c388866f5e4eada75b1e71d244abf4",
      "52ed19b750434431bdc23cbe373f1738",
      "ebd8a01d06934e7aaf7cdcef618f5681",
      "ba8936a0e3df4123b854d3a76ca1df68",
      "a8d94eb30ad442e9a7cb067b869a880e",
      "a5c6c66801f640178f02a41ea4bcac29",
      "8dc7a75addc04c94b3f3bece28de66e9",
      "f2e7110a375e4ccb948fff6f7d6080e1",
      "e2f470a3ccb24ef2bf6fed2a7a1edaf9",
      "8949bc354df84e6b98af85ce4477fc97",
      "173cd282e77547ac9c3a28b716267399",
      "c4df709a1c7949b7bf662c52c9252851",
      "8e24c27d38bf4342bc1fb437c060e3d4",
      "7dd73f4d4e9043309f7652c1f7769da0",
      "60825205c1934bf7b047ca2b2a066c87",
      "0d0b62ee202a4d768551d99380dabf1e",
      "5116802ee6c6476c9ce443c66c3a83c2",
      "9fbb38b9514d43e9a958e57363c34535",
      "d297fa8490c14b4cb9e7e0da1a21a091",
      "4a50db08f4a0406dad0124bd0e409e11",
      "59e25030a04741caa14ecef5c109d585",
      "fbed0c81413345ea93dac48819f15b35",
      "e77e193e116f4bf9b09904dbaf6032f9",
      "8c2e228a327843adb95d7bdd28befc78",
      "20317480538a47999fee2d3012a40f71",
      "31e9ff1307a244b2818facd333f2f6ee",
      "16219a0e74484855b27ac73659e6d400",
      "29def3a38fc9423b99020358a865f2f5",
      "a14a7c258fad4f3bbf8a6b7a3cc77fc8",
      "408673b7be174ea0848cd5a6ee838c0a",
      "6cfacacace4b4fd8b6d9d88b360ca47c",
      "c4bcc467f4644b61ba1c2d93c02a2166",
      "837c27de932d4fa8affc4476c98cfa07",
      "a12e37c3d5c644f8a46b59f0b8ace995",
      "05f424a58f144b68a5e3d42d6a37a3a3",
      "c03a4f1b8b68426d8897298b1fae0bc6",
      "75a12e4ee7a040c8895671542bc8dd3e",
      "fc1e652d1da34eacb307fe9be12e3c1f",
      "e6d2a0aed4e4420a9d65ec1b2f97c495",
      "9d5efb1803934babbfcaa6c1ea96ab30",
      "281891e13eeb4933a720efd05b548a89",
      "2f256a20d2ac42099d94a82ff4231bf9",
      "ef6236b0b0d3448292ff2a5acb81fb48",
      "0d678e53dfd145f1911fdee116d4cac2",
      "df6b379a01b4482680e82bd1b5bdffe9",
      "a86b1dd9c00346cbb2741470555b6fd2",
      "9fa503db295249a4bfede71a9ccb7bf3",
      "d9029607954f4817a8b86e7fbc41b453",
      "8834d785b8fd43d3acea48906eecb826",
      "3cdee13cea274ec8bfedb8cfb2ad4cbd",
      "e3cafd518f8540c294a6b860b7fd7ee8",
      "d18334c188d24029be9aaef85a50236d",
      "03b16308bbc440ceb2519beb232f1c08",
      "31444eb58c1942e8b27776e148c6e3ee",
      "07cbb2a1c24c4b4aa2fd133dbe673f70",
      "ce65b1b3066e4c84aa5d7cd5afdeebd3",
      "b04f91ba588c45e98062a18117a59012",
      "aff38ba8914d4141b06917d0c3674c47",
      "4a12da886b8c428e86fea679e8bda75f",
      "99bee4773d5f4215812a2543ebafb3d7",
      "74a7c31f7ae6411795b0eab219ad05dc",
      "fd9a1821eb8e4164a991fdc225f2017a",
      "da591329fb9a452bbe204dfc7e8fd5af",
      "8939cc49bd5f4652a40da36f2eca796a",
      "6f1f354bfd39461f901e3c886ba36f4b",
      "13661bc4255d4c12b9c803eb3e2af249",
      "5aba2492208b4682b1b7c60f08571081",
      "e144dc74053d49cb82d3dded409f51ef",
      "e1ae2e01226748ada81ec175ef55d6da",
      "6c5f4451425e4e9eb81b1a30923bf48e",
      "2119be0643754b23b29a6641f4262f19",
      "5675a695b7f84fc8b3ab706a63d0df65",
      "427c04fc912c4f23b79307b936786f58",
      "9dc84710411a402db49c3121cdba1501",
      "a7551f24e029453d9255baf5f8990f72",
      "c51450c6eb1b4203bf0cc8cf14e5df1c",
      "32bed0a105954f5abf3f77382936be35",
      "08e1a26f64d7404d8cdba5fd5414ffbb",
      "91517b636f4e495e9bce2f69fe22e528",
      "918997f11eb04dcab61f8a0694498967",
      "f4e29d2e89e348e68c8915d4b41c03fe",
      "e11d3fbbfa99451f8a51836d08eb494e",
      "d7a345db54214834b35ff778ffa076d2",
      "f7b91e5dfdea4b50a90055e718b1ebd4",
      "3e45b886210f4a758f1bebb776aeab60",
      "7342582e8a1f4d84bfaaf0e9031c32bc",
      "71942881d6814966869f9216771476a3",
      "9189c28bb23140f3b4ceea910b946379",
      "e0d9273ab7b84f4d90a4abc79e79339f",
      "e760074871554970a9aefcc83c36fc10",
      "514933ed4f8e408fb097af22cb70255c",
      "a56c08d5f7c642309fe4d839e940b36b",
      "aa8033aade67440ab6587d0ebdb01a5d",
      "f7ceaf8a42934d7ca5741a452a61ecf5",
      "f573c17be1eb48c087d887b6ec0578c5",
      "8a9b9962ac38432b833cb87447563958",
      "37d4c6b808154086887ccb48d1a1165d",
      "f55d7fae8c6f4082bb50970325a76abc",
      "8a1405d4cb0a49328d689eb102192711",
      "324366f6a1b743cf96385a810b783e56",
      "981380ad3f7647df8353021a6b3b720c",
      "33bdd9cdd935456484ca02a744315a94",
      "64ffa6a6d8364136b3ce09b95eb22972",
      "9d4e07a5e43f4859b289857685a9616e",
      "043bac131d394d3b923499a1255f5e1b",
      "06ef647f6cd0452b9f03e74d8789b8d4",
      "615c1270211649ceb476e558eda1795d"
     ]
    },
    "id": "qJWXjZfZGDDq",
    "outputId": "56f219b2-3f6e-40b4-c5ed-f9dc91e5e4b8"
   },
   "outputs": [],
   "source": [
    "# Definir categorías de especies\n",
    "CATEGORIAS = ['paper', 'rock', 'scissors']\n",
    "COLORES_CATEGORIAS = ['#9e0142', '#d53e4f', '#f46d43']\n",
    "\n",
    "# Paths del dataset\n",
    "DATA_PATH = \"dataset/\"\n",
    "TRAIN_PATH = os.path.join(DATA_PATH, \"train\")\n",
    "TEST_PATH = os.path.join(DATA_PATH, \"test\")\n",
    "\n",
    "# Cargar datasets de entrenamiento y prueba\n",
    "print(\"=\" * 50)\n",
    "print(\"CARGANDO DATASET DE ENTRENAMIENTO\")\n",
    "print(\"=\" * 50)\n",
    "imagenes_train, etiquetas_train, nombres_train = cargarDataSet(TRAIN_PATH, CATEGORIAS)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"CARGANDO DATASET DE PRUEBA\")\n",
    "print(\"=\" * 50)\n",
    "imagenes_test, etiquetas_test, nombres_test = cargarDataSet(TEST_PATH, CATEGORIAS)\n",
    "\n",
    "print(f\"\\n📊 RESUMEN DEL DATASET:\")\n",
    "print(f\"Training: {len(imagenes_train)} imágenes\")\n",
    "print(f\"Testing: {len(imagenes_test)} imágenes\")\n",
    "print(f\"Total: {len(imagenes_train) + len(imagenes_test)} imágenes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gBo7kCmOxHzy"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wpTBy6pW81G7"
   },
   "source": [
    "***VISUALIZACION***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GNTBhEU9TsZE"
   },
   "outputs": [],
   "source": [
    "# Visualización de ejemplos del dataset\n",
    "def mostrarEjemplosDataSet(imagenes, etiquetas, categorias, n_ejemplos=2):\n",
    "  \"\"\"Muestra ejemplos de cada categoría del dataset\"\"\"\n",
    "\n",
    "  fig, axes = plt.subplots(len(categorias), n_ejemplos, figsize=(15, 12))\n",
    "  fig.suptitle('Ejemplos del Dataset por Categoría', fontsize=16, fontweight='bold')\n",
    "\n",
    "  for i, categoria in enumerate(categorias):\n",
    "    # Encontrar índices de esta categoría\n",
    "    indices_categoria = indicesDeCategoriaEnLista(etiquetas, categoria)\n",
    "    random.shuffle(indices_categoria)\n",
    "\n",
    "    # Mostramos imagenes de Ejemplos por categoria\n",
    "    for j in range(n_ejemplos):\n",
    "\n",
    "        img = indexadoIndirecto(j, indices_categoria, imagenes)\n",
    "        axes[i, j].imshow(img, cmap='gray', clim=(0,1))\n",
    "        axes[i, j].set_title(f'{categoria}', fontweight='bold')\n",
    "        axes[i, j].axis('off')\n",
    "\n",
    "  plt.tight_layout()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "hMj-jye9Txl1",
    "outputId": "3a7b961e-de52-4f59-8cbc-d9e76fb782db"
   },
   "outputs": [],
   "source": [
    "mostrarEjemplosDataSet(imagenes_test, etiquetas_test, CATEGORIAS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jlQ_1Pt1FlkB"
   },
   "source": [
    "### ***2. Extracción de Características Daisy***\n",
    "Con las imagenes cargadas, empezaremos por extraer cada uno de sus keypoints y descriptores de Daisy correspondientes. Luego utilizaremos estos datos para crear nuestras palabras visuales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R-yRms4lWBEJ"
   },
   "outputs": [],
   "source": [
    "def extraerDaisyDataSet(imagenes, step = 16, image_index=0, **kwargs):\n",
    "    keypoints = []\n",
    "    descriptores = []\n",
    "    stats = {cat: {'total_keypoints': 0, 'promedio_keypoints': 0} for cat in CATEGORIAS}\n",
    "\n",
    "    for i, img in enumerate(imagenes):\n",
    "      if i == image_index:\n",
    "        desc, image_daisy = daisy(img, step=step, visualize=True, **kwargs)\n",
    "        plt.imsave('daisy_visualizacion.png', image_daisy, cmap='gray')\n",
    "      else:\n",
    "        desc = daisy(img, step = step , **kwargs)\n",
    "\n",
    "      desc_flat = desc.reshape(-1, desc.shape[-1]).astype(np.float32)\n",
    "      descriptores.append(desc_flat)\n",
    "\n",
    "      # Guardar los keypoints (coordenadas de la grilla)\n",
    "      x, y = np.meshgrid(np.arange(0, img.shape[1], step), np.arange(0, img.shape[0], step))\n",
    "      puntos = np.vstack([x.ravel(), y.ravel()]).T\n",
    "      keypoints.append(puntos)\n",
    "      # Estadísticas\n",
    "\n",
    "      stats[CATEGORIAS[i % len(CATEGORIAS)]]['total_keypoints'] += len(desc_flat)\n",
    "    # Calcular promedios\n",
    "    for cat in CATEGORIAS:\n",
    "        stats[cat]['promedio_keypoints'] = stats[cat]['total_keypoints'] / max(1, sum([1 for e in imagenes if cat in str(e)]))\n",
    "    return keypoints, descriptores, stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nizj_eiHa6Dy",
    "outputId": "843e3ce7-f49f-4ff1-bb94-ce3d1c011715"
   },
   "outputs": [],
   "source": [
    "if recalcular_descriptores_daisy:\n",
    "\n",
    "  # Extraer Daisy del dataset de entrenamiento\n",
    "  print(\"\\n\" + \"=\" * 50)\n",
    "  print(\"EXTRACCIÓN DE CARACTERÍSTICAS Daisy - TRAINING\")\n",
    "  print(\"=\" * 50)\n",
    "\n",
    "  keypoints_train_daisy, descriptores_train_daisy, stats_train_daisy = extraerDaisyDataSet(imagenes_train, step=45, image_index = 5, radius=30, rings=2, histograms=6, orientations=8)\n",
    "\n",
    "  if guardar_descriptores_daisy:\n",
    "    # Guardamos así no lo calculamos todo el tiempo\n",
    "    ruta = 'daisy_train.pkl'\n",
    "    with open(ruta, 'wb') as f:\n",
    "      pickle.dump((keypoints_train_daisy, descriptores_train_daisy, stats_train_daisy), f)\n",
    "\n",
    "  # Mostrar estadísticas\n",
    "  print(\"\\n📊 ESTADÍSTICAS DE EXTRACCIÓN Daisy:\")\n",
    "  for categoria in CATEGORIAS:\n",
    "    total = stats_train_daisy[categoria]['total_keypoints']\n",
    "    promedio = stats_train_daisy[categoria]['promedio_keypoints'] # corregir promedio\n",
    "    print(f\"{categoria}: {total} keypoints total, {promedio:.1f} promedio por imagen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2NYLQIqnzNOn"
   },
   "outputs": [],
   "source": [
    "if not recalcular_descriptores_daisy:\n",
    "\n",
    "   # Cargar los resultados\n",
    "\n",
    "  ruta = 'daisy_train.pkl'\n",
    "\n",
    "  with open(ruta, 'rb') as f:\n",
    "    keypoints_train_daisy, descriptores_train_daisy, stats_train_daisy = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraerSIFTImagen(imagen):\n",
    "  \"\"\"\n",
    "  Extrae características SIFT de una imagen\n",
    "\n",
    "  Returns:\n",
    "    keypoints: coordenadas de los puntos clave\n",
    "    descriptores: descriptores SIFT (128 dimensiones cada uno)\n",
    "  \"\"\"\n",
    "\n",
    "  sift = SIFT()\n",
    "\n",
    "  sift.detect_and_extract(imagen)\n",
    "\n",
    "  return sift.keypoints, sift.descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraerSIFTDataSet(imagenes, etiquetas):\n",
    "  \"\"\"\n",
    "  Extrae SIFT de todo el dataset\n",
    "\n",
    "  Returns:\n",
    "    keypoints_dataset: lista de keypoints por imagen\n",
    "    descriptores_dataset: lista de descriptores por imagen\n",
    "    estadisticas: diccionario con estadísticas de extracción\n",
    "  \"\"\"\n",
    "\n",
    "  keypoints_dataset = []\n",
    "  descriptores_dataset = []\n",
    "\n",
    "  # Estadísticas por categoría\n",
    "  stats = {cat: {'total_keypoints': 0, 'num_images': 0} for cat in CATEGORIAS}\n",
    "\n",
    "  print(\"Extrayendo características SIFT...\")\n",
    "\n",
    "  # i: indice | img: imagen correspondiente | etiqueta: etiqueta correspondiente\n",
    "  for i, (img, etiqueta) in enumerate(tqdm(zip(imagenes, etiquetas), total=len(imagenes))):\n",
    "\n",
    "    keypoints, descriptores = extraerSIFTImagen(img)\n",
    "\n",
    "    keypoints_dataset.append(keypoints)\n",
    "    descriptores_dataset.append(descriptores)\n",
    "\n",
    "    # Actualizar estadísticas\n",
    "    stats[etiqueta]['total_keypoints'] += len(keypoints)\n",
    "    stats[etiqueta]['num_images'] += 1\n",
    "\n",
    "  # Calcular promedios\n",
    "  for categoria in stats:\n",
    "    if stats[categoria]['num_images'] > 0:\n",
    "      stats[categoria]['promedio_keypoints'] = stats[categoria]['total_keypoints'] / stats[categoria]['num_images']\n",
    "\n",
    "  return keypoints_dataset, descriptores_dataset, stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if recalcular_descriptores_sift:\n",
    "\n",
    "  # Extraer Daisy del dataset de entrenamiento\n",
    "  print(\"\\n\" + \"=\" * 50)\n",
    "  print(\"EXTRACCIÓN DE CARACTERÍSTICAS Sift - TRAINING\")\n",
    "  print(\"=\" * 50)\n",
    "\n",
    "  keypoints_train_sift, descriptores_train_sift, stats_train_sift = extraerSIFTDataSet(imagenes_train, etiquetas_train)\n",
    "\n",
    "  if guardar_descriptores_daisy:\n",
    "    # Guardamos así no lo calculamos todo el tiempo\n",
    "    ruta = 'sift_train.pkl'\n",
    "    with open(ruta, 'wb') as f:\n",
    "      pickle.dump((keypoints_train_sift, descriptores_train_sift, stats_train_sift), f)\n",
    "\n",
    "  # Mostrar estadísticas\n",
    "  print(\"\\n📊 ESTADÍSTICAS DE EXTRACCIÓN Sift:\")\n",
    "  for categoria in CATEGORIAS:\n",
    "    total = stats_train_sift[categoria]['total_keypoints']\n",
    "    promedio = stats_train_sift[categoria]['promedio_keypoints'] # corregir promedio\n",
    "    print(f\"{categoria}: {total} keypoints total, {promedio:.1f} promedio por imagen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not recalcular_descriptores_sift:\n",
    "\n",
    "   # Cargar los resultados\n",
    "\n",
    "   ruta = 'sift_train.pkl'\n",
    "\n",
    "   with open(ruta, 'rb') as f:\n",
    "     keypoints_train_sift, descriptores_train_sift, stats_train_sift = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tD0qb7K4FCB9"
   },
   "source": [
    "***VISUALIZACION***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364
    },
    "collapsed": true,
    "id": "B4WNAXv0GE98",
    "outputId": "69a52396-9a85-4981-8eb2-a727400032f5"
   },
   "outputs": [],
   "source": [
    "# Visualizar keypoints en ejemplos\n",
    "def mostrar_keypoints_ejemplos(imagenes, keypoints, etiquetas, categorias):\n",
    "  \"\"\"Muestra keypoints detectados en ejemplos de cada categoría\"\"\"\n",
    "\n",
    "  fig, axes = plt.subplots(2, len(categorias), figsize=(20, 10))\n",
    "  fig.suptitle('Keypoints Daisy detectados por categoría', fontsize=16, fontweight='bold')\n",
    "\n",
    "  for i, categoria in enumerate(categorias):\n",
    "    indices_categoria = indicesDeCategoriaEnLista(etiquetas, categoria)\n",
    "    random.shuffle(indices_categoria)\n",
    "\n",
    "    for row in range(2):\n",
    "      img = indexadoIndirecto(row, indices_categoria, imagenes)\n",
    "      kp = indexadoIndirecto(row, indices_categoria, keypoints)\n",
    "\n",
    "      # Imagen original\n",
    "      axes[row, i].imshow(img, cmap='gray')\n",
    "\n",
    "      # Keypoints\n",
    "      axes[row, i].scatter(kp[:, 0], kp[:, 1], s=10, c='red', alpha=0.7)\n",
    "\n",
    "      axes[row, i].set_title(f'{categoria} ({len(kp)} keypoints)')\n",
    "      axes[row, i].axis('off')\n",
    "\n",
    "  plt.tight_layout()\n",
    "  plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"VISUALIZACIÓN DE KEYPOINTS\")\n",
    "print(\"=\" * 50)\n",
    "mostrar_keypoints_ejemplos(imagenes_train, keypoints_train_daisy, etiquetas_train, CATEGORIAS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E5NzUbK8zsX8"
   },
   "source": [
    "### ***3. Cross Validation***\n",
    "\n",
    "Para poder encontrar los mejores parametros a usar en el categorizador sin caer en la trampa de **sobreajustarse a los datos de test**, utilizaremos la tecnica de **Cross Validation**.\n",
    "\n",
    "Dividiremos nuestro set de entrenamiento en 5 subsets balanceados en categoria y aleatorios. Por cada uno de los subsets, tomaremos el resto de los 4 para **entrenar un categorizador** utilizando los meta-parametros a testear (numero de clusters, batch size, etc) y los testearemos sobre el subset apartado.\n",
    "\n",
    "Por ultimo, utilizaremos la combinacion de meta-parametros que mejor accuracy hayan conseguido en **promedio**.\n",
    "\n",
    "Con esta tecnica aumentamos las chances de generalizar sin tener que aumentar los datos de entrenamiento, ya que estariamos eligiendo los parametros que mayor capacidad de generalizacion obtuvieron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2QrhgLZczsX8"
   },
   "outputs": [],
   "source": [
    "def getPorcionDeSubset(lista, indices_cat, cat_subset_inicio, cat_subset_fin):\n",
    "  \"\"\"\n",
    "    Devuelve una sublista del arreglo original siendo indexada indirectamente\n",
    "    por un arreglo con los indices de una categoria en especifico\n",
    "  \"\"\"\n",
    "\n",
    "  return [indexadoIndirecto(idx, indices_cat, lista) for idx in range(cat_subset_inicio, cat_subset_fin)]\n",
    "\n",
    "def crearSubsets(imagenes, etiquetas, nombres, keypoints, descriptores, n_subsets=5):\n",
    "  \"\"\"Devuelve una lista con los subsets creados al dividir el dataset de entrenamiento original\"\"\"\n",
    "\n",
    "  # Encontramos los indices que le pertenecen a cada categoria (3\n",
    "  # Encontramos cuantos item de cada categoria deberia haber por subset\n",
    "  indices_categorias = {cat: indicesDeCategoriaEnLista(etiquetas,cat) for cat in CATEGORIAS}\n",
    "  categoria_por_subset = {cat: math.ceil(len(indices_categorias[cat]) / n_subsets) for cat in CATEGORIAS}\n",
    "\n",
    "  # Reordenamos los indices de las categorias de forma aleatoria\n",
    "  for cat in CATEGORIAS:\n",
    "    random.shuffle(indices_categorias[cat])\n",
    "\n",
    "  subsets = []\n",
    "\n",
    "  for subset_index in range(n_subsets):\n",
    "    subset = {\n",
    "        'imagenes': [],\n",
    "        'etiquetas': [],\n",
    "        'nombres': [],\n",
    "        'keypoints': [],\n",
    "        'descriptores': [],\n",
    "        'stats': {cat: {'num_images': 0} for cat in CATEGORIAS}\n",
    "      }\n",
    "\n",
    "    for cat in CATEGORIAS:\n",
    "\n",
    "      cat_indices = indices_categorias[cat]\n",
    "      cat_subset_inicio = subset_index * categoria_por_subset[cat]\n",
    "      cat_subset_fin = min(cat_subset_inicio + categoria_por_subset[cat], len(indices_categorias[cat]))\n",
    "\n",
    "      cat_etiquetas = getPorcionDeSubset(etiquetas, cat_indices, cat_subset_inicio, cat_subset_fin)\n",
    "      cat_descriptores = getPorcionDeSubset(descriptores, cat_indices, cat_subset_inicio, cat_subset_fin)\n",
    "      cat_nombres = getPorcionDeSubset(nombres, cat_indices, cat_subset_inicio, cat_subset_fin)\n",
    "      cat_imagenes = getPorcionDeSubset(imagenes, cat_indices, cat_subset_inicio, cat_subset_fin)\n",
    "      cat_keypoints = getPorcionDeSubset(keypoints, cat_indices, cat_subset_inicio, cat_subset_fin)\n",
    "\n",
    "      subset['etiquetas'] += (cat_etiquetas)\n",
    "      subset['nombres'] += (cat_nombres)\n",
    "      subset['descriptores']+=(cat_descriptores)\n",
    "      subset['imagenes']+=(cat_imagenes)\n",
    "      subset['keypoints']+=(cat_keypoints)\n",
    "\n",
    "      subset['stats'][cat]['num_images'] = len(cat_imagenes)\n",
    "\n",
    "    subsets.append(subset)\n",
    "\n",
    "  return subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m4mu2UhazsX9",
    "outputId": "17c14bf5-21ef-4a87-82d6-c23c6a07b30f"
   },
   "outputs": [],
   "source": [
    "subsets_daisy = crearSubsets(imagenes_train, etiquetas_train, nombres_train, keypoints_train_daisy, descriptores_train_daisy)\n",
    "subsets_sift = crearSubsets(imagenes_train, etiquetas_train, nombres_train, keypoints_train_sift, descriptores_train_sift)\n",
    "\n",
    "for i in range(len(subsets_daisy)):\n",
    "    subset = subsets_daisy[i]\n",
    "\n",
    "    print(f\"Subset {i}\")\n",
    "    print(f\"Imagenes Totales: {len(subset['etiquetas'])}\")\n",
    "\n",
    "    for categoria in CATEGORIAS:\n",
    "      print(f\"\\t{categoria}: {subset['stats'][categoria]['num_images']} imagenes\")\n",
    "\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1TvXuV2qzsX9"
   },
   "outputs": [],
   "source": [
    "def imagenesDeEjemploSubSet(subset, n_ejemplos=4):\n",
    "  \"\"\"Muestra ejemplos de cada categoría del subset\"\"\"\n",
    "\n",
    "  fig, axes = plt.subplots(len(CATEGORIAS), n_ejemplos, figsize=(15, 12))\n",
    "  fig.suptitle('Ejemplos del Sub Dataset por Categoría', fontsize=16, fontweight='bold')\n",
    "\n",
    "  for i, categoria in enumerate(CATEGORIAS):\n",
    "    # Encontrar índices de esta categoría\n",
    "    indices_categoria = indicesDeCategoriaEnLista(subset['etiquetas'], categoria)\n",
    "    random.shuffle(indices_categoria)\n",
    "\n",
    "    # Mostramos imagenes de Ejemplos por categoria\n",
    "    for j in range(n_ejemplos):\n",
    "\n",
    "        img = indexadoIndirecto(j, indices_categoria, subset['imagenes'])\n",
    "        axes[i, j].imshow(img, cmap='gray', clim=(0,1))\n",
    "        axes[i, j].set_title(f'{categoria}', fontweight='bold')\n",
    "        axes[i, j].axis('off')\n",
    "\n",
    "  plt.tight_layout()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 803
    },
    "collapsed": true,
    "id": "tQsmqgekzsX9",
    "outputId": "e806d804-9019-49cf-9c93-2e66999e3ed5"
   },
   "outputs": [],
   "source": [
    "imagenesDeEjemploSubSet(subsets_daisy[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TT-j_d5TzsX9"
   },
   "outputs": [],
   "source": [
    "def unirSubsets(subsets):\n",
    "  \"\"\"Devuelve un subset conformado por la union de los subset en la lista\"\"\"\n",
    "\n",
    "  subset_union = {\n",
    "        'imagenes': [],\n",
    "        'etiquetas': [],\n",
    "        'nombres': [],\n",
    "        'keypoints': [],\n",
    "        'descriptores': [],\n",
    "        'stats': {cat: {'num_images': 0} for cat in CATEGORIAS}\n",
    "      }\n",
    "\n",
    "  for subset in subsets:\n",
    "\n",
    "    subset_union['etiquetas'] += subset['etiquetas']\n",
    "    subset_union['nombres']+= subset['nombres']\n",
    "    subset_union['descriptores']+= subset['descriptores']\n",
    "    subset_union['imagenes']+= subset['imagenes']\n",
    "    subset_union['keypoints']+= subset['keypoints']\n",
    "\n",
    "    for cat in CATEGORIAS:\n",
    "      subset_union['stats'][cat]['num_images'] += len(subset['etiquetas'])\n",
    "\n",
    "  return subset_union\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZdrKNAG0Fr9C"
   },
   "source": [
    "### ***4. Creación del Vocabulario Visual***\n",
    "\n",
    "Ya teniendo los descriptores, podemos clasificarlos para comprender que keypoints eran similares a traves de las imagenes y empezar a hablar sobre el contenido de ellas.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "***Construccion de Vocabulario Visual*** ➡️ *Representacion BOW* ➡️ *Procesamiento de la Representacion* ➡️ *Entrenamiento de Categorizador* ➡️ *Validacion*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eO1OjqnVmdPB"
   },
   "outputs": [],
   "source": [
    "# Crear matriz global de descriptores para clustering\n",
    "def crearMatrizDescriptores(descriptores_dataset):\n",
    "    \"\"\"\n",
    "    Combina todos los descriptores en una matriz global para poder realizar clustering\n",
    "    Donde cada fila es un descriptor\n",
    "    \"\"\"\n",
    "    matriz_descriptores = []\n",
    "\n",
    "    for descriptores_imagen in descriptores_dataset:\n",
    "      matriz_descriptores.append(descriptores_imagen)\n",
    "\n",
    "    matriz_descriptores = np.vstack(matriz_descriptores)\n",
    "\n",
    "    return matriz_descriptores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XnZOssGkmA4N"
   },
   "outputs": [],
   "source": [
    "def construirVocabularioAgglomerativeClustering(descriptores, n_clusters=100, metric='euclidean', linkage='ward'):\n",
    "    \"\"\"\n",
    "    Construye vocabulario visual usando Agglomerative Clustering.\n",
    "\n",
    "    Returns:\n",
    "        modelo: objeto con labels y centroides de los clusters\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"Construyendo vocabulario con Agglomerative Clustering (n_clusters={n_clusters})...\")\n",
    "    modelo = AgglomerativeClustering(n_clusters=n_clusters, linkage=linkage)\n",
    "    labels = modelo.fit_predict(descriptores)\n",
    "\n",
    "\n",
    "    centroides = np.zeros((n_clusters, descriptores.shape[1]), dtype=np.float32)\n",
    "    for i in range(n_clusters):\n",
    "        grupo = descriptores[labels == i]\n",
    "        if len(grupo) > 0:\n",
    "            centroides[i] = grupo.mean(axis=0).astype(np.float32)\n",
    "\n",
    "    return {\"modelo\": modelo, \"centroides\": centroides}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construirVocabularioMiniBatchKMeans(descriptores, k=200, batch_size=1024, random_state=42):\n",
    "  \"\"\"\n",
    "  Construye vocabulario visual usando K-means\n",
    "\n",
    "  Args:\n",
    "    descriptores: matriz de descriptores\n",
    "    k: número de clusters (palabras visuales)\n",
    "    batch_size: Cantidad de keypoints aleatorios que utilizara para encontrar los clusters (chico para hacer pruebas, luego incrementar)\n",
    "    random_state: semilla para reproducibilidad\n",
    "\n",
    "  Returns:\n",
    "    kmeans: Categorizador K-Means entrenado para categorizar los descriptores a su centroido mas cercano\n",
    "  \"\"\"\n",
    "  print(f\"Construyendo vocabulario con k={k} palabras visuales...\")\n",
    "\n",
    "  kmeans = MiniBatchKMeans(\n",
    "      n_clusters=k,\n",
    "      random_state=random_state,\n",
    "      batch_size=batch_size,\n",
    "      max_iter=300,\n",
    "      n_init=5,\n",
    "      verbose=0\n",
    "      )\n",
    "\n",
    "  kmeans.fit(descriptores)\n",
    "\n",
    "  return kmeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WXS34Uq1FyRE"
   },
   "source": [
    "### ***5. Representación Bag of Words***\n",
    "Ya teniendo nuestro corpus o palabras visuales, podremos empezar a re-describir nuestras imagenes segun este. Gracias a esto podemos \"hablar\" de todas nuestras imagenes en el mismo \"lenguaje\", el nuevo descriptor.\n",
    "\n",
    "Para la descripcion de una imagen utilizaremos la frecuencia de cada palabra en el vocabulario.\n",
    "\n",
    "---\n",
    "\n",
    "*Construccion de Vocabulario Visual* ➡️ ***Representacion BOW*** ➡️ *Procesamiento de la Representacion* ➡️ *Entrenamiento de Categorizador* ➡️ *Validacion*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oQZy1cjV6KCA"
   },
   "source": [
    "### FALTA OBTENER n_clusters A PARTIR DEL MODELO ENTRENADO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5mbhfWW7nc5A"
   },
   "outputs": [],
   "source": [
    "def descriptoresABOWAgglomerativeClustering(descriptores_imagen, vocabulario):\n",
    "    \"\"\"\n",
    "    Convierte descriptores de una imagen a representación BoW\n",
    "\n",
    "    Args:\n",
    "        descriptores_imagen: np.array de descriptores Daisy de una imagen\n",
    "        vocabulario: modelo Agglomerative Clustering entrenado (modelo del vocabulario visual)\n",
    "\n",
    "    Returns:\n",
    "        histograma: vector de frecuencias de palabras visuales (BoW)\n",
    "    \"\"\"\n",
    "    centroides = vocabulario[\"centroides\"].astype(np.float32)\n",
    "\n",
    "    # Calcular distancias de cada descriptor al centroide más cercano\n",
    "    distancias = cdist(descriptores_imagen, centroides, metric='euclidean').astype(np.float32) # (n_descriptores, n_clusters)\n",
    "\n",
    "    # Asignar cada descriptor al centroide más cercano (palabra visual)\n",
    "    asignaciones = np.argmin(distancias, axis=1)\n",
    "\n",
    "    # Construir histograma de frecuencias de palabras visuales\n",
    "    histograma, _ = np.histogram(asignaciones, bins=np.arange(len(centroides) + 1))\n",
    "\n",
    "    return histograma.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def descriptoresABOWMiniBatchKMeans(descriptores_imagen, vocabulario):\n",
    "    \"\"\"\n",
    "    Convierte descriptores de una imagen a representación BoW\n",
    "\n",
    "    Args:\n",
    "        descriptores_imagen: np.array de descriptores SIFT de una imagen\n",
    "        vocabulario: objeto MiniBatchKMeans entrenado (modelo del vocabulario visual)\n",
    "\n",
    "    Returns:\n",
    "        histograma: vector de frecuencias de palabras visuales (BoW)\n",
    "    \"\"\"\n",
    "    n_clusters = vocabulario.n_clusters\n",
    "\n",
    "    # Asignar cada descriptor al centroide más cercano (palabra visual)\n",
    "    asignaciones = vocabulario.predict(descriptores_imagen) #COMPLETAR ...\n",
    "\n",
    "    # Construir histograma de frecuencias de palabras visuales\n",
    "    histograma, _ = np.histogram(asignaciones, bins=np.arange(n_clusters + 1)) #COMPLETAR ...\n",
    "\n",
    "    return histograma.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D7ThfTFInjVW"
   },
   "outputs": [],
   "source": [
    "def crearMatrizBOW(descriptores_dataset, vocabulario, clustering=None):\n",
    "    \"\"\"\n",
    "    Crea matriz BoW para todo el dataset\n",
    "    Donde Cada fila es la frecuencia del vocabulario en una imagen\n",
    "    \"\"\"\n",
    "    matriz_bow = []\n",
    "\n",
    "    print(\"Creando representaciones BoW...\")\n",
    "\n",
    "    for descriptores_imagen in tqdm(descriptores_dataset):\n",
    "      if clustering == \"agglomerative_clustering\":\n",
    "        bow = descriptoresABOWAgglomerativeClustering(descriptores_imagen, vocabulario)\n",
    "      else:\n",
    "        bow = descriptoresABOWMiniBatchKMeans(descriptores_imagen, vocabulario)\n",
    "      matriz_bow.append(bow.astype(np.float32))\n",
    "      del bow\n",
    "\n",
    "    return np.array(matriz_bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2jR00-SJWWVy"
   },
   "source": [
    "### ***6. TF-IDF***\n",
    "Con la Matriz de Representacion de Bag Of Words creada, podemos empezar a transformarla para intentar conseguir un mejor puntaje de forma barata. Una de nuestras opciones es aplicarle **TF-IDF**, presentado en la clase practica, con la intencion de darle mas importancia a las palabras visuales menos frecuentes y bajar el impacto de palabras comunes que no aportan informacion. Si pensamos en una analogia con texto, seria el equivalente de \"bajarle el precio\" a conectores, pronombres, articulos y etc.\n",
    "\n",
    "$$\n",
    "\\text{Tf-idf}_{t,d} = \\text{tf}_{t,d} ⋅ log(\\frac{N}{\\text{df}_t})\n",
    "$$\n",
    "\n",
    "donde\n",
    "- $\\text{Tf-idf}_{t,d}$ sera el nuevo valor de la palabra $t$ para la imagen $d$\n",
    "- $\\text{tf}_{t,d}$ era la frecuencia de la palabra $t$ para la imagen $d$\n",
    "- $N$ es la cantidad de imagenes totales\n",
    "- $\\text{df}_t$ es la cantidad de imagenes en la que la palabra $t$ aparece al menos una vez.\n",
    "\n",
    "---\n",
    "\n",
    "*Construccion de Vocabulario Visual* ➡️ *Representacion BOW* ➡️ ***Procesamiento de la Representacion*** ➡️ *Entrenamiento de Categorizador* ➡️ *Validacion*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8T5EH0POZJnc"
   },
   "outputs": [],
   "source": [
    "def aplicar_tfidf(matriz_bow):\n",
    "  \"\"\"\n",
    "  Aplica transformación TF-IDF a matriz de frecuencias\n",
    "\n",
    "  Args:\n",
    "    matriz_bow: matriz de frecuencias (n_images x n_words)\n",
    "\n",
    "  Returns:\n",
    "    matriz_tfidf: matriz con pesos TF-IDF\n",
    "  \"\"\"\n",
    "\n",
    "  matriz_tfidf = matriz_bow.copy()\n",
    "\n",
    "  n, m = matriz_bow.shape\n",
    "\n",
    "  df = np.count_nonzero(matriz_bow>0, axis=0)\n",
    "\n",
    "  df[df==0] = 1\n",
    "\n",
    "  idf = np.log(n / df)\n",
    "\n",
    "  matriz_tfidf = matriz_tfidf * idf\n",
    "\n",
    "\n",
    "  return matriz_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9QfjWjr0F4td"
   },
   "source": [
    "### ***7. Entrenamiento de un Clasificador***\n",
    "\n",
    "Ya habiendo aplicado todo el **post-procesamiento** que quisieramos a nuestra aplicacion, solo nos queda usarla para entrenar un **Categorizador de Escenas** que luego utilizaremos para hacer predicciones con imagenes entrantes nuevas.\n",
    "\n",
    "En este caso usaremos una **SVC** por su flexibilidad y por ya haber sido presentada en la Tarea anterior. Recordemos que una **SVC** encuentra los mejores Hiper Planos para separar los puntos de cada categoria, dejandonos aplicarle una **transformacion a los datos de entradas a un espacio de dimensionalidad mayor** si nos es necesario para encontrar hiperplanos validos.\n",
    "\n",
    "---\n",
    "\n",
    "*Construccion de Vocabulario Visual* ➡️ *Representacion BOW* ➡️ *Procesamiento de la Representacion* ➡️ ***Entrenamiento de Categorizador*** ➡️ *Validacion*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uoN2Uv1vM3XH"
   },
   "outputs": [],
   "source": [
    "def entrenar_svm(descriptores_train, etiquetas_train):\n",
    "    \"\"\"\n",
    "    Entrena un clasificador SVM\n",
    "\n",
    "    Returns:\n",
    "        clf: pipeline con SVC\n",
    "    \"\"\"\n",
    "\n",
    "    # make_pipeline les permite crear un pipeline sobre el propio categorizador SVC\n",
    "    # por si quieren hacer un procesamiento mas general de los datos antes de enviarlos a la SVC\n",
    "    clf = make_pipeline(SVC(kernel='linear', probability=True))\n",
    "    clf.fit(descriptores_train, etiquetas_train)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yE8NFiovkB_c"
   },
   "source": [
    "### ***8. Validacion***\n",
    "\n",
    "Con nuestro Clasificador entrenado, solo queda probarlo con los datos de validacion. Para esto tendremos que representar nuestras imagenes de validacion utilizando el vocabulario y las transformaciones de post-procesamiento con las que se entreno la SVM.\n",
    "\n",
    "Luego podremos analizar con mas detalles que puntos debiles tiene nuestro clasificador, por ejemplo, cuales son las categorias que mas se confunde entre si.\n",
    "\n",
    "---\n",
    "\n",
    "*Construccion de Vocabulario Visual* ➡️ *Representacion BOW* ➡️ *Procesamiento de la Representacion* ➡️ *Entrenamiento de Categorizador* ➡️ ***Validacion***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H99sr8oab90L"
   },
   "outputs": [],
   "source": [
    "def evaluar_clasificador_svm(clasificador, descriptores_bow_test, etiquetas_test, nombre_experimento=\"\"):\n",
    "  \"\"\"\n",
    "  Evalúa el clasificador SVM\n",
    "  Args:\n",
    "    clasificador: Clasificador a Evaluar\n",
    "    descriptores_bow_test: Descriptores de BoW a categorizar\n",
    "    etiquetas_test: Ground Truth para cada descriptor\n",
    "    nombre_experimento: Nombre opcional a imprimr\n",
    "\n",
    "  Returns:\n",
    "    predicciones: Etiquetas predichas por el clasificador para cada muestra del conjunto de prueba.\n",
    "    confianzas: Probabilidad más alta asignada por el modelo a la clase predicha para cada muestra (valor entre 0 y 1).\n",
    "    accuracy: Proporción de etiquetas correctamente clasificadas sobre el total de muestras: (n° aciertos) / (n° total).\n",
    "    precision: Para cada categoría, proporción de verdaderos positivos entre todos los predichos como esa categoría: TP / (TP + FP).\n",
    "    recall: Para cada categoría, proporción de verdaderos positivos entre los casos reales de esa categoría: TP / (TP + FN).\n",
    "    f1: Para cada categoría, media armónica entre precisión y recall: 2 * (precision * recall) / (precision + recall).\n",
    "    support: Número real de muestras en cada categoría dentro del conjunto de prueba (distribución real por clase).\n",
    "    confusion_matrix: Matriz de Confusion\n",
    "  \"\"\"\n",
    "\n",
    "  print(f\"Evaluando clasificador: {nombre_experimento}\")\n",
    "\n",
    "  # Predicción\n",
    "  predicciones = clasificador.predict(descriptores_bow_test)\n",
    "\n",
    "  # Confianzas: tomamos la probabilidad de la clase predicha\n",
    "  confianzas_prob = clasificador.predict_proba(descriptores_bow_test)\n",
    "  confianzas = confianzas_prob.max(axis=1)\n",
    "\n",
    "  # Métricas\n",
    "  accuracy = accuracy_score(etiquetas_test, predicciones)\n",
    "\n",
    "  precision, recall, f1, support = precision_recall_fscore_support(\n",
    "      etiquetas_test, predicciones, average=None, labels=CATEGORIAS\n",
    "  )\n",
    "\n",
    "  # Creamos una Matriz de Confusion para ver en que categorias se confunde nuestro clasificador\n",
    "  cm = confusion_matrix(etiquetas_test, predicciones, labels=CATEGORIAS)\n",
    "\n",
    "  return {\n",
    "    'predicciones': predicciones,\n",
    "    'confianzas': confianzas,\n",
    "    'accuracy': accuracy,\n",
    "    'precision': precision,\n",
    "    'recall': recall,\n",
    "    'f1': f1,\n",
    "    'support': support,\n",
    "    'confusion_matrix': cm\n",
    "  }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H2x39LAOnAjo"
   },
   "source": [
    "### ***8 Bis. Analisis de Resultados***\n",
    "Ya teniendo una muestra de como funciona nuestro categorizador, analizemos en mas detalle su desempeño."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c_zeXOggn6bQ"
   },
   "source": [
    "#### **Funciones de Analisis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T4zU1jMSnk78"
   },
   "outputs": [],
   "source": [
    "def crearTablaResultados(resultados, ks=None, metodos=None):\n",
    "    \"\"\"\n",
    "    Crea tabla resumen con todos los resultados\n",
    "    resultados: dict {metodo: métricas}\n",
    "    ks: dict opcional {metodo: valor_k}, si no se pasa, muestra '-'\n",
    "    metodos: lista opcional [(clave, titulo_legible)]\n",
    "    \"\"\"\n",
    "    if ks is None:\n",
    "        ks = {}\n",
    "\n",
    "    if metodos is None:\n",
    "        metodos = [(m, m) for m in resultados.keys()]\n",
    "\n",
    "    print(\"\\n📊 TABLA RESUMEN DE RESULTADOS\")\n",
    "    print(\"=\" * 90)\n",
    "    print(f\"{'Config':<35} {'Accuracy':<10} {'Precisión':<12} {'Recall':<10} {'F1-Score':<10}\")\n",
    "\n",
    "    for (metodo, titulo) in metodos:\n",
    "        res = resultados[metodo]\n",
    "        k_val = ks.get(metodo, '-')\n",
    "        config = f\"{titulo} (k={k_val})\"\n",
    "\n",
    "        acc = res['accuracy']\n",
    "        prec = np.mean(res['precision'])\n",
    "        rec = np.mean(res['recall'])\n",
    "        f1 = np.mean(res['f1'])\n",
    "\n",
    "        print(f\"{config:<35} {acc:<10.3f} {prec:<12.3f} {rec:<10.3f} {f1:<10.3f}\")\n",
    "\n",
    "    print(\"-\" * 90)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2Mr2ssgFnpGl"
   },
   "outputs": [],
   "source": [
    "def plotConfusionMatrices(resultados, k_valor, metodos):\n",
    "    \"\"\"Plotea matrices de confusión para un valor de k específico\"\"\"\n",
    "\n",
    "    fig, axes = plt.subplots(1, len(metodos), figsize=(15, 6))\n",
    "    if len(metodos) == 1:\n",
    "        axes = [axes]\n",
    "    for i, (metodo, titulo) in enumerate(metodos):\n",
    "\n",
    "        cm = resultados[metodo]['confusion_matrix']\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                   xticklabels=[cat for cat in CATEGORIAS],\n",
    "                   yticklabels=[cat for cat in CATEGORIAS],\n",
    "                   ax=axes[i])\n",
    "\n",
    "        axes[i].set_title(f'{titulo} (k={k_valor})')\n",
    "        axes[i].set_xlabel('Predicción')\n",
    "        axes[i].set_ylabel('Verdadero')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FUnSGF1snwC_"
   },
   "outputs": [],
   "source": [
    "def analizar_errores(resultados, metodo, testing_set):\n",
    "  \"\"\"Devuelve los errores de clasificación\"\"\"\n",
    "\n",
    "  resultado = resultados[metodo]\n",
    "  predicciones = resultado['predicciones']\n",
    "\n",
    "  etiquetas = testing_set['etiquetas']\n",
    "  imagenes = testing_set['imagenes']\n",
    "  nombres = testing_set['nombres']\n",
    "\n",
    "  # Encontrar errores\n",
    "  errores = []\n",
    "  for i, (real, pred) in enumerate(zip(etiquetas, predicciones)):\n",
    "    if real != pred:\n",
    "      errores.append({\n",
    "        'real': real,\n",
    "        'predicho': pred,\n",
    "        'imagen': imagenes[i],\n",
    "        'imagen_nombre': nombres[i],\n",
    "        'confianza': resultado['confianzas'][i]\n",
    "      })\n",
    "\n",
    "  return errores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mzDMR5dory63"
   },
   "outputs": [],
   "source": [
    "def imprimirErrores(errores, k, metodo, total, name=\"\"):\n",
    "  \"\"\"Imprime informacion sobre los errores\"\"\"\n",
    "  if not (k == None):\n",
    "    print(f\"\\n🔍 ANÁLISIS DE ERRORES ({metodo.upper()}, {name.upper()}, k={k})\")\n",
    "  else:\n",
    "    print(f\"\\n🔍 ANÁLISIS DE ERRORES ({metodo.upper()}, {name.upper()})\")\n",
    "\n",
    "  print(\"-\" * 50)\n",
    "  print(f\"Total de errores: {len(errores)} de {total} imágenes\")\n",
    "  print(f\"Accuracy: {(total - len(errores))/total:.3f}\")\n",
    "\n",
    "\n",
    "\n",
    "  # Análisis de confusiones más comunes\n",
    "  confusiones = {}\n",
    "  for error in errores:\n",
    "    par = (error['real'], error['predicho'])\n",
    "    if par not in confusiones:\n",
    "      confusiones[par] = []\n",
    "    confusiones[par].append(error)\n",
    "\n",
    "  print(f\"\\n📊 CONFUSIONES MÁS COMUNES:\")\n",
    "  for (real, pred), casos in sorted(confusiones.items(), key=lambda x: len(x[1]), reverse=True):\n",
    "    print(f\"  {real} → {pred}: {len(casos)} casos\")\n",
    "\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cpLgrjx4n4ap"
   },
   "outputs": [],
   "source": [
    "def mostrarEjemplosErrores(errores, n_ejemplos=4, name=\"\"):\n",
    "    \"\"\"Muestra ejemplos visuales de errores de clasificación en 2 columnas\"\"\"\n",
    "\n",
    "    if len(errores) == 0:\n",
    "        print(\"¡No hay errores para mostrar!\")\n",
    "        return\n",
    "\n",
    "    n_mostrar = min(n_ejemplos, len(errores))\n",
    "    errores_sample = random.sample(errores, k=n_mostrar)\n",
    "\n",
    "    # Definir 2 columnas\n",
    "    cols = 2\n",
    "    rows = math.ceil(n_mostrar / cols)\n",
    "\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(10, 5 * rows))\n",
    "    axes = axes.flatten()  # Convertir a lista para indexar fácilmente\n",
    "\n",
    "    fig.suptitle('Ejemplos de Errores de Clasificación', fontsize=16, fontweight='bold')\n",
    "\n",
    "    for i, error in enumerate(errores_sample):\n",
    "        axes[i].imshow(error['imagen'], cmap='gray', clim=(0,1))\n",
    "        axes[i].set_title(f'Real: {error[\"real\"].title()}\\nPredicho: {error[\"predicho\"].title()}')\n",
    "        axes[i].axis('off')\n",
    "\n",
    "    # Ocultar ejes sobrantes si hay menos imágenes que subplots\n",
    "    for j in range(i+1, len(axes)):\n",
    "        axes[j].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Guardar en Drive\n",
    "    output_dir = '/content/drive/MyDrive/TP-Final/'\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    output_path = os.path.join(output_dir, f\"{name.replace(' ', '_')}.png\")\n",
    "    plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tqaK8ed_DXaE"
   },
   "source": [
    "## PIPELINE DUAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SadlXwPRDRs_"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def pipeline(\n",
    "    subsets,\n",
    "    crearMatrizDescriptores,\n",
    "    crearMatrizBOW,\n",
    "    aplicar_tfidf,\n",
    "    entrenar_svm,\n",
    "    evaluar_clasificador_svm,\n",
    "    n_clusters=0,\n",
    "    K=0,\n",
    "    batch_size=0,\n",
    "    clustering_method=None\n",
    "):\n",
    "\n",
    "    if (clustering_method not in [\"agglomerative_clustering\", \"minibatchkmeans\"]):\n",
    "      print(\"Clustering inválido\")\n",
    "      return\n",
    "\n",
    "    usaKMeans = clustering_method == \"minibatchkmeans\"\n",
    "\n",
    "    resultados = []\n",
    "\n",
    "    n_folds = len(subsets)\n",
    "\n",
    "\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    if usaKMeans:\n",
    "       print(f\"Evaluando vocabulario con k={K} y batch_size={batch_size}\")\n",
    "    else:\n",
    "       print(f\"Evaluando vocabulario con {n_clusters} clusters...\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "\n",
    "    metrics_bow = []\n",
    "    metrics_tfidf = []\n",
    "    tiempos = []\n",
    "\n",
    "    for fold in range(n_folds):\n",
    "        print(f\"Fold {fold + 1}/{n_folds}\")\n",
    "\n",
    "        # Separo en subsets para cross validation\n",
    "        val_subset = subsets[fold]\n",
    "        train_subsets = [s for i, s in enumerate(subsets) if i != fold]\n",
    "        train_subset = unirSubsets(train_subsets)\n",
    "\n",
    "        print(\"Creo matriz de descriptores global\")\n",
    "\n",
    "        # 1. Creao matriz de descriptores global\n",
    "        descriptores = crearMatrizDescriptores(train_subset['descriptores'])\n",
    "\n",
    "        # 2. Entreno vocabulario\n",
    "\n",
    "        inicio = time.time()\n",
    "\n",
    "        descriptores_entrenamiento = np.vstack(train_subset['descriptores'])\n",
    "\n",
    "        print(\"Entreno vocabulario\")\n",
    "        if usaKMeans:\n",
    "          vocabulario = construirVocabularioMiniBatchKMeans(descriptores_entrenamiento, k=K, batch_size=batch_size)\n",
    "        else:\n",
    "          vocabulario = construirVocabularioAgglomerativeClustering(descriptores_entrenamiento, n_clusters)\n",
    "\n",
    "        fin = time.time()\n",
    "        tiempo_vocab = fin - inicio\n",
    "        tiempos.append(tiempo_vocab)\n",
    "\n",
    "        # 3. Representaciones BoW\n",
    "\n",
    "        print(\"Creo matriz BOW\")\n",
    "        X_train_bow = crearMatrizBOW(train_subset['descriptores'], vocabulario, clustering=clustering_method)\n",
    "        X_val_bow = crearMatrizBOW(val_subset['descriptores'], vocabulario, clustering=clustering_method)\n",
    "\n",
    "        # # 4. TF-IDF\n",
    "        X_train_tfidf = aplicar_tfidf(X_train_bow)\n",
    "        X_val_tfidf = aplicar_tfidf(X_val_bow)\n",
    "\n",
    "        # 5. Entrenar clasificadores\n",
    "\n",
    "        print(\"Entreno clasificador\")\n",
    "\n",
    "        clf_bow = entrenar_svm(X_train_bow, train_subset['etiquetas'])\n",
    "        clf_tfidf = entrenar_svm(X_train_tfidf, train_subset['etiquetas'])\n",
    "\n",
    "        # 6. Evaluo los clasificadores\n",
    "\n",
    "        print(\"Evaluo\")\n",
    "        resultado_bow = evaluar_clasificador_svm(\n",
    "            clf_bow, X_val_bow, val_subset['etiquetas'], f\"BoW fold {fold+1} (n_cluster={n_clusters})\"\n",
    "        )\n",
    "        resultado_tfidf = evaluar_clasificador_svm(\n",
    "            clf_tfidf, X_val_tfidf, val_subset['etiquetas'], f\"TF-IDF fold {fold+1} (n_cluster={n_clusters})\"\n",
    "        )\n",
    "\n",
    "        metrics_bow.append(resultado_bow)\n",
    "        metrics_tfidf.append(resultado_tfidf)\n",
    "\n",
    "    # Promedio métricas por fold (accuracy, precision, recall, f1)\n",
    "    def promediar_metricas(lista_resultados):\n",
    "        return {\n",
    "            'accuracy': np.mean([r['accuracy'] for r in lista_resultados]),\n",
    "            'precision': np.mean([r['precision'] for r in lista_resultados], axis=0),\n",
    "            'recall': np.mean([r['recall'] for r in lista_resultados], axis=0),\n",
    "            'f1': np.mean([r['f1'] for r in lista_resultados], axis=0),\n",
    "            'support': np.sum([r['support'] for r in lista_resultados], axis=0),  # soporte se suma\n",
    "            'confusion_matrix': np.sum([r['confusion_matrix'] for r in lista_resultados], axis=0)\n",
    "        }\n",
    "\n",
    "    promedio_bow = promediar_metricas(metrics_bow)\n",
    "    promedio_tfidf = promediar_metricas(metrics_tfidf)\n",
    "\n",
    "    if usaKMeans:\n",
    "        res = {\n",
    "        'k' : K,\n",
    "        'batch_size' : batch_size,\n",
    "        'n_cluster' : n_clusters,\n",
    "        'tiempo_promedio_vocab': np.mean(tiempos),\n",
    "        'bow': promedio_bow,\n",
    "        'tfidf': promedio_tfidf\n",
    "        }\n",
    "\n",
    "    else:\n",
    "        res = {\n",
    "        'n_cluster' : n_clusters,\n",
    "        'tiempo_promedio_vocab': np.mean(tiempos),\n",
    "        'bow': promedio_bow,\n",
    "        'tfidf': promedio_tfidf\n",
    "        }\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "08c8c13bd2e846d39b29a479df82b3b9",
      "6f286fbce079411d82903e49f0cce0d8",
      "d616de610d2b4abb8be0ad9a09915590",
      "21bc7372455444db8e13035fb1768d56",
      "4d9c6e505dcb492aa0b0d6baee25b518",
      "69c6cab8f1424d94b6a3a295b1049045",
      "5a0651c1ad5c43dd83e68e6a1dda8744",
      "ea429c0e9fa04867bde6087a8ecf9ec0",
      "2463cebd30104f60b0bf45dfd9570a2f",
      "5dfd7efc277b474cb7c1de858baf0d95",
      "5654dccfc7bb4a75b0c046aa4ad83876",
      "800a780635e747618b76785883174805",
      "ad76db799a524fe7875aa6d698a62cf3",
      "df41f363c8434521b0d24b5ffb5cae7b",
      "5903072f9a0849acbf05f1ed6c242316",
      "5be40f40216b4c96ae8b66477ad3c5a8",
      "d64561f796e143ed8e90b622c12a7fb1",
      "5fcb88f777af48388e4642ee518bf4af",
      "bed19e8b2a0f443981029add0bd1e3f4",
      "534accc056b64169a7825ee3b819122f",
      "61856204190f49a1bdbb7824bbf5336c",
      "9ed5295756414dea8a635156e2b71476",
      "46e7ada498cb406981ef7f5822bf1fd0",
      "a3ae0adee968459da8526543521bc5e6",
      "03ddb358d91d42b7823e948e344feda4",
      "80e3e1e6ca174f199a53cdaa7426a857",
      "9c1a6d40c9a84934b2de1cac82ee6fe6",
      "18ca8e2279ab4aa3b2118c97e81e5814",
      "bede69a6310b4639ac68e49d19462566",
      "72520c05c00742f0a2c22673059611d4",
      "03475cbaad3840c9bc35dd8dba217e46",
      "4fddbd02057a48c0b8d48bbd509824eb",
      "c48500db85a1408e8c47b97c4f1bfe40",
      "2212d97175eb4b318c8a0083d4426165",
      "c7f172734d064b9480e22c2afb8310eb",
      "0508e331f07842c1a236df4fa403df84",
      "a5c69c76859a4d88b0445eca54d242e0",
      "60b68b8f35d14b73becc8755af7def5e",
      "70dae5b6b1d04e94a679e9f8e08ecd0d",
      "faad1ee1b5504de082353d8a556da25c",
      "5affeb32f4e248fcb7e7647e87e79134",
      "dc104ef74bf34fbfacb0c68e97a2a696",
      "20587c05495e433bbe8b291aad82b165",
      "742e1a27e9be41169548afc18a9ebecd",
      "ab0f627b720345d690082ac6ffb03f92",
      "8cbd17a97dd14c3cab28730c6ab337de",
      "ac1ff63c83fc4c5895e3f7954ac0ae54",
      "e3f85c708b9a4a7a845273a2a50303c4",
      "2b263afa1b82492baacf168fa8b4891e",
      "9be0783f9b41431b9cc53b0667543e9d",
      "8ec0c02682404b0c80b42ad721e77671",
      "8a3e84ed842847bb84b9c375683ab70c",
      "d3b0d42a82244caf912076f47faaf48e",
      "0a2a34a3727d490f863ecf4ad51f23ca",
      "3e7cb6dbfe5243788d38db2ba6edc9f3",
      "5f0b43c80e5d4294b7d12b9eefb64037",
      "40de6387dd1f4054a2d958a3160482c8",
      "f1517f120eef4c1ba9bb0fd611e21d9d",
      "4e7b87e0c55b4f5c95cda5fe5c334ea6",
      "ffca0e02362b431da6d91417410c5108",
      "0d72fbd6185a4ccf92fc617ed189531e",
      "e9a136a2d42845c69f1985e04aa619b6",
      "1c2629179749410298e0b7b36cd37259",
      "abc210ae719f46e69ae9cc2e8eb6e6b8",
      "6d0b87cdd7b54b53a041125009e15a8f",
      "d3c586272030472f97649f12f2081a92",
      "ff72aa39ee004b3e84e8b71832986a24",
      "f06b44a6998749feb0cc3efd300a5a0f",
      "5e7ce1a5a5374f6ca81c1aaa5c31d444",
      "6928236e3e7c4caf982d052ddab0cca1",
      "a657cc3900914db2b60a3247914c7802",
      "90fada24068543169e71f281bcded12f",
      "8c7ddf533b2b4d5d98c3b0dad4bb8df9",
      "fb11ecb6d8014a6198fb51877857cf41",
      "6096698d03d74d2a91202738828d19b5",
      "60164109985f4d3f8cb5e0c4006178cd",
      "88bed3336b064a53bdf2a43f8896d49b",
      "65858b52d4d4485ebd93526e966e6818",
      "6474218b57a441f1ae55163a2bccffe3",
      "b9ced31c5ed64942a7ac20c962c15a8b",
      "ee5ef3f2d2a64202962a52b55f0f8422",
      "5ecd6a6b2e77443480f985dab19a50df",
      "a0976c61c93c4259a7d2af7cfa757329",
      "fa3c91ff9352492ab3d02652d520f866",
      "775f6c008fd84d708c58e6e2839966a4",
      "93892728347f4dcf969a1e6c8608c7f4",
      "68997764116346878dc25e2bffa4cfa1",
      "8447ed1fd70f4b9f918411b640e14627",
      "8ee659e3b308410f9153c92eb8592001",
      "389d08dbd00f452f8aa5a60231f92623",
      "69872954ef92408dba16381d2fcdd635",
      "a25be9efb1ae40ddbfb4ef8fdebf1362",
      "f663ab5f3c56437ca501475aea37c858",
      "b1fb21ed55f64fa9a4baca69a6971898",
      "0b610c71010046f79642d482a1d66db3",
      "0e9de5676b644bd6984d0c0f3b94b4ff",
      "712886e8591d4e0c986301749b9777c8",
      "c8a4f36bf778400aa2d8ad84a2c9d02e",
      "caea81046327403995a59ee8103aa8fb",
      "55b536ed453e45538e4777beefb8178e",
      "6730a4b05a8f4f69a75cb82cdf8d156b",
      "a94b20cc5b2f4f57a5611cf9be4eb62a",
      "0ea8bc7508dc4c749d1717618f694e86",
      "f8e7cd8d3dbf47cda50913692af3ba96",
      "26610378cb30435c823b018e39b7239c",
      "f6cc0565d8474901bb1b349ff518b523",
      "16cc377350de41a18c2984898f8a9904",
      "b71e0b8d08d54b89b35cf50b24f7d55b",
      "8e670b68bdbc42708ef448397a66371a",
      "c1a268fc88de4d01b37a46c60d64f977",
      "e1f140619d5d4b80bf68c67c648d3ec1",
      "4ec7c456b8e24235b9316820bd2952b4",
      "de9f66eb43254e8a9a1d96b4d8025bfb",
      "5b61ea8380c04e779975bc911fa44c29",
      "394e3731876c4d26b33772394f5c182a",
      "f07066b97ccf4ef2bfba268a5980810a",
      "91f0a7fa112047119edec8071429cb99",
      "3118424eb2894509be69a4a4e75c1272",
      "d5b23781341e495d94b18a0dc3722f44",
      "e9d0ac5d1f714143899494e0264c650c",
      "e87b21f6a9b747428f9cab3ad945409a",
      "cf5e40fe96cb4c41866d55c92c76d375",
      "f32e3e08e77c4055973072513d632080",
      "5c1573f8aba542d0aa8cd715207c5779",
      "e8a9767f144d41c8a8bc745aa229413a",
      "00371b6ccbce449fa69e4fd156507b71",
      "5d98bbba4a14446f8cc1c93550eb2f19",
      "6051890d0db74ceca5e796f883c9df54",
      "d7ec246cb75b498ca09490cd8ca09da6",
      "cf73069687914426b79f9c9fad6608c1",
      "2dad3909bfb9463da0190d88e428fe17",
      "09c752a577624d3a9d953cb33203b004",
      "407c3f0360854171885ca89d5b7849ef",
      "37fd190c06e6465493bfcf332cd779eb",
      "44b144ef6180402da637b8c3654b9699",
      "8799d631ee11471c91f47da887568c8d",
      "092d52616f9f4bbd8d206e1e1bdb760d",
      "af73acca3df84082927593b00886bade",
      "e4430acf62d7488ba9cc31e1ce561676",
      "f4c1262ede094b339ccdcd766de52c72",
      "36cb62b9dd7548ada6c71442ee6f844c",
      "312a822825b149e3b90df66592972bf9",
      "ac7410d0daa443fbac44af103e429caf",
      "22095d2745484b2f8b1b6f8d49ab21f1",
      "198a0f1030224003bf7e6d75620ec5f2",
      "1c1ca76997fa44eab7bf91e342688ba6",
      "15566c4ef7d1438d8d46070c58340c53",
      "5e3ef14d1f144082a9814fe8a8ee1114",
      "3bc5b0d642574feea148131adb63e2cf",
      "c6f3cdef51ef4592a33049e8b8687970",
      "9c832b6249b249ad8b7d40dd07ffabc0",
      "0dce219ba63d4b0c99e2dfab4c41194c",
      "ccdce9c88a5045a3839d9400fe64e683",
      "dec189c98ecd465aaea9a9dcecd7083b",
      "879e3b903ed84a43ae151169faed29a1",
      "61dd700eafb6407cabe355a5962ed488",
      "9776fb76efbe4a558f0544bc1ecec266",
      "213149af171b4189917df00175dcc62b",
      "00a699db2989474ea068f28c525eb876",
      "0130e9e0d59f44e8a3fd02f549458889",
      "a493143bccb6484482b3e151fb86de3b",
      "1a4f99a0c71b4ecca3ddb9c55b3a4063",
      "68713e99f1e9452f8a8e444867206955",
      "4b19e5e6633845bf806fb2490a105405",
      "591dc3550d3940289a2433f280aa50c7",
      "08af21f465df4e3397be42e494c31c7d",
      "4f96b534dfc04877b881454afde4f984",
      "8965aa85cac6429ebbe185cd852aab5a",
      "651d2915501a4e7eafe099d0bf8b3b09",
      "7a2491eee38343b19d90340da9410e20",
      "7a4e8ca0491c4a7b9897cc57dc162371",
      "84bf5eeee8bc4d81810f50239e23bf37",
      "cf4dd68551894da1ad248d930ad81c0d",
      "6114e5697c0d4b80a48a726729df5f38",
      "00ac742d72684f28bfc796222e2b4d65",
      "fcf45f746b364f4fa0b54888217cacc1",
      "d16baecf7922441089ca5b0e372d12ef",
      "b66771c0bcd24331a1c3813691a41cfc",
      "14710c19496c403cac7cc58ce8e0dbc7",
      "c68dbed531b243bab8d8bdb2820d0f74",
      "1445b5bc4198415bb1276170e592ce9d",
      "1c84a1694dbf4e4da997e2165dfbb19a",
      "2319386f636346c7a9507fb670540663",
      "79bbb84d1d194463b0671b79194d54fc",
      "18c4db23056b47f7a9d2c1b5eb8dbac1",
      "73359ce914a843c7adb0c875bf681520",
      "f1d62ef06cac4a63b6e99ed352098c2d",
      "76a300106b924c8580482c0598fa4826",
      "13a61a2e5c384d019677f9cb7418c38b",
      "14e3c9f89f704b02b10feb35ccd47bc3",
      "0f6b8a723a204063ab57b65fd9db16c1",
      "009de33c238046fbaf57e6cb55f0faae",
      "92f2caeed9064f3f86338c378ceb9b93",
      "79bc2cf0ab5b4f33958f2f9b37d7c4a9",
      "715a22e4856a4656afe37c410ed78d7e",
      "25b9ed7bbb514666bc82d2115235f121",
      "c53e77bfdad0409d9bb7636b7766e6be",
      "d9a702cf447a4790b1b9b41c3bcc2f91",
      "992f290b7ca84d96a1b351f786da070c",
      "6dfc5018a3534b52af636c8958d99327",
      "ef5d6755ea46491cbdcd294f04709abc",
      "a19f91791a5446938aac2c78c1f00039",
      "5b01f8f731b941ceaa333405b4545eff",
      "58068b5a5d0f4dab89ac02ddcfec0fc9",
      "b2d3960d5ca5452c82e720650537dfcd",
      "58e5fec57af048c5bb7990e549569885",
      "a57affeaab8d4eefaba1dfe97fe46683",
      "167c8ea756d9446297f44cc9ca8af217",
      "15a75ac4c71f4bb2817d76713fc2375a",
      "e2b9d08081c344a5859380013ba214ab",
      "42387bbb16ea44f2bd79ecff733de171",
      "4482c060ffe74ba5b58f54b8540b4738",
      "69c67390b17044e0a5eb9635c0a5efbb",
      "1767b36e794947ccb1dd0454db58965a",
      "b9afe19eea0d4710bdac84ef563a6760",
      "a2ae295e6a0a430abc2e40d655e4b59f",
      "4f280dae4b574947bc9cfc8e55ad8450",
      "8bbdf86295d5436d82d032392e28e379",
      "60c631c97a2c49f0ad8dddfb4777128b",
      "ab918091753a48f5a2b9e0760d525d9b",
      "f4f3d7f38a15468787894b600fac19f9",
      "2baa4a82a3c04d1facd07bfecd6aba2b",
      "1a6f4e6f95f44777a3c0e380bcfb060b",
      "e351e5e539b04dde9dbf836d1a72cdb0",
      "4d1ba9d932ea49c49a502fb62947ee13",
      "7fd3be156af7496a96811ca12ef71c93",
      "f3042b76ed4c4ec0b11d5cdaffaab63d",
      "05f2f0cba8424b0dab7ed72cf961d614",
      "e12aeed52310444e807d7f3100d39080",
      "05525c56aadd47beb78dc030ed222fba",
      "a10d175b183b41dbbf42fb95bed80c14",
      "0102d73528d44062989dcfbef3e88291",
      "88c0d6866b3644569cba9214d610479c",
      "4c16679076f4419e98af3c1884312bfc",
      "04e282757bce4e00843a9a1abcc3d1a6",
      "8fcb145104584e21a8b9c57004bf3982",
      "5f318d0141874488b6c96f740a0f581e",
      "f82f3456db094c729992c9b7a762dd2b",
      "9a910ddbceec4f1c9f59310ffafa849b",
      "46908241982d4b20be46a2b10e73e6d5",
      "c56b2c22342b467fb2aa1355a8f55020",
      "d32bc5b2e1ac4ee385f4389a39d5234b",
      "da11f0a4f4344ccb8caae832eeaff9b6",
      "6d797871062449c9ab1fdcc0ec7ca93d",
      "38138b1d9f724f31b5d09e09402382ef",
      "547efe889bde482da8d656fb354647f0",
      "f9a3f033b1c84f86b1f273ba4d98e194",
      "b1b5da5229424b049c7153c87b2e8ebe",
      "1865b3eb27834552b0cf91986f618d08",
      "4a41ea8276914e96badfca2fcabf1614",
      "7b3587db020a457aa413527fb3e4667d",
      "e5b9d4a8538b41439fdf9b05d846ec25",
      "bec16fc6114d44449aaa9a1074bfbccb",
      "10cb88d9680e41478d02cdc2f11057be",
      "084006ca835c4d10978bf91d4a26e381",
      "321c903fc36644c890596c6720d3f8f1",
      "555c005322f7461297957003bfad1fb2",
      "b28ba156f43a44dfaeb3e7d8e80f557c",
      "a22f08848e484a58abc3b0f3bc3ccc48",
      "ffd63210525d42dbb98f23f467fd32f8",
      "92faaa12648541e380dfb887f402f157",
      "43dbe32a714c49bea160b5cf8fe97018",
      "93c17548eb2449c496f3bcfb9e4906ab",
      "5ab47b0761014a5b966c76c08f6fb748",
      "e9285ed1975241be807d9a024267ee0f",
      "ba55cf7e4b8f4f75ba153326c80bc41f",
      "407f7b6d1d7c4db5b2aa643840e84432",
      "4ee981fc341a4cd4aa70e120f837b261",
      "4a97ca4bbeeb487dac236749571b5221",
      "b7876066dec34277baf6aa4d11476d46",
      "3dc72a1bf0cf489c9decd8f1d63711d0",
      "d6db393fa34742038f07ca40ebc683a5",
      "4132649e9c5243d1af51fc07663d6e7d",
      "45557f321dd245afbb4590f6763e35fc",
      "faa133031dba4f708f8fe87583ca5657",
      "ea381311d6a447b2bdc9968c79709cd5",
      "18a3c3e8d5854b709a9cf400835cff44",
      "f3af1b46042b4d9d9031968b6d8a74c8",
      "079e8b3851c44e7f97ffe5e207033668",
      "e16e278bce45481b95e15d6cf052280a",
      "fb444a14c967425599e30645f8e5a072",
      "67e27aa55afc47d2838e13654fa518b1",
      "724982a96f5f4f16a0c810db53d3f5bd",
      "a1fb17f1a7e24fa38c8182c7cd816848",
      "44844d8de4994ac69eda65ce2e606bae",
      "1a944b48c07b457ab06e8df266be5e9a",
      "6804fd8eace6453bbb6357793ff2018b",
      "a489d95275134ac18a18a8e8bb25bd7a",
      "bd9b9abcdb2b4425aa56246be4e28ae5",
      "7f180de5ff8c4823a09d206dba49f34c",
      "36b848eb8f474a9a940f2d9407066101",
      "a8d61ed2bd8a4d22bbe3d12b1d6dbf71",
      "44e2ba50050b4d918f7a5c1c273b27f8",
      "8c3722ca1c0f4fd7abf3be27ba81d00a",
      "0c595e38f4d540c1973a54057a3fd9e7",
      "793010d1effc448994e335f49ba75b94",
      "86154ede542e452a930fc9ca1172823d",
      "b5799f6339174952bba2fb813b532e1f",
      "6bbb80e39e0e4c4fac4e60f72a7b3de9",
      "23821ea680184d4abcb16a6af79ad193",
      "a9c8b93f436a40d8bccfc1c52fa8e134",
      "62dcc778b709485f8a665093cb675d84",
      "647248415ff340d9b271202c2e7a83cf",
      "34cd3ba52c4d4ed1a84a7b8b89523cce",
      "1f8aa3512bb04fe7a36cea7403b5e1b9",
      "cb4cb4cac2684c2cb5483393c45398f9",
      "61901b2327464c0a9ac88e10f25a885a",
      "b22f92da87494d11a56ca0894c1f35db",
      "15916c73c24d438c8276d82b1cf552e7",
      "e000251866e04b2289683dcca27a266d",
      "2cbdd378314840cd8bd2fa6272f4512a",
      "6debd77f7b924484b56e80153754a6d0",
      "656e2ee18af74bbd989faa5e914fcbf9",
      "c856def0876e42f5a5bb1c090ab06a09",
      "bac8d1ba5727497bbe06e985921581e0",
      "5d4eb63f45a947cd91d9b61de0f30bd0",
      "9538763991e444a19c79f1a2c0e8fa2b",
      "a7f6927d79f24b7a9f7d31c8f9a9a24a",
      "87d003dd21714e84ae3618c0b3865764",
      "50386c26a36049a2b985833115140e68",
      "4208183327c44921898cd58c7ab19aaf",
      "e89ba1d25b8b41a28a34a5a76911c492",
      "fb502e341fb046b2a44e80d97f66d81b",
      "26418086eb994861b39994fa9980c813",
      "49cf1b55508e4c32bc9314add558f510",
      "e167f4ad865a4015a29a4514829ae6ba",
      "dc42ed6ede594bc2bc3882d190ec62a4",
      "b17096243882469aa9ae4b588d99841b",
      "06c465fad1334fb78db740561b0a9171",
      "37d3368e5eec4c4fb12fc6155fb698ae",
      "2a9da849f70f4ddfa22ee59a54462163",
      "1e3053853cbb4942bce4ff4ecb5f8b2f",
      "70c6ce176d99416da720aaa4284fba79",
      "976d46938478433297891f10017da9fd",
      "2aef00c462cf47d0bd78b6090480d0c1",
      "f34ea1065be14b56a513a01c2c18e82e",
      "10bcb5a4489845559b772a5a45a63e49",
      "fcc64c6f1e374a9fb42f5c144fb8095c",
      "98d58fd81edd43848c55c820c2cfe475",
      "b169ef5e16834a708c101689fdb34011",
      "7faac2534ac84ad7bcfd7c6da9a462df",
      "9d9ab44998bd43afa33802d31e04b575",
      "668563d54d214070a345c4b84e4b1176",
      "a47a53f4c43342ebb5c8e12b1c3d3319",
      "d65aa9cc8bda455085f28c65aeacda4d",
      "90525dea2ea340f78d2fe244e788fe57",
      "22fd2c2ec28249548f2b98fcacaf4df7",
      "7055b715d1be449c8e9e24740d074071",
      "fdaae4d6637440f1a1ef2171190feca2",
      "c39bbdf548f44a9d94fc53f90dd0821b",
      "ddcf49cc34f04fe294179a5ca6f6dc0b",
      "1efbbec2a55348ffb527335d230cbd01",
      "7665b15f225e4420a9601fff5ce40753",
      "6dc6d2f5d8bf41449733668e0d260ea0",
      "acc555d7607642019529b3f364a5675e",
      "c2c2ed6ee38743d8b3473409fc1dcc2d",
      "5a8afdb50ad442a59e2b565afc2418b8",
      "87be7c8a39d34ec5bbe650e57a5569df",
      "f11f2dbbbb85404eb9fe858c2fdce274",
      "1b4d634e4a564e0eb077645626caabb6",
      "cd3047280156441587a5f3a7ea9ae161",
      "f4e917fbffb941c291623def1b9fca31",
      "e6cf8982f87a470bb014a111677be072",
      "980cd06261a4469b802cda4798ea7183",
      "3d7b119b3f1440b19ede236d771929f0",
      "46d80a066f3b4f0f95ea5ebb6b502544",
      "cc0c180539384b1285491d5ebd2627e0",
      "6154bc7a0d2f492a8f7a359eee5dd6de",
      "f6a4f140f8d240a3bd5c303f8d752291",
      "a9a1ac4652994b56996ddc205b3c2c9e",
      "d72785f9ff8541d2a12a9d85f64f09dc",
      "c19f49e33dcd4130ae8a1ca31bf091ed",
      "0853705919024ca4a6ca30b1d85a3926",
      "3f7dbc4fb94b4d58b77c36471dbd7c1c",
      "380298877e1f436e8f8da0b28abe5b82",
      "eca9b61fd46f4a7b81d673ca46760fad",
      "a1067487c9504346b0f325680b079f0f",
      "1e4ab44e16534fcba7f23c9a751d21c8",
      "45d1c532f62045e2a6c7649c989a5f01",
      "24230f58deeb466e8bacae8a741307fd",
      "00d533abbf7a4088b62b66912aec9a15",
      "465523e7a1f84b4e917707036474870c",
      "9a91f77c7bab4cd18022fd365b2aa4fe",
      "84f21f11f553400bb1f27ae5701d8f54",
      "9f7054a37a344ae193a8428b1cb9a003",
      "41e4c13826c143e58fa633463a613cf3",
      "a6fcf1a8948e4b8db2652c6970645657",
      "415c70ded5874e32aeed6f29b2d76fd7",
      "e49336d736ee428cbd1e588cbca7a985",
      "3bcf812ebd4d48048b2fe3e0b36d244f",
      "966e0e344ef647b0a838e357709b868f",
      "d467d083701c4e89bc04c403ad8be659",
      "0f8b8e272db441bc8759949f5d725d6f",
      "bf012a5daeb64b8780e54c0e6cd1256e",
      "06569162c89e40c7ac0555a5fcfb9057",
      "143450d1195445ff9d72b6d7dc118c3f",
      "e75da2322946476e99ecab0df4d9a6fe",
      "e62c33f0e31d4169ac892964bf7ea1e4",
      "2c2e9c3d06434c1f907e30c61cd7f1e5",
      "b062bd52fa4d42a398bdc69f93b20492",
      "053bd463e5104332a52104cb1377e771",
      "0faabbdb1faa46a0bd2748bf538ba806",
      "fa147f7101224881b10ec2d19a4dd127",
      "7532ec1f5ec446c8a78b9ea5d77f5e23",
      "b05eeb3f0231466da954fd8982085406",
      "8a51ccd860ee49ae819c9ef30031bd21",
      "f2d692d84e4c469ea93609be1e8ff312",
      "ef01d739c2cc4c8ea8eb8060a69f396c",
      "e870ccdd7468437796c3a9a4d2dfcfbd",
      "d6836844a8e841c9925ef9582c6ff306",
      "ca09a7ec48af4a6780145a1b7494036f",
      "ca03fd2904f74d38bfd7f013c4730428",
      "e58b8bd8ddea405986d06211eb7ac299",
      "dc26fbf430174b0e9d6cd830992aa407",
      "d6d1757fcd284deea48b75f498ebe1ca",
      "9c559ec9c4b040c9accbb5d7e4c87f52",
      "eefb028521d746878e90a714563cb1fd",
      "c5ea232a808b4a2c9a1401708f3a9b4e",
      "fafbf2ea29b84137a1e2052f7425ad6a",
      "4579f4bbd6994215b6722c8ac6c48995",
      "3ae361b57a3e4d28a0c79699fbd93983",
      "8c4a0ec2c16347cba90f8b10cf1a4d5f",
      "2dfa722031984636b1cef33974460038",
      "cea111b17a77438993d35907a0a03df8",
      "857a9c40bef6456a8dcd57f102250eeb",
      "7d71ba09d1c14864b2852f8bb0ebbade",
      "29ea9a5c6d1347b3877d6ddf87e156e8",
      "619d7cdb82a24070933b762e2c56b2f8",
      "ad603368862a48b587b0f1debddb1cb2",
      "4db4a689917a4ce28ccbee5ad7e9b02b",
      "de057105a4b442929a1fecafc206c92f",
      "5313dd53d16a409d9b35135b731ee268",
      "c02f51959e8548068124fa7d6251f3d1",
      "48b11034cef345438fde907c439cd395",
      "e34135d407254e1b85b005bfe7e0351f",
      "346fee514c3e4ee09dc63929d48b5bfa",
      "5cb8542003364c0bbdecee0ca743815a",
      "5b8ecfcb51be439781f3477f1b562bcd",
      "6d52e0c6f1d04f19bf1b653450d35f16",
      "e041e71969db4b818cac3eb0ea475de5",
      "525f6142253e462abae3f928f541c207",
      "b5710b8a9dd949a59a0db963329d5ab7",
      "848dc3e9eff1471482c9f8fc045346b8",
      "09e781d1dfd14ba29987104faa327104",
      "7925e90db75049faab52a1bd773cdecd",
      "3525246860c349e1bae59b07324716bb",
      "e5c2724392884d41bc23b698beac7063",
      "14f3eed918f24b8184247b32b5d7e86c",
      "c4130f95d18b4c36a92608b6c35deef1",
      "e97698e867814c7d9d27cd85064e1291",
      "f5190db440d440cb97faeab9735fb0d5",
      "03e2cbc76742404c9175e51ca7af5920",
      "1e61403069f74ad191bb6e717848b570",
      "997b2c152cf94f25bb259df39c256eb1",
      "be0ad9953bf648ebb2308821c8a01de0",
      "d035479345b844df822f7c7c45a4899f",
      "ea57cd7d9cc94b15b90f39af61745160",
      "f5180c840a0a46a387e1e4382ca2995d",
      "691c68cdf15c487281e493c5b872eac0",
      "67f2a0f0e29f444083fa067c58ff189e",
      "3a78542f27ba4a8b8083609f4b1dbf06",
      "14be0b24003348dfb9ceed4f15d41f85",
      "7abc2c2f0937438a84b2e1984a316673",
      "27564add73ac433da4f272a7e0576d3d",
      "e3242263116d498e9cc488d88606e850",
      "227ee3d685a34aa0bddc2bc3e8711947",
      "6061de06d6384ec1a8ae9bd52a0eff50",
      "df96f18835b64b038663ce02957cadcf",
      "64ceb55368244b6883139a5a6ccfda12",
      "4443692d412b4c7485abbe344ae63a5d",
      "b93edc8f9bec49b3b588fda83f8d6b60",
      "07933fbe66e74c7a9407e8cd3ecfd8f6",
      "f60b44639bdb4fc5ba042d0cc135b9ce",
      "87197c95b4c24297a352067085dddaf2",
      "fd75560f321046ae891d15f7ad2ce0b6",
      "3b8810ecfb804b299145e1d782f52e5b",
      "7e3f4566c25a4006a3ea77886ecaba8a",
      "6e3c87bd85a74d3495c026fd4f6e4d1d",
      "75f9ee5ae3ba48f29973ed5674a2296d",
      "5ba501855eb34e7cb00395683b12eaec",
      "d20255e338ff4f5c93d63d0cc21293c4",
      "d95b4990b42044689fa5a7804d70690f",
      "064bbf4d362547658ba64b162611f2ee",
      "0eeef83c14034ba6ac8005bf7249152b",
      "22e5e13fe17844338ea30e19c503433d",
      "9d032a32b76247ec913d3dfbd6ac08b4",
      "c1343a61a2044cf68c7f5f268b9b1042",
      "abb1ac4034c24cedb4723168c94316c8",
      "64effed1415243f6a8417f6c3fb939ce",
      "382ebee342af415ea4988e2991925672",
      "75fba35d4f85443da1e72046473beb69",
      "d90d947fa02b40ddabce28cacb18af92",
      "085f739cec7d465bba3aebea24c32457",
      "2ce1375f28d34062acd4d5b6259af10d",
      "c1170aa6d9cb4e7cadd782887a9e45ae",
      "ab3b8d9e215f4dc1a0c177d6e4d1c8c0",
      "8b875565f9114139ae45b509bcc2b7e9",
      "6660a525e3de4aebabeee0287f05547c",
      "75bb01b3de3a4295baaa671647df61a7",
      "b843c5d8b5d34cbb9337cb6bae4e5878",
      "cb3bacefa9ab43809491215933df754c",
      "7bff3c95ea214eedb0e9c5a1cf881fc3",
      "9dc3246267e44ce2986cc3426a17db13",
      "c51e348ab1b84840abbd8e88e36f5a49",
      "a7c2abc0c86145eb9a542f4f748b952a",
      "47b88f44d884437388d21a9563efee62",
      "8999895d3ccf4963ba8bfbebbe3b0ce3",
      "d3daa609d4804b1e97d1192235507201",
      "14a153f481104e819f78ea7f4a07880e",
      "5b6b785822f140c2a835c3975110e1e7",
      "0a97b05f93484a3aba146d6512a00f93",
      "c823624bb00f412e84becd3087b1897b",
      "59f130e7b2c14c6e973fceedd20cd9c9",
      "500369cc61464c9f873e77761f134fe4",
      "c8641c03e6f4467c86b865db412b648c",
      "8468f9452f954016895a19850cbd40b8",
      "73324d0a9d1d4eb5ac68feeda78854b3",
      "c1341a935402451aba1be7bd743ada30",
      "3b995340a49448afb81c7dd70e9a4b94",
      "080f261320b24b18a4bfe7aed9af38f3",
      "5e2dc9cf77644dbab1d07066997498c0",
      "f2a3e3b891884c529236791f64fce291",
      "de613aa95309457eaeaca6965c3f759e",
      "3db9a16afd874c37b9da0eb85db68682",
      "4f7e7790f2e14812956083252774e616",
      "3e0bbb6d57f94a6fa24d91e5e6df1516",
      "c8a9d199eeba4aae97c4486cd6411dc5",
      "64c59eb480944f11a0423cc90fe4c3bf",
      "e09968619d1045859ee1a39f4a8ffeb1",
      "1b44329b78ea45779d5f570649abc562",
      "bc40dfb487d347d8a90c0b59d1e34ca6",
      "30bedcbfa8f946c1b2621757a4104342",
      "40b4a8d3ee7147f68a656cd414505cbd",
      "2d5ef5b847b0457a8dfdad960928edaa",
      "be6672c095144723a3686cf80588de26",
      "cc4af6c70709482d8b898cb537bfb006",
      "a9e9fa5769ef4557ad54f26f53503505",
      "28d3174ffd7042588eda0aba309cc61b",
      "df4271db770f4ed3a924538127abed7d",
      "84d5a54a68454f5296e68097e39d56c4",
      "4d28255c22614b3da2d2ac2f1363ab73",
      "6f3c2168453c49d3b00ea5362e218696",
      "311aad4ff96148868be6534e27ef54fe",
      "cf63ff07e8f5475db563a78c0ceb1743",
      "68c76aa248c34f009826b03967abe8bc",
      "9f0da93abad9499b9479bd5f5cc8bd6a",
      "9a11a6e6ee6041689974cece702191ca",
      "74e2f962594a4b29aeb7c4e5488087be",
      "c20735c1cb6e41c795fadb82ba224556",
      "fa9e4d062d094bf59fddfec306eb3932"
     ]
    },
    "id": "o7owhXoNDKu6",
    "outputId": "68bf4205-cb0e-49c8-8266-e9fad00d0d3b"
   },
   "outputs": [],
   "source": [
    "n_clusters = [5, 10, 20, 50, 100, 150, 200]\n",
    "k_values = [5, 30, 50, 100, 300]\n",
    "batch_sizes = [200, 500, 800, 1000]\n",
    "\n",
    "if recalcular_pipeline:\n",
    "  res_agglomerative = []\n",
    "\n",
    "  for n_cluster in n_clusters:\n",
    "    res = pipeline(\n",
    "      subsets=subsets_daisy,\n",
    "      crearMatrizDescriptores=crearMatrizDescriptores,\n",
    "      crearMatrizBOW=crearMatrizBOW,\n",
    "      aplicar_tfidf=aplicar_tfidf,\n",
    "      entrenar_svm=entrenar_svm,\n",
    "      evaluar_clasificador_svm=evaluar_clasificador_svm,\n",
    "      n_clusters=n_cluster,\n",
    "      K=None,\n",
    "      batch_size=None,\n",
    "      clustering_method=\"agglomerative_clustering\"\n",
    "      )\n",
    "    res_agglomerative.append(res)\n",
    "\n",
    "  res_kmeans = []\n",
    "\n",
    "  for k in k_values:\n",
    "    for batch_size in batch_sizes:\n",
    "      res = pipeline(\n",
    "        subsets=subsets_sift,\n",
    "        crearMatrizDescriptores=crearMatrizDescriptores,\n",
    "        crearMatrizBOW=crearMatrizBOW,\n",
    "        aplicar_tfidf=aplicar_tfidf,\n",
    "        entrenar_svm=entrenar_svm,\n",
    "        evaluar_clasificador_svm=evaluar_clasificador_svm,\n",
    "        n_clusters=None,\n",
    "        K=k,\n",
    "        batch_size=batch_size,\n",
    "        clustering_method=\"minibatchkmeans\"\n",
    "        )\n",
    "      res_kmeans.append(res)\n",
    "\n",
    "    # Guardamos así no lo calculamos todo el tiempo\n",
    "    with open(\"res_agglomerative.pkl\", \"wb\") as f:\n",
    "        pickle.dump(res_agglomerative, f)\n",
    "    with open(\"res_kmeans.pkl\", \"wb\") as f:\n",
    "        pickle.dump(res_kmeans, f)\n",
    "\n",
    "else:\n",
    "    with open(\"/content/drive/MyDrive/TP-Final/res_agglomerative.pkl\", \"rb\") as f:\n",
    "        res_agglomerative = pickle.load(f)\n",
    "    with open(\"/content/drive/MyDrive/TP-Final/res_kmeans.pkl\", \"rb\") as f:\n",
    "        res_kmeans = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v6KV2y2EUeAk",
    "outputId": "a218f117-a5fc-452c-a7f7-0f3ea8583ee4"
   },
   "outputs": [],
   "source": [
    "print(f\"{'n_clusters':<6} {'BoW Acc':<10} {'TF-IDF Acc':<12} {'Tiempo Vocabulario (s)':<10} \")\n",
    "print(\"-\" * 50)\n",
    "for r in res_agglomerative: # Corrected to iterate through res_agglomerative for n_cluster\n",
    "    print(f\"{r['n_cluster']:<6}  {r['bow']['accuracy']:<12.2f} {r['tfidf']['accuracy']:<10.3f} {r['tiempo_promedio_vocab']:<10.3f}\")\n",
    "\n",
    "print(\" \")\n",
    "print(f\"{'k':<6} {'batch_size':<10} {'Acc. BoW':<10} {'Acc. TF-IDF':<10} {'Tiempo(s)':<12} \")\n",
    "print(\"-\" * 50)\n",
    "for r in res_kmeans: # Corrected to iterate through res_kmeans for k and batch_size\n",
    "    print(f\"{r['k']:<6} {r['batch_size']:<10} {r['bow']['accuracy']:<10.3f} {r['tfidf']['accuracy']:<10.3f} {r['tiempo_promedio_vocab']:<12.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def convertir_resultados_a_df(resultados, metodo):\n",
    "    filas = []\n",
    "    for r in resultados:\n",
    "        fila = {\n",
    "            'metodo': metodo,\n",
    "            'n_clusters': r.get('n_cluster'),\n",
    "            'k': r.get('k', None),\n",
    "            'batch_size': r.get('batch_size', None),\n",
    "            'tiempo_vocab': r['tiempo_promedio_vocab'],\n",
    "            'accuracy_bow': r['bow']['accuracy'],\n",
    "            'accuracy_tfidf': r['tfidf']['accuracy'],\n",
    "            'f1_macro_bow': r['bow']['f1'].mean(),\n",
    "            'f1_macro_tfidf': r['tfidf']['f1'].mean()\n",
    "        }\n",
    "        filas.append(fila)\n",
    "    return pd.DataFrame(filas)\n",
    "\n",
    "df_kmeans = convertir_resultados_a_df(res_kmeans, \"MiniBatchKMeans\")\n",
    "df_agglom = convertir_resultados_a_df(res_agglomerative, \"Agglomerative\")\n",
    "\n",
    "df_resultados = pd.concat([df_kmeans, df_agglom], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "plt.figure(figsize=(18, 10))\n",
    "\n",
    "# 1. Accuracy BoW\n",
    "plt.subplot(2, 3, 1)\n",
    "sns.lineplot(data=df_resultados, x='n_clusters', y='accuracy_bow', marker='o')\n",
    "plt.title('Accuracy (BoW) vs n_clusters')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('n_clusters')\n",
    "\n",
    "# 2. Accuracy TF-IDF\n",
    "plt.subplot(2, 3, 2)\n",
    "sns.lineplot(data=df_resultados, x='n_clusters', y='accuracy_tfidf', marker='o')\n",
    "plt.title('Accuracy (TF-IDF) vs n_clusters')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('n_clusters')\n",
    "\n",
    "# 3. Tiempo vocabulario\n",
    "plt.subplot(2, 3, 3)\n",
    "sns.lineplot(data=df_resultados, x='n_clusters', y='tiempo_vocab', marker='o')\n",
    "plt.title('Tiempo promedio vocabulario vs n_clusters')\n",
    "plt.ylabel('Tiempo (seg)')\n",
    "plt.xlabel('n_clusters')\n",
    "\n",
    "# 4. F1 macro BoW\n",
    "plt.subplot(2, 3, 4)\n",
    "sns.lineplot(data=df_resultados, x='n_clusters', y='f1_macro_bow', marker='o')\n",
    "plt.title('F1 macro (BoW) vs n_clusters')\n",
    "plt.ylabel('F1 macro')\n",
    "plt.xlabel('n_clusters')\n",
    "\n",
    "# 5. F1 macro TF-IDF\n",
    "plt.subplot(2, 3, 5)\n",
    "sns.lineplot(data=df_resultados, x='n_clusters', y='f1_macro_tfidf', marker='o')\n",
    "plt.title('F1 macro (TF-IDF) vs n_clusters')\n",
    "plt.ylabel('F1 macro')\n",
    "plt.xlabel('n_clusters')\n",
    "\n",
    "# Espacio entre subplots\n",
    "\n",
    "plt.suptitle(\"Visualización de resultados para Daisy + Agglomerative Clustering\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar que a partir de los 50 clusters no hay una tendencia significativa de aumento en las métricas. Además, el tiempo se mantiene cercano al rango de los 70-80 segundos para todos los valores. Entre Bag of Words y TF-IDF no vemos una ventaja clara, ya que dan resultados muy similares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función auxiliar para crear cada heatmap\n",
    "def plot_heatmap(df, value_col, title, ax, cmap=\"YlGnBu\", fmt=\".3f\"):\n",
    "    tabla = df.pivot(index='batch_size', columns='k', values=value_col)\n",
    "    sns.heatmap(tabla, annot=True, fmt=fmt, cmap=cmap, ax=ax)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"k\")\n",
    "    ax.set_ylabel(\"batch_size\")\n",
    "\n",
    "# Crear figura: 3 filas, 2 columnas\n",
    "fig, axes = plt.subplots(3, 2, figsize=(14, 14))\n",
    "\n",
    "# Heatmaps métricas\n",
    "plot_heatmap(df_kmeans, 'accuracy_bow', 'Accuracy (BoW)', axes[0, 0])\n",
    "plot_heatmap(df_kmeans, 'accuracy_tfidf', 'Accuracy (TF-IDF)', axes[0, 1])\n",
    "plot_heatmap(df_kmeans, 'f1_macro_bow', 'F1 macro (BoW)', axes[1, 0], cmap=\"magma\")\n",
    "plot_heatmap(df_kmeans, 'f1_macro_tfidf', 'F1 macro (TF-IDF)', axes[1, 1], cmap=\"magma\")\n",
    "\n",
    "# Heatmap de tiempo\n",
    "plot_heatmap(df_kmeans, 'tiempo_vocab', 'Tiempo construcción vocabulario (seg)', axes[2, 0], cmap=\"OrRd\", fmt=\".2f\")\n",
    "axes[2, 1].axis('off')  # Dejar el último espacio vacío\n",
    "\n",
    "# Título general\n",
    "plt.suptitle(\"Efecto de k y batch_size en SIFT+MiniBatchKMeans\", fontsize=18)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso, vemos que con K=30 ya es suficiente para un accuracy elevado, y que con K=300 es casi inmejorable. Hay una leve tendencia a aumentar los parametros con un K más elevado, sin embargo, no hay diferencias significativas al aumentar el batch_size más allá de 200. El tiempo, por su parte, es muy inferior al de Daisy+Agglomerative Clustering, y podemos notar que a medida que aumentamos los clusters, también lo hace el tiempo, aunque nunca superior a los 2 segundos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🔝 Top 5 resultados según Accuracy (BoW):\")\n",
    "print(df_resultados.sort_values(by='accuracy_bow', ascending=False).head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si priorizamos el accuracy o el f1, que ya vimos que aumentan de forma muy similar, las mejores combinaciones son con MiniBatchKMeans, y a un costo computacional considerablemente mejor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluación final de ambos modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar los mejores resultados según BoW Accuracy\n",
    "best_agglomerative = max(res_agglomerative, key=lambda r: r['bow']['accuracy'])\n",
    "best_kmeans = max(res_kmeans, key=lambda r: r['bow']['accuracy'])\n",
    "\n",
    "# Extraer valores\n",
    "best_n_cluster = best_agglomerative['n_cluster']\n",
    "best_k = best_kmeans['k']\n",
    "best_batch = best_kmeans['batch_size']\n",
    "\n",
    "print(\"Mejor Agglomerative:\")\n",
    "print(f\"  n_clusters = {best_n_cluster}, Accuracy = {best_agglomerative['bow']['accuracy']:.3f}\")\n",
    "\n",
    "print(\"Mejor MiniBatchKMeans:\")\n",
    "print(f\"  k = {best_k}, batch_size = {best_batch}, Accuracy = {best_kmeans['bow']['accuracy']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if recalcular_test:\n",
    "    # Extraer SIFT del set de test\n",
    "    keypoints_test_sift, descriptores_test_sift, stats_test_sift = extraerSIFTDataSet(imagenes_test, etiquetas_test)\n",
    "    keypoints_test_daisy, descriptores_test_daisy, stats_test_daisy = extraerDaisyDataSet(imagenes_test, step=45, image_index = 5, radius=30, rings=2, histograms=6, orientations=8)\n",
    "    # Guardar los resultados de test\n",
    "    with open('sift_test.pkl', 'wb') as f:\n",
    "        pickle.dump((keypoints_test_sift, descriptores_test_sift, stats_test_sift), f)\n",
    "\n",
    "    with open('daisy_test.pkl', 'wb') as f:\n",
    "        pickle.dump((keypoints_test_daisy, descriptores_test_daisy, stats_test_daisy), f)\n",
    "else:\n",
    "\n",
    "    with open('sift_test.pkl', 'rb') as f:\n",
    "        keypoints_test_sift, descriptores_test_sift, stats_test_sift = pickle.load(f)\n",
    "\n",
    "    with open('daisy_test.pkl', 'rb') as f:\n",
    "        keypoints_test_daisy, descriptores_test_daisy, stats_test_daisy = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluo Daisy + Agglomerative clustering\n",
    "\n",
    "if recalcular_mejores:\n",
    "\n",
    "  descs_entrenamiento = np.vstack(descriptores_train_daisy)\n",
    "\n",
    "  vocab = construirVocabularioAgglomerativeClustering(descs_entrenamiento, n_clusters=best_n_cluster)\n",
    "\n",
    "  X_train_bow = crearMatrizBOW(descriptores_train_daisy, vocab, clustering='agglomerative_clustering')\n",
    "\n",
    "  X_test_bow = crearMatrizBOW(descriptores_test_daisy, vocab, clustering='agglomerative_clustering')\n",
    "\n",
    "  clf_bow = entrenar_svm(X_train_bow, etiquetas_train)\n",
    "\n",
    "  resultado_daisy = evaluar_clasificador_svm(clf_bow, X_test_bow, etiquetas_test, \"Daisy + Agglomerative Clustering\")\n",
    "\n",
    "  if recalcular_mejores:\n",
    "    with open('res_mejor_daisy.pkl', 'wb') as f:\n",
    "        pickle.dump(resultado_daisy, f)\n",
    "\n",
    "else:\n",
    "  with open('res_mejor_daisy.pkl', 'rb') as f:\n",
    "    resultado_daisy = pickle.load(f)\n",
    "\n",
    "\n",
    "print(resultado_daisy[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluo SIFT + MiniBatchKMeans\n",
    "\n",
    "if recalcular_mejores:\n",
    "\n",
    "  descs_entrenamiento = np.vstack(descriptores_train_sift)\n",
    "\n",
    "  vocab2 = construirVocabularioMiniBatchKMeans(descs_entrenamiento, k=best_k, batch_size=best_batch)\n",
    "\n",
    "  X_train_bow = crearMatrizBOW(descriptores_train_sift, vocab2, clustering='minibatchkmeans')\n",
    "\n",
    "  X_test_bow = crearMatrizBOW(descriptores_test_sift, vocab2, clustering='minibatchkmeans')\n",
    "\n",
    "  clf_bow = entrenar_svm(X_train_bow, etiquetas_train)\n",
    "\n",
    "  resultado_sift = evaluar_clasificador_svm(clf_bow, X_test_bow, etiquetas_test, \"SIFT + MiniBatchKMeans\")\n",
    "\n",
    "  if recalcular_mejores:\n",
    "    with open('/content/drive/MyDrive/TP-Final/res_mejor_sift.pkl', 'wb') as f:\n",
    "        pickle.dump(resultado_sift, f)\n",
    "\n",
    "else:\n",
    "  with open('/content/drive/MyDrive/TP-Final/res_mejor_sift.pkl', 'rb') as f:\n",
    "      resultado_sift = pickle.load(f)\n",
    "\n",
    "print(resultado_sift[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados = {\n",
    "    'sift': resultado_sift,\n",
    "    'daisy': resultado_daisy\n",
    "}\n",
    "\n",
    "ks = {\n",
    "    'sift': best_k,\n",
    "    'daisy': None\n",
    "}\n",
    "\n",
    "metodos = [\n",
    "    ('sift', 'BoW SIFT Final'),\n",
    "    ('daisy', 'BoW DAISY Final')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotConfusionMatrices({'bow': resultado_sift}, best_k, [('bow', 'BoW Final')])\n",
    "plotConfusionMatrices({'bow': resultado_daisy}, \"-\", [('bow', 'BoW Final')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_set = {\n",
    "    'imagenes': imagenes_test,\n",
    "    'etiquetas': etiquetas_test,\n",
    "    'nombres': nombres_test\n",
    "}\n",
    "errores_test_daisy = analizar_errores({'bow': resultado_daisy}, 'bow', testing_set)\n",
    "imprimirErrores(errores_test_daisy, k=None, metodo='bow', total=len(etiquetas_test), name=\"DAISY\")\n",
    "\n",
    "errores_test_sift = analizar_errores({'bow': resultado_sift}, 'bow', testing_set)\n",
    "imprimirErrores(errores_test_sift, k=best_k, metodo='bow', total=len(etiquetas_test), name=\"SIFT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrarEjemplosErrores(errores_test_daisy, 2, name=\"DAISY + Agglomerative Clustering\")\n",
    "mostrarEjemplosErrores(errores_test_sift, 4, name=\"SIFT + MiniBatchKMeans\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graficar_sift_vs_daisy(imagen, kp_sift, kp_daisy, step=45, radius=30, rings=2, histograms=6, orientations=8):\n",
    "    \"\"\"\n",
    "    Muestra comparación entre SIFT, DAISY simple y DAISY detallado (visualize=True).\n",
    "\n",
    "    Params:\n",
    "        imagen: imagen en escala de grises o RGB\n",
    "        kp_sift: lista de puntos (KeyPoint o coordenadas)\n",
    "        kp_daisy: lista de puntos (KeyPoint o coordenadas)\n",
    "    \"\"\"\n",
    "    # Convertir a escala de grises para DAISY\n",
    "    img_gray = color.rgb2gray(imagen) if imagen.ndim == 3 else imagen\n",
    "\n",
    "    # Normalizar para OpenCV\n",
    "    img_cv = (img_gray * 255).astype('uint8') if img_gray.dtype != 'uint8' else img_gray\n",
    "\n",
    "    # Convertir keypoints DAISY a KeyPoint si es necesario\n",
    "    def convertir(lista, size=10):\n",
    "        return [cv2.KeyPoint(float(x), float(y), size) for (x, y) in lista]\n",
    "\n",
    "    if not isinstance(kp_sift[0], cv2.KeyPoint):\n",
    "        kp_sift = convertir(kp_sift)\n",
    "    if not isinstance(kp_daisy[0], cv2.KeyPoint):\n",
    "        kp_daisy = convertir(kp_daisy)\n",
    "\n",
    "    # Dibujar keypoints\n",
    "    img_sift = cv2.drawKeypoints(img_cv, kp_sift, None, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "    # DAISY detallado (visualize=True)\n",
    "    _, daisy_vis = daisy(img_gray, step=step, radius=radius, rings=rings,\n",
    "                         histograms=histograms, orientations=orientations,\n",
    "                         visualize=True)\n",
    "\n",
    "    # Mostrar\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    axs[0].imshow(cv2.cvtColor(img_sift, cv2.COLOR_BGR2RGB))\n",
    "    axs[0].set_title(f\"SIFT Keypoints ({len(kp_sift)})\", fontsize=16, fontweight='bold')\n",
    "    axs[0].axis('off')\n",
    "\n",
    "\n",
    "    axs[1].imshow(daisy_vis, cmap='gray')\n",
    "    axs[1].set_title(\"DAISY Structure\", fontsize=16, fontweight='bold')\n",
    "    axs[1].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagen = imagenes_test[7]\n",
    "kp_sift = keypoints_test_sift[7]\n",
    "kp_daisy = keypoints_test_daisy[7]\n",
    "\n",
    "graficar_sift_vs_daisy(imagen, kp_sift, kp_daisy)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "c_zeXOggn6bQ"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
